{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Copy of Roboflow_Deploy_Custom_Mobilenet_to_OAK-D.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/bhargav23/OpenCV/blob/main/Success/Copy_of_Roboflow_Deploy_Custom_Mobilenet_to_OAK_D.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mJz_ToJtkufM"
      },
      "source": [
        "# Roboflow and DepthAI Tutorial: Train and Deploy a custom object detection model with depth! \n",
        "\n",
        "#### ![Roboflow Workmark](https://i.imgur.com/WHFqYSJ.png)\n",
        "\n",
        "\n",
        "<img src=\"https://docs.luxonis.com/images/depthai_logo.png\" width=\"500\">\n",
        "\n",
        "We highly recommend working through this notebook with the corresponding blog post in hand. \n",
        "\n",
        "A Major shoutout to Luxonis, the creators of the OAK-D Device for originally putting this tutorial together. Here, we streamline the training process with data management, transformation, and exportation from Roboflow. \n",
        "\n",
        "At the end of this tutorial, you will have a custom trained object detection model to deploy to your OAK-D device!\n",
        "\n",
        "\n",
        "Insert GIF\n",
        "\n",
        "The steps we take to train and deploy our custom model are as follows \n",
        "\n",
        "\n",
        "* Install MobileNet Training Environment Dependencies\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3TEgconcGvVK"
      },
      "source": [
        "# Install Training Environment Dependencies and Configs"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pH1x08R-yM-L",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 360
        },
        "outputId": "32059037-bdea-42c1-fc56-676cc48b9268"
      },
      "source": [
        "# %%capture\n",
        "#After this cell executes runtime will restart to finish the install, ignore and close the crash message, continue running cells starting with the one below\n",
        "!pip install numpy==1.17.5;\n",
        "import os\n",
        "#os.kill(os.getpid(), 9)"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting numpy==1.17.5\n",
            "  Downloading numpy-1.17.5-cp37-cp37m-manylinux1_x86_64.whl (20.0 MB)\n",
            "\u001b[K     |████████████████████████████████| 20.0 MB 1.3 MB/s \n",
            "\u001b[?25hInstalling collected packages: numpy\n",
            "  Attempting uninstall: numpy\n",
            "    Found existing installation: numpy 1.19.5\n",
            "    Uninstalling numpy-1.19.5:\n",
            "      Successfully uninstalled numpy-1.19.5\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "tensorflow 2.5.0 requires numpy~=1.19.2, but you have numpy 1.17.5 which is incompatible.\n",
            "kapre 0.3.5 requires numpy>=1.18.5, but you have numpy 1.17.5 which is incompatible.\n",
            "datascience 0.10.6 requires folium==0.2.1, but you have folium 0.8.3 which is incompatible.\n",
            "albumentations 0.1.12 requires imgaug<0.2.7,>=0.2.5, but you have imgaug 0.2.9 which is incompatible.\u001b[0m\n",
            "Successfully installed numpy-1.17.5\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "numpy"
                ]
              }
            }
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9z8kgcs0E7iV",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "39fd2037-46f5-4dac-ea16-b28c544f5a60"
      },
      "source": [
        "%tensorflow_version 1.x\n",
        "!pip install tf_slim"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "TensorFlow 1.x selected.\n",
            "Requirement already satisfied: tf_slim in /usr/local/lib/python3.7/dist-packages (1.1.0)\n",
            "Requirement already satisfied: absl-py>=0.2.2 in /usr/local/lib/python3.7/dist-packages (from tf_slim) (0.12.0)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from absl-py>=0.2.2->tf_slim) (1.15.0)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gnNXNQCjdniL"
      },
      "source": [
        "\n",
        "# Number of training steps - 1000 will train very quickly, but more steps will increase accuracy.\n",
        "\n",
        "num_steps = 5000  # A step means using a single batch of data. larger batch, less steps required\n",
        "#60000 steps is required to train our example sign language dataset, less or more may be required based on your custom datasets needs\n",
        "\n",
        "#Number of evaluation steps.\n",
        "num_eval_steps = 50\n",
        "#Batch size 24 is a setting that generally works well. can be changed higher or lower \n",
        "MODELS_CONFIG = {\n",
        "        'ssd_mobilenet_v2': {\n",
        "        'model_name': 'ssd_mobilenet_v2_coco_2018_03_29',\n",
        "        'pipeline_file': 'ssd_mobilenet_v2_coco.config',\n",
        "        'batch_size': 24\n",
        "    }\n",
        "}\n",
        "selected_model = 'ssd_mobilenet_v2'\n",
        "\n",
        "# Name of the object detection model to use.\n",
        "MODEL = MODELS_CONFIG[selected_model]['model_name']\n",
        "\n",
        "# Name of the pipline file in tensorflow object detection API.\n",
        "pipeline_file = MODELS_CONFIG[selected_model]['pipeline_file']\n",
        "\n",
        "# Training batch size fits in Colab's GPU memory for selected model.\n",
        "batch_size = MODELS_CONFIG[selected_model]['batch_size']"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bI8__uNS8-ns"
      },
      "source": [
        "# Install Tensorflow Object Detection API\n",
        "\n",
        "Clone TF models which contains the Object Detection API; also install the required dependencies\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ecpHEnka8Kix",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5df638fc-ae4b-45e0-a048-02019c4c3403"
      },
      "source": [
        "# %%capture\n",
        "%cd /content\n",
        "!git clone --quiet https://github.com/tensorflow/models.git\n",
        "%cd /content/models/\n",
        "!git checkout 58d19c67e1d30d905dd5c6e5092348658fed80af\n",
        "!apt-get update && apt-get install -qq protobuf-compiler python-pil python-lxml python-tk\n",
        "!pip install -q Cython contextlib2 pillow lxml matplotlib\n",
        "!pip install -q pycocotools\n",
        "%cd /content/models/research\n",
        "!protoc object_detection/protos/*.proto --python_out=.\n",
        "import os\n",
        "os.environ['PYTHONPATH'] += ':/content/models/research/:/content/models/research/slim/'\n",
        "!python object_detection/builders/model_builder_test.py"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content\n",
            "/content/models\n",
            "Note: checking out '58d19c67e1d30d905dd5c6e5092348658fed80af'.\n",
            "\n",
            "You are in 'detached HEAD' state. You can look around, make experimental\n",
            "changes and commit them, and you can discard any commits you make in this\n",
            "state without impacting any branches by performing another checkout.\n",
            "\n",
            "If you want to create a new branch to retain commits you create, you may\n",
            "do so (now or later) by using -b with the checkout command again. Example:\n",
            "\n",
            "  git checkout -b <new-branch-name>\n",
            "\n",
            "HEAD is now at 58d19c67 Internal change\n",
            "Get:1 https://cloud.r-project.org/bin/linux/ubuntu bionic-cran40/ InRelease [3,626 B]\n",
            "Ign:2 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu1804/x86_64  InRelease\n",
            "Get:3 https://cloud.r-project.org/bin/linux/ubuntu bionic-cran40/ Packages [62.9 kB]\n",
            "Get:4 http://security.ubuntu.com/ubuntu bionic-security InRelease [88.7 kB]\n",
            "Ign:5 https://developer.download.nvidia.com/compute/machine-learning/repos/ubuntu1804/x86_64  InRelease\n",
            "Get:6 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu1804/x86_64  Release [697 B]\n",
            "Hit:7 https://developer.download.nvidia.com/compute/machine-learning/repos/ubuntu1804/x86_64  Release\n",
            "Get:8 http://ppa.launchpad.net/c2d4u.team/c2d4u4.0+/ubuntu bionic InRelease [15.9 kB]\n",
            "Hit:9 http://archive.ubuntu.com/ubuntu bionic InRelease\n",
            "Get:10 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu1804/x86_64  Release.gpg [836 B]\n",
            "Get:12 http://archive.ubuntu.com/ubuntu bionic-updates InRelease [88.7 kB]\n",
            "Hit:13 http://ppa.launchpad.net/cran/libgit2/ubuntu bionic InRelease\n",
            "Get:14 http://archive.ubuntu.com/ubuntu bionic-backports InRelease [74.6 kB]\n",
            "Hit:15 http://ppa.launchpad.net/deadsnakes/ppa/ubuntu bionic InRelease\n",
            "Get:16 http://security.ubuntu.com/ubuntu bionic-security/main amd64 Packages [2,263 kB]\n",
            "Ign:17 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu1804/x86_64  Packages\n",
            "Get:17 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu1804/x86_64  Packages [695 kB]\n",
            "Get:18 http://ppa.launchpad.net/graphics-drivers/ppa/ubuntu bionic InRelease [21.3 kB]\n",
            "Get:19 http://archive.ubuntu.com/ubuntu bionic-updates/main amd64 Packages [2,698 kB]\n",
            "Get:20 http://security.ubuntu.com/ubuntu bionic-security/restricted amd64 Packages [510 kB]\n",
            "Get:21 http://security.ubuntu.com/ubuntu bionic-security/universe amd64 Packages [1,420 kB]\n",
            "Get:22 http://ppa.launchpad.net/c2d4u.team/c2d4u4.0+/ubuntu bionic/main Sources [1,786 kB]\n",
            "Get:23 http://security.ubuntu.com/ubuntu bionic-security/multiverse amd64 Packages [26.7 kB]\n",
            "Get:24 http://archive.ubuntu.com/ubuntu bionic-updates/restricted amd64 Packages [544 kB]\n",
            "Get:25 http://archive.ubuntu.com/ubuntu bionic-updates/universe amd64 Packages [2,195 kB]\n",
            "Get:26 http://archive.ubuntu.com/ubuntu bionic-updates/multiverse amd64 Packages [39.4 kB]\n",
            "Get:27 http://ppa.launchpad.net/c2d4u.team/c2d4u4.0+/ubuntu bionic/main amd64 Packages [914 kB]\n",
            "Get:28 http://ppa.launchpad.net/graphics-drivers/ppa/ubuntu bionic/main amd64 Packages [44.1 kB]\n",
            "Fetched 13.5 MB in 7s (1,871 kB/s)\n",
            "Reading package lists... Done\n",
            "Selecting previously unselected package python-bs4.\n",
            "(Reading database ... 160837 files and directories currently installed.)\n",
            "Preparing to unpack .../0-python-bs4_4.6.0-1_all.deb ...\n",
            "Unpacking python-bs4 (4.6.0-1) ...\n",
            "Selecting previously unselected package python-pkg-resources.\n",
            "Preparing to unpack .../1-python-pkg-resources_39.0.1-2_all.deb ...\n",
            "Unpacking python-pkg-resources (39.0.1-2) ...\n",
            "Selecting previously unselected package python-chardet.\n",
            "Preparing to unpack .../2-python-chardet_3.0.4-1_all.deb ...\n",
            "Unpacking python-chardet (3.0.4-1) ...\n",
            "Selecting previously unselected package python-six.\n",
            "Preparing to unpack .../3-python-six_1.11.0-2_all.deb ...\n",
            "Unpacking python-six (1.11.0-2) ...\n",
            "Selecting previously unselected package python-webencodings.\n",
            "Preparing to unpack .../4-python-webencodings_0.5-2_all.deb ...\n",
            "Unpacking python-webencodings (0.5-2) ...\n",
            "Selecting previously unselected package python-html5lib.\n",
            "Preparing to unpack .../5-python-html5lib_0.999999999-1_all.deb ...\n",
            "Unpacking python-html5lib (0.999999999-1) ...\n",
            "Selecting previously unselected package python-lxml:amd64.\n",
            "Preparing to unpack .../6-python-lxml_4.2.1-1ubuntu0.4_amd64.deb ...\n",
            "Unpacking python-lxml:amd64 (4.2.1-1ubuntu0.4) ...\n",
            "Selecting previously unselected package python-olefile.\n",
            "Preparing to unpack .../7-python-olefile_0.45.1-1_all.deb ...\n",
            "Unpacking python-olefile (0.45.1-1) ...\n",
            "Selecting previously unselected package python-pil:amd64.\n",
            "Preparing to unpack .../8-python-pil_5.1.0-1ubuntu0.6_amd64.deb ...\n",
            "Unpacking python-pil:amd64 (5.1.0-1ubuntu0.6) ...\n",
            "Setting up python-pkg-resources (39.0.1-2) ...\n",
            "Setting up python-six (1.11.0-2) ...\n",
            "Setting up python-bs4 (4.6.0-1) ...\n",
            "Setting up python-lxml:amd64 (4.2.1-1ubuntu0.4) ...\n",
            "Setting up python-olefile (0.45.1-1) ...\n",
            "Setting up python-pil:amd64 (5.1.0-1ubuntu0.6) ...\n",
            "Setting up python-webencodings (0.5-2) ...\n",
            "Setting up python-chardet (3.0.4-1) ...\n",
            "Setting up python-html5lib (0.999999999-1) ...\n",
            "Processing triggers for man-db (2.8.3-2ubuntu0.1) ...\n",
            "/content/models/research\n",
            "object_detection/protos/input_reader.proto: warning: Import object_detection/protos/image_resizer.proto but not used.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mT0asaLNN1Vz",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9cad2e49-1f9e-4d62-9f8a-e056ea820584"
      },
      "source": [
        "import os\n",
        "\n",
        "repo_url = 'https://github.com/roboflow-ai/tensorflow-object-detection-faster-rcnn'\n",
        "\n",
        "%cd /content\n",
        "\n",
        "repo_dir_path = os.path.abspath(os.path.join('.', os.path.basename(repo_url)))\n",
        "\n",
        "!git clone {repo_url}\n",
        "%cd {repo_dir_path}\n",
        "!git pull\n"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content\n",
            "Cloning into 'tensorflow-object-detection-faster-rcnn'...\n",
            "remote: Enumerating objects: 885, done.\u001b[K\n",
            "remote: Total 885 (delta 0), reused 0 (delta 0), pack-reused 885\n",
            "Receiving objects: 100% (885/885), 24.83 MiB | 20.91 MiB/s, done.\n",
            "Resolving deltas: 100% (428/428), done.\n",
            "/content/tensorflow-object-detection-faster-rcnn\n",
            "Already up to date.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "u-k7uGThXlny"
      },
      "source": [
        "## Prepare `tfrecord` files\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HcJhUwgCIKpC",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7325011f-d972-44ce-9ed4-b64974b0d92f"
      },
      "source": [
        "%cd /content/tensorflow-object-detection-faster-rcnn/data\n",
        "\n",
        "!curl -L \"https://app.roboflow.com/ds/1ZNCtHrC3G?key=tiQ1PabKYN\" > roboflow.zip; unzip roboflow.zip; rm roboflow.zip"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/tensorflow-object-detection-faster-rcnn/data\n",
            "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
            "                                 Dload  Upload   Total   Spent    Left  Speed\n",
            "100   891  100   891    0     0    895      0 --:--:-- --:--:-- --:--:--   894\n",
            "100 73.0M  100 73.0M    0     0  26.7M      0  0:00:02  0:00:02 --:--:-- 47.6M\n",
            "Archive:  roboflow.zip\n",
            " extracting: README.roboflow.txt     \n",
            "   creating: test/\n",
            " extracting: test/bus.tfrecord       \n",
            " extracting: test/bus_label_map.pbtxt  \n",
            "   creating: train/\n",
            " extracting: train/bus.tfrecord      \n",
            " extracting: train/bus_label_map.pbtxt  \n",
            "   creating: valid/\n",
            " extracting: valid/bus.tfrecord      \n",
            " extracting: valid/bus_label_map.pbtxt  \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "g4K8uaumM9zo"
      },
      "source": [
        "#RENAME Based on your annotation type - In this example our annotation type is \"letters\"\n",
        "#RENAME to the file path based on your download above ^^\n",
        "test_record_fname = '/content/tensorflow-object-detection-faster-rcnn/data/test/bus.tfrecord'\n",
        "train_record_fname = '/content/tensorflow-object-detection-faster-rcnn/data/train/bus.tfrecord'\n",
        "label_map_pbtxt_fname = '/content/tensorflow-object-detection-faster-rcnn/data/train/bus_label_map.pbtxt'"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RzMxk7UWyS6g",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "508c31cc-2e94-4c79-fe29-05c5206bf24a"
      },
      "source": [
        "#double check that our class names came through\n",
        "#Rename based on your data above^^\n",
        "%cat '/content/tensorflow-object-detection-faster-rcnn/data/train/bus_label_map.pbtxt'"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "item {\n",
            "    name: \"bus\",\n",
            "    id: 1,\n",
            "    display_name: \"bus\"\n",
            "}\n",
            "item {\n",
            "    name: \"front door\",\n",
            "    id: 2,\n",
            "    display_name: \"front door\"\n",
            "}\n",
            "item {\n",
            "    name: \"rear door\",\n",
            "    id: 3,\n",
            "    display_name: \"rear door\"\n",
            "}\n",
            "item {\n",
            "    name: \"rout\",\n",
            "    id: 4,\n",
            "    display_name: \"rout\"\n",
            "}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0MpYFYzNNumA",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e5b4e583-5d55-4778-f685-7ee12fe283d0"
      },
      "source": [
        "!ls '/content/tensorflow-object-detection-faster-rcnn/data/'"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "FYI.txt  README.roboflow.txt  test  train  valid\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iCNYAaC7w6N8"
      },
      "source": [
        "## Download the Mobilenet SSD v2 Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "orDCj6ihgUMR",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e35bb342-7d05-4a4b-994d-a1ce76f9c21f"
      },
      "source": [
        "%cd /content/models/research\n",
        "\n",
        "import os\n",
        "import shutil\n",
        "import glob\n",
        "import urllib.request\n",
        "import tarfile\n",
        "MODEL_FILE = MODEL + '.tar.gz'\n",
        "DOWNLOAD_BASE = 'http://download.tensorflow.org/models/object_detection/'\n",
        "DEST_DIR = '/content/models/research/pretrained_model'\n",
        "\n",
        "if not (os.path.exists(MODEL_FILE)):\n",
        "    urllib.request.urlretrieve(DOWNLOAD_BASE + MODEL_FILE, MODEL_FILE)\n",
        "\n",
        "tar = tarfile.open(MODEL_FILE)\n",
        "tar.extractall()\n",
        "tar.close()\n",
        "\n",
        "os.remove(MODEL_FILE)\n",
        "if (os.path.exists(DEST_DIR)):\n",
        "    shutil.rmtree(DEST_DIR)\n",
        "os.rename(MODEL, DEST_DIR)\n",
        "!echo {DEST_DIR}\n",
        "!ls -alh {DEST_DIR}"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/models/research\n",
            "/content/models/research/pretrained_model\n",
            "total 135M\n",
            "drwxr-xr-x  3 345018 89939 4.0K Mar 30  2018 .\n",
            "drwxr-xr-x 63 root   root  4.0K Aug  5 09:40 ..\n",
            "-rw-r--r--  1 345018 89939   77 Mar 30  2018 checkpoint\n",
            "-rw-r--r--  1 345018 89939  67M Mar 30  2018 frozen_inference_graph.pb\n",
            "-rw-r--r--  1 345018 89939  65M Mar 30  2018 model.ckpt.data-00000-of-00001\n",
            "-rw-r--r--  1 345018 89939  15K Mar 30  2018 model.ckpt.index\n",
            "-rw-r--r--  1 345018 89939 3.4M Mar 30  2018 model.ckpt.meta\n",
            "-rw-r--r--  1 345018 89939 4.2K Mar 30  2018 pipeline.config\n",
            "drwxr-xr-x  3 345018 89939 4.0K Mar 30  2018 saved_model\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UHnxlfRznPP3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "46523c66-ff8a-43de-d71e-fc1d90b32e09"
      },
      "source": [
        "#TF pretrained model checkpoint\n",
        "fine_tune_checkpoint = os.path.join(DEST_DIR, \"model.ckpt\")\n",
        "fine_tune_checkpoint"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'/content/models/research/pretrained_model/model.ckpt'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MvwtHlLOeRJD"
      },
      "source": [
        "## Configuring a Training Pipeline"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dIhw7IdpLuiU"
      },
      "source": [
        "import os\n",
        "pipeline_fname = os.path.join('/content/models/research/object_detection/samples/configs/', pipeline_file)\n",
        "\n",
        "assert os.path.isfile(pipeline_fname), '`{}` not exist'.format(pipeline_fname)\n",
        "def get_num_classes(pbtxt_fname):\n",
        "    from object_detection.utils import label_map_util\n",
        "    label_map = label_map_util.load_labelmap(pbtxt_fname)\n",
        "    categories = label_map_util.convert_label_map_to_categories(\n",
        "        label_map, max_num_classes=90, use_display_name=True)\n",
        "    category_index = label_map_util.create_category_index(categories)\n",
        "    return len(category_index.keys())"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YjtCbLF2i0wI",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7656a957-0896-4f04-ff10-9ff3f9e97e73"
      },
      "source": [
        "import re\n",
        "iou_threshold = 0.50\n",
        "num_classes = get_num_classes(label_map_pbtxt_fname)\n",
        "with open(pipeline_fname) as f:\n",
        "    print(pipeline_fname)\n",
        "    s = f.read()\n",
        "with open(pipeline_fname, 'w') as f:\n",
        "    \n",
        "    # fine_tune_checkpoint\n",
        "    s = re.sub('fine_tune_checkpoint: \".*?\"',\n",
        "               'fine_tune_checkpoint: \"{}\"'.format(fine_tune_checkpoint), s)\n",
        "    \n",
        "    # tfrecord files train and test.\n",
        "    s = re.sub(\n",
        "        '(input_path: \".*?)(train.record)(.*?\")', 'input_path: \"{}\"'.format(train_record_fname), s)\n",
        "    s = re.sub(\n",
        "        '(input_path: \".*?)(val.record)(.*?\")', 'input_path: \"{}\"'.format(test_record_fname), s)\n",
        "\n",
        "    # label_map_path\n",
        "    s = re.sub(\n",
        "        'label_map_path: \".*?\"', 'label_map_path: \"{}\"'.format(label_map_pbtxt_fname), s)\n",
        "\n",
        "    # Set training batch_size.\n",
        "    s = re.sub('batch_size: [0-9]+',\n",
        "               'batch_size: {}'.format(batch_size), s)\n",
        "\n",
        "    # Set training steps, num_steps\n",
        "    s = re.sub('num_steps: [0-9]+',\n",
        "               'num_steps: {}'.format(num_steps), s)\n",
        "    \n",
        "    # Set number of classes num_classes.\n",
        "    s = re.sub('num_classes: [0-9]+',\n",
        "               'num_classes: {}'.format(num_classes), s)\n",
        "    # Set number of classes num_classes.\n",
        "    s = re.sub('iou_threshold: [0-9].[0-9]+',\n",
        "               'iou_threshold: {}'.format(iou_threshold), s)\n",
        "    \n",
        "    f.write(s)"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/models/research/object_detection/samples/configs/ssd_mobilenet_v2_coco.config\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GH0MEEanocn6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c77f115b-36b6-4be2-d938-93c998e1947d"
      },
      "source": [
        "# #Have a look at the config file with various settings\n",
        "!cat {pipeline_fname}"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "# SSD with Mobilenet v2 configuration for MSCOCO Dataset.\n",
            "# Users should configure the fine_tune_checkpoint field in the train config as\n",
            "# well as the label_map_path and input_path fields in the train_input_reader and\n",
            "# eval_input_reader. Search for \"PATH_TO_BE_CONFIGURED\" to find the fields that\n",
            "# should be configured.\n",
            "\n",
            "model {\n",
            "  ssd {\n",
            "    num_classes: 4\n",
            "    box_coder {\n",
            "      faster_rcnn_box_coder {\n",
            "        y_scale: 10.0\n",
            "        x_scale: 10.0\n",
            "        height_scale: 5.0\n",
            "        width_scale: 5.0\n",
            "      }\n",
            "    }\n",
            "    matcher {\n",
            "      argmax_matcher {\n",
            "        matched_threshold: 0.5\n",
            "        unmatched_threshold: 0.5\n",
            "        ignore_thresholds: false\n",
            "        negatives_lower_than_unmatched: true\n",
            "        force_match_for_each_row: true\n",
            "      }\n",
            "    }\n",
            "    similarity_calculator {\n",
            "      iou_similarity {\n",
            "      }\n",
            "    }\n",
            "    anchor_generator {\n",
            "      ssd_anchor_generator {\n",
            "        num_layers: 6\n",
            "        min_scale: 0.2\n",
            "        max_scale: 0.95\n",
            "        aspect_ratios: 1.0\n",
            "        aspect_ratios: 2.0\n",
            "        aspect_ratios: 0.5\n",
            "        aspect_ratios: 3.0\n",
            "        aspect_ratios: 0.3333\n",
            "      }\n",
            "    }\n",
            "    image_resizer {\n",
            "      fixed_shape_resizer {\n",
            "        height: 300\n",
            "        width: 300\n",
            "      }\n",
            "    }\n",
            "    box_predictor {\n",
            "      convolutional_box_predictor {\n",
            "        min_depth: 0\n",
            "        max_depth: 0\n",
            "        num_layers_before_predictor: 0\n",
            "        use_dropout: false\n",
            "        dropout_keep_probability: 0.8\n",
            "        kernel_size: 1\n",
            "        box_code_size: 4\n",
            "        apply_sigmoid_to_scores: false\n",
            "        conv_hyperparams {\n",
            "          activation: RELU_6,\n",
            "          regularizer {\n",
            "            l2_regularizer {\n",
            "              weight: 0.00004\n",
            "            }\n",
            "          }\n",
            "          initializer {\n",
            "            truncated_normal_initializer {\n",
            "              stddev: 0.03\n",
            "              mean: 0.0\n",
            "            }\n",
            "          }\n",
            "          batch_norm {\n",
            "            train: true,\n",
            "            scale: true,\n",
            "            center: true,\n",
            "            decay: 0.9997,\n",
            "            epsilon: 0.001,\n",
            "          }\n",
            "        }\n",
            "      }\n",
            "    }\n",
            "    feature_extractor {\n",
            "      type: 'ssd_mobilenet_v2'\n",
            "      min_depth: 16\n",
            "      depth_multiplier: 1.0\n",
            "      conv_hyperparams {\n",
            "        activation: RELU_6,\n",
            "        regularizer {\n",
            "          l2_regularizer {\n",
            "            weight: 0.00004\n",
            "          }\n",
            "        }\n",
            "        initializer {\n",
            "          truncated_normal_initializer {\n",
            "            stddev: 0.03\n",
            "            mean: 0.0\n",
            "          }\n",
            "        }\n",
            "        batch_norm {\n",
            "          train: true,\n",
            "          scale: true,\n",
            "          center: true,\n",
            "          decay: 0.9997,\n",
            "          epsilon: 0.001,\n",
            "        }\n",
            "      }\n",
            "    }\n",
            "    loss {\n",
            "      classification_loss {\n",
            "        weighted_sigmoid {\n",
            "        }\n",
            "      }\n",
            "      localization_loss {\n",
            "        weighted_smooth_l1 {\n",
            "        }\n",
            "      }\n",
            "      hard_example_miner {\n",
            "        num_hard_examples: 3000\n",
            "        iou_threshold: 0.5\n",
            "        loss_type: CLASSIFICATION\n",
            "        max_negatives_per_positive: 3\n",
            "        min_negatives_per_image: 3\n",
            "      }\n",
            "      classification_weight: 1.0\n",
            "      localization_weight: 1.0\n",
            "    }\n",
            "    normalize_loss_by_num_matches: true\n",
            "    post_processing {\n",
            "      batch_non_max_suppression {\n",
            "        score_threshold: 1e-8\n",
            "        iou_threshold: 0.5\n",
            "        max_detections_per_class: 100\n",
            "        max_total_detections: 100\n",
            "      }\n",
            "      score_converter: SIGMOID\n",
            "    }\n",
            "  }\n",
            "}\n",
            "\n",
            "train_config: {\n",
            "  batch_size: 24\n",
            "  optimizer {\n",
            "    rms_prop_optimizer: {\n",
            "      learning_rate: {\n",
            "        exponential_decay_learning_rate {\n",
            "          initial_learning_rate: 0.004\n",
            "          decay_steps: 800720\n",
            "          decay_factor: 0.95\n",
            "        }\n",
            "      }\n",
            "      momentum_optimizer_value: 0.9\n",
            "      decay: 0.9\n",
            "      epsilon: 1.0\n",
            "    }\n",
            "  }\n",
            "  fine_tune_checkpoint: \"/content/models/research/pretrained_model/model.ckpt\"\n",
            "  fine_tune_checkpoint_type:  \"detection\"\n",
            "  # Note: The below line limits the training process to 200K steps, which we\n",
            "  # empirically found to be sufficient enough to train the pets dataset. This\n",
            "  # effectively bypasses the learning rate schedule (the learning rate will\n",
            "  # never decay). Remove the below line to train indefinitely.\n",
            "  num_steps: 5000\n",
            "  data_augmentation_options {\n",
            "    random_horizontal_flip {\n",
            "    }\n",
            "  }\n",
            "  data_augmentation_options {\n",
            "    ssd_random_crop {\n",
            "    }\n",
            "  }\n",
            "}\n",
            "\n",
            "train_input_reader: {\n",
            "  tf_record_input_reader {\n",
            "    input_path: \"/content/tensorflow-object-detection-faster-rcnn/data/train/bus.tfrecord\"\n",
            "  }\n",
            "  label_map_path: \"/content/tensorflow-object-detection-faster-rcnn/data/train/bus_label_map.pbtxt\"\n",
            "}\n",
            "\n",
            "eval_config: {\n",
            "  num_examples: 8000\n",
            "  # Note: The below line limits the evaluation process to 10 evaluations.\n",
            "  # Remove the below line to evaluate indefinitely.\n",
            "  max_evals: 10\n",
            "}\n",
            "\n",
            "eval_input_reader: {\n",
            "  tf_record_input_reader {\n",
            "    input_path: \"/content/tensorflow-object-detection-faster-rcnn/data/test/bus.tfrecord\"\n",
            "  }\n",
            "  label_map_path: \"/content/tensorflow-object-detection-faster-rcnn/data/train/bus_label_map.pbtxt\"\n",
            "  shuffle: false\n",
            "  num_readers: 1\n",
            "}"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JDddx2rPfex9"
      },
      "source": [
        "# Train Custom Mobilenet Model\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CjDHjhKQofT5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3f41ba76-ab31-4862-ea9c-830a8a24b7d9"
      },
      "source": [
        "model_dir = 'training/'\n",
        "# Optionally remove content in output model directory for a fresh start.\n",
        "# !rm -rf {model_dir}\n",
        "# os.makedirs(model_dir, exist_ok=True)\n",
        "!python /content/models/research/object_detection/model_main.py \\\n",
        "    --pipeline_config_path={pipeline_fname} \\\n",
        "    --model_dir={model_dir} \\\n",
        "    --alsologtostderr \\\n",
        "    --num_train_steps={num_steps} \\\n",
        "    --num_eval_steps={num_eval_steps}\n",
        "\n",
        "#training will take a while (the TF OD library is not heavily optimized for speed on GPU), watch the mAP metrics rise, you can quit training early when you think your model has maxed out performance"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Forced number of epochs for all eval validations to be 1.\n",
            "W0805 09:41:03.362477 140452147025792 model_lib.py:717] Forced number of epochs for all eval validations to be 1.\n",
            "INFO:tensorflow:Maybe overwriting train_steps: 5000\n",
            "I0805 09:41:03.362741 140452147025792 config_util.py:552] Maybe overwriting train_steps: 5000\n",
            "INFO:tensorflow:Maybe overwriting use_bfloat16: False\n",
            "I0805 09:41:03.362879 140452147025792 config_util.py:552] Maybe overwriting use_bfloat16: False\n",
            "INFO:tensorflow:Maybe overwriting sample_1_of_n_eval_examples: 1\n",
            "I0805 09:41:03.363020 140452147025792 config_util.py:552] Maybe overwriting sample_1_of_n_eval_examples: 1\n",
            "INFO:tensorflow:Maybe overwriting eval_num_epochs: 1\n",
            "I0805 09:41:03.363157 140452147025792 config_util.py:552] Maybe overwriting eval_num_epochs: 1\n",
            "INFO:tensorflow:Maybe overwriting load_pretrained: True\n",
            "I0805 09:41:03.363285 140452147025792 config_util.py:552] Maybe overwriting load_pretrained: True\n",
            "INFO:tensorflow:Ignoring config override key: load_pretrained\n",
            "I0805 09:41:03.363431 140452147025792 config_util.py:562] Ignoring config override key: load_pretrained\n",
            "WARNING:tensorflow:Expected number of evaluation epochs is 1, but instead encountered `eval_on_train_input_config.num_epochs` = 0. Overwriting `num_epochs` to 1.\n",
            "W0805 09:41:03.363764 140452147025792 model_lib.py:733] Expected number of evaluation epochs is 1, but instead encountered `eval_on_train_input_config.num_epochs` = 0. Overwriting `num_epochs` to 1.\n",
            "INFO:tensorflow:create_estimator_and_inputs: use_tpu False, export_to_tpu False\n",
            "I0805 09:41:03.363919 140452147025792 model_lib.py:768] create_estimator_and_inputs: use_tpu False, export_to_tpu False\n",
            "INFO:tensorflow:Using config: {'_model_dir': 'training/', '_tf_random_seed': None, '_save_summary_steps': 100, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': allow_soft_placement: true\n",
            "graph_options {\n",
            "  rewrite_options {\n",
            "    meta_optimizer_iterations: ONE\n",
            "  }\n",
            "}\n",
            ", '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 100, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_experimental_max_worker_delay_secs': None, '_session_creation_timeout_secs': 7200, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x7fbd239bb150>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}\n",
            "I0805 09:41:03.364427 140452147025792 estimator.py:212] Using config: {'_model_dir': 'training/', '_tf_random_seed': None, '_save_summary_steps': 100, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': allow_soft_placement: true\n",
            "graph_options {\n",
            "  rewrite_options {\n",
            "    meta_optimizer_iterations: ONE\n",
            "  }\n",
            "}\n",
            ", '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 100, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_experimental_max_worker_delay_secs': None, '_session_creation_timeout_secs': 7200, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x7fbd239bb150>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}\n",
            "WARNING:tensorflow:Estimator's model_fn (<function create_model_fn.<locals>.model_fn at 0x7fbd23fb5f80>) includes params argument, but params are not passed to Estimator.\n",
            "W0805 09:41:03.364714 140452147025792 model_fn.py:630] Estimator's model_fn (<function create_model_fn.<locals>.model_fn at 0x7fbd23fb5f80>) includes params argument, but params are not passed to Estimator.\n",
            "INFO:tensorflow:Not using Distribute Coordinator.\n",
            "I0805 09:41:03.365171 140452147025792 estimator_training.py:186] Not using Distribute Coordinator.\n",
            "INFO:tensorflow:Running training and evaluation locally (non-distributed).\n",
            "I0805 09:41:03.365408 140452147025792 training.py:612] Running training and evaluation locally (non-distributed).\n",
            "INFO:tensorflow:Start train and evaluate loop. The evaluate will happen after every checkpoint. Checkpoint frequency is determined based on RunConfig arguments: save_checkpoints_steps None or save_checkpoints_secs 600.\n",
            "I0805 09:41:03.365740 140452147025792 training.py:700] Start train and evaluate loop. The evaluate will happen after every checkpoint. Checkpoint frequency is determined based on RunConfig arguments: save_checkpoints_steps None or save_checkpoints_secs 600.\n",
            "WARNING:tensorflow:From /tensorflow-1.15.2/python3.7/tensorflow_core/python/training/training_util.py:236: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.\n",
            "W0805 09:41:03.381428 140452147025792 deprecation.py:323] From /tensorflow-1.15.2/python3.7/tensorflow_core/python/training/training_util.py:236: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.\n",
            "WARNING:tensorflow:num_readers has been reduced to 1 to match input file shards.\n",
            "W0805 09:41:03.411457 140452147025792 dataset_builder.py:83] num_readers has been reduced to 1 to match input file shards.\n",
            "WARNING:tensorflow:From /content/models/research/object_detection/builders/dataset_builder.py:100: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.\n",
            "W0805 09:41:03.417540 140452147025792 deprecation.py:323] From /content/models/research/object_detection/builders/dataset_builder.py:100: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.\n",
            "WARNING:tensorflow:From /content/models/research/object_detection/builders/dataset_builder.py:175: DatasetV1.map_with_legacy_function (from tensorflow.python.data.ops.dataset_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use `tf.data.Dataset.map()\n",
            "W0805 09:41:03.439912 140452147025792 deprecation.py:323] From /content/models/research/object_detection/builders/dataset_builder.py:175: DatasetV1.map_with_legacy_function (from tensorflow.python.data.ops.dataset_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use `tf.data.Dataset.map()\n",
            "WARNING:tensorflow:Entity <bound method TfExampleDecoder.decode of <object_detection.data_decoders.tf_example_decoder.TfExampleDecoder object at 0x7fbd23fb6410>> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: module 'gast' has no attribute 'Index'\n",
            "W0805 09:41:03.475472 140452147025792 ag_logging.py:146] Entity <bound method TfExampleDecoder.decode of <object_detection.data_decoders.tf_example_decoder.TfExampleDecoder object at 0x7fbd23fb6410>> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: module 'gast' has no attribute 'Index'\n",
            "WARNING:tensorflow:Entity <function train_input.<locals>.transform_and_pad_input_data_fn at 0x7fbd240c6440> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: Bad argument number for Name: 3, expecting 4\n",
            "W0805 09:41:03.719905 140452147025792 ag_logging.py:146] Entity <function train_input.<locals>.transform_and_pad_input_data_fn at 0x7fbd240c6440> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: Bad argument number for Name: 3, expecting 4\n",
            "WARNING:tensorflow:From /content/models/research/object_detection/inputs.py:79: sparse_to_dense (from tensorflow.python.ops.sparse_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Create a `tf.sparse.SparseTensor` and use `tf.sparse.to_dense` instead.\n",
            "W0805 09:41:03.728075 140452147025792 deprecation.py:323] From /content/models/research/object_detection/inputs.py:79: sparse_to_dense (from tensorflow.python.ops.sparse_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Create a `tf.sparse.SparseTensor` and use `tf.sparse.to_dense` instead.\n",
            "WARNING:tensorflow:From /content/models/research/object_detection/utils/ops.py:493: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
            "W0805 09:41:03.737069 140452147025792 deprecation.py:323] From /content/models/research/object_detection/utils/ops.py:493: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
            "WARNING:tensorflow:From /content/models/research/object_detection/core/preprocessor.py:199: sample_distorted_bounding_box (from tensorflow.python.ops.image_ops_impl) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "`seed2` arg is deprecated.Use sample_distorted_bounding_box_v2 instead.\n",
            "W0805 09:41:03.845721 140452147025792 deprecation.py:323] From /content/models/research/object_detection/core/preprocessor.py:199: sample_distorted_bounding_box (from tensorflow.python.ops.image_ops_impl) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "`seed2` arg is deprecated.Use sample_distorted_bounding_box_v2 instead.\n",
            "WARNING:tensorflow:From /content/models/research/object_detection/inputs.py:260: to_float (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use `tf.cast` instead.\n",
            "W0805 09:41:04.753816 140452147025792 deprecation.py:323] From /content/models/research/object_detection/inputs.py:260: to_float (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use `tf.cast` instead.\n",
            "INFO:tensorflow:Calling model_fn.\n",
            "I0805 09:41:05.307905 140452147025792 estimator.py:1148] Calling model_fn.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/tf_slim/layers/layers.py:1089: Layer.apply (from tensorflow.python.keras.engine.base_layer) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use `layer.__call__` method instead.\n",
            "W0805 09:41:05.916880 140452147025792 deprecation.py:323] From /usr/local/lib/python3.7/dist-packages/tf_slim/layers/layers.py:1089: Layer.apply (from tensorflow.python.keras.engine.base_layer) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use `layer.__call__` method instead.\n",
            "INFO:tensorflow:depth of additional conv before box predictor: 0\n",
            "I0805 09:41:09.124209 140452147025792 convolutional_box_predictor.py:156] depth of additional conv before box predictor: 0\n",
            "INFO:tensorflow:depth of additional conv before box predictor: 0\n",
            "I0805 09:41:09.163961 140452147025792 convolutional_box_predictor.py:156] depth of additional conv before box predictor: 0\n",
            "INFO:tensorflow:depth of additional conv before box predictor: 0\n",
            "I0805 09:41:09.202543 140452147025792 convolutional_box_predictor.py:156] depth of additional conv before box predictor: 0\n",
            "INFO:tensorflow:depth of additional conv before box predictor: 0\n",
            "I0805 09:41:09.241560 140452147025792 convolutional_box_predictor.py:156] depth of additional conv before box predictor: 0\n",
            "INFO:tensorflow:depth of additional conv before box predictor: 0\n",
            "I0805 09:41:09.280593 140452147025792 convolutional_box_predictor.py:156] depth of additional conv before box predictor: 0\n",
            "INFO:tensorflow:depth of additional conv before box predictor: 0\n",
            "I0805 09:41:09.318607 140452147025792 convolutional_box_predictor.py:156] depth of additional conv before box predictor: 0\n",
            "W0805 09:41:09.373283 140452147025792 variables_helper.py:153] Variable [FeatureExtractor/MobilenetV2/layer_19_2_Conv2d_2_3x3_s2_512/weights] is available in checkpoint, but has an incompatible shape with model variable. Checkpoint shape: [[1, 1, 256, 512]], model variable shape: [[3, 3, 256, 512]]. This variable will not be initialized from the checkpoint.\n",
            "W0805 09:41:09.373532 140452147025792 variables_helper.py:153] Variable [FeatureExtractor/MobilenetV2/layer_19_2_Conv2d_3_3x3_s2_256/weights] is available in checkpoint, but has an incompatible shape with model variable. Checkpoint shape: [[1, 1, 128, 256]], model variable shape: [[3, 3, 128, 256]]. This variable will not be initialized from the checkpoint.\n",
            "W0805 09:41:09.373695 140452147025792 variables_helper.py:153] Variable [FeatureExtractor/MobilenetV2/layer_19_2_Conv2d_4_3x3_s2_256/weights] is available in checkpoint, but has an incompatible shape with model variable. Checkpoint shape: [[1, 1, 128, 256]], model variable shape: [[3, 3, 128, 256]]. This variable will not be initialized from the checkpoint.\n",
            "W0805 09:41:09.373915 140452147025792 variables_helper.py:153] Variable [FeatureExtractor/MobilenetV2/layer_19_2_Conv2d_5_3x3_s2_128/weights] is available in checkpoint, but has an incompatible shape with model variable. Checkpoint shape: [[1, 1, 64, 128]], model variable shape: [[3, 3, 64, 128]]. This variable will not be initialized from the checkpoint.\n",
            "WARNING:tensorflow:From /tensorflow-1.15.2/python3.7/tensorflow_core/python/training/rmsprop.py:119: calling Ones.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Call initializer instance with the dtype argument instead of passing it to the constructor\n",
            "W0805 09:41:18.317703 140452147025792 deprecation.py:506] From /tensorflow-1.15.2/python3.7/tensorflow_core/python/training/rmsprop.py:119: calling Ones.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Call initializer instance with the dtype argument instead of passing it to the constructor\n",
            "INFO:tensorflow:Done calling model_fn.\n",
            "I0805 09:41:26.074615 140452147025792 estimator.py:1150] Done calling model_fn.\n",
            "INFO:tensorflow:Create CheckpointSaverHook.\n",
            "I0805 09:41:26.076336 140452147025792 basic_session_run_hooks.py:541] Create CheckpointSaverHook.\n",
            "INFO:tensorflow:Graph was finalized.\n",
            "I0805 09:41:30.759497 140452147025792 monitored_session.py:240] Graph was finalized.\n",
            "2021-08-05 09:41:30.773225: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2299995000 Hz\n",
            "2021-08-05 09:41:30.773677: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x5569608e4bc0 initialized for platform Host (this does not guarantee that XLA will be used). Devices:\n",
            "2021-08-05 09:41:30.773719: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version\n",
            "2021-08-05 09:41:30.779486: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcuda.so.1\n",
            "2021-08-05 09:41:30.975638: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2021-08-05 09:41:30.976651: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x55696f3081c0 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n",
            "2021-08-05 09:41:30.976686: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Tesla K80, Compute Capability 3.7\n",
            "2021-08-05 09:41:30.977884: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2021-08-05 09:41:30.978694: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1639] Found device 0 with properties: \n",
            "name: Tesla K80 major: 3 minor: 7 memoryClockRate(GHz): 0.8235\n",
            "pciBusID: 0000:00:04.0\n",
            "2021-08-05 09:41:30.997272: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.1\n",
            "2021-08-05 09:41:31.232342: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcublas.so.10\n",
            "2021-08-05 09:41:31.375376: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcufft.so.10\n",
            "2021-08-05 09:41:31.395680: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcurand.so.10\n",
            "2021-08-05 09:41:31.664298: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusolver.so.10\n",
            "2021-08-05 09:41:31.682882: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusparse.so.10\n",
            "2021-08-05 09:41:32.186132: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudnn.so.7\n",
            "2021-08-05 09:41:32.186416: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2021-08-05 09:41:32.187292: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2021-08-05 09:41:32.188046: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1767] Adding visible gpu devices: 0\n",
            "2021-08-05 09:41:32.191372: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.1\n",
            "2021-08-05 09:41:32.193031: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1180] Device interconnect StreamExecutor with strength 1 edge matrix:\n",
            "2021-08-05 09:41:32.193065: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1186]      0 \n",
            "2021-08-05 09:41:32.193082: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1199] 0:   N \n",
            "2021-08-05 09:41:32.194850: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2021-08-05 09:41:32.195780: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2021-08-05 09:41:32.196516: W tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:39] Overriding allow_growth setting because the TF_FORCE_GPU_ALLOW_GROWTH environment variable is set. Original config value was 0.\n",
            "2021-08-05 09:41:32.196578: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1325] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 10813 MB memory) -> physical GPU (device: 0, name: Tesla K80, pci bus id: 0000:00:04.0, compute capability: 3.7)\n",
            "INFO:tensorflow:Running local_init_op.\n",
            "I0805 09:41:43.893588 140452147025792 session_manager.py:500] Running local_init_op.\n",
            "INFO:tensorflow:Done running local_init_op.\n",
            "I0805 09:41:44.399389 140452147025792 session_manager.py:502] Done running local_init_op.\n",
            "INFO:tensorflow:Saving checkpoints for 0 into training/model.ckpt.\n",
            "I0805 09:41:57.748674 140452147025792 basic_session_run_hooks.py:606] Saving checkpoints for 0 into training/model.ckpt.\n",
            "2021-08-05 09:42:11.557147: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudnn.so.7\n",
            "2021-08-05 09:42:15.594994: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcublas.so.10\n",
            "INFO:tensorflow:loss = 7.244637, step = 0\n",
            "I0805 09:42:19.554501 140452147025792 basic_session_run_hooks.py:262] loss = 7.244637, step = 0\n",
            "INFO:tensorflow:global_step/sec: 1.25241\n",
            "I0805 09:43:39.399796 140452147025792 basic_session_run_hooks.py:692] global_step/sec: 1.25241\n",
            "INFO:tensorflow:loss = 3.739062, step = 100 (79.847 sec)\n",
            "I0805 09:43:39.401066 140452147025792 basic_session_run_hooks.py:260] loss = 3.739062, step = 100 (79.847 sec)\n",
            "INFO:tensorflow:global_step/sec: 1.36671\n",
            "I0805 09:44:52.568438 140452147025792 basic_session_run_hooks.py:692] global_step/sec: 1.36671\n",
            "INFO:tensorflow:loss = 2.1506183, step = 200 (73.169 sec)\n",
            "I0805 09:44:52.569629 140452147025792 basic_session_run_hooks.py:260] loss = 2.1506183, step = 200 (73.169 sec)\n",
            "INFO:tensorflow:global_step/sec: 1.36527\n",
            "I0805 09:46:05.813932 140452147025792 basic_session_run_hooks.py:692] global_step/sec: 1.36527\n",
            "INFO:tensorflow:loss = 1.9552443, step = 300 (73.246 sec)\n",
            "I0805 09:46:05.815356 140452147025792 basic_session_run_hooks.py:260] loss = 1.9552443, step = 300 (73.246 sec)\n",
            "INFO:tensorflow:global_step/sec: 1.36957\n",
            "I0805 09:47:18.829328 140452147025792 basic_session_run_hooks.py:692] global_step/sec: 1.36957\n",
            "INFO:tensorflow:loss = 2.404312, step = 400 (73.015 sec)\n",
            "I0805 09:47:18.830579 140452147025792 basic_session_run_hooks.py:260] loss = 2.404312, step = 400 (73.015 sec)\n",
            "INFO:tensorflow:global_step/sec: 1.36373\n",
            "I0805 09:48:32.157807 140452147025792 basic_session_run_hooks.py:692] global_step/sec: 1.36373\n",
            "INFO:tensorflow:loss = 2.9037404, step = 500 (73.329 sec)\n",
            "I0805 09:48:32.159163 140452147025792 basic_session_run_hooks.py:260] loss = 2.9037404, step = 500 (73.329 sec)\n",
            "INFO:tensorflow:global_step/sec: 1.38132\n",
            "I0805 09:49:44.552400 140452147025792 basic_session_run_hooks.py:692] global_step/sec: 1.38132\n",
            "INFO:tensorflow:loss = 1.5342735, step = 600 (72.394 sec)\n",
            "I0805 09:49:44.553649 140452147025792 basic_session_run_hooks.py:260] loss = 1.5342735, step = 600 (72.394 sec)\n",
            "INFO:tensorflow:global_step/sec: 1.3544\n",
            "I0805 09:50:58.385626 140452147025792 basic_session_run_hooks.py:692] global_step/sec: 1.3544\n",
            "INFO:tensorflow:loss = 1.7135766, step = 700 (73.833 sec)\n",
            "I0805 09:50:58.386995 140452147025792 basic_session_run_hooks.py:260] loss = 1.7135766, step = 700 (73.833 sec)\n",
            "INFO:tensorflow:Saving checkpoints for 786 into training/model.ckpt.\n",
            "I0805 09:52:00.851732 140452147025792 basic_session_run_hooks.py:606] Saving checkpoints for 786 into training/model.ckpt.\n",
            "WARNING:tensorflow:Entity <bound method TfExampleDecoder.decode of <object_detection.data_decoders.tf_example_decoder.TfExampleDecoder object at 0x7fbd1070d8d0>> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: module 'gast' has no attribute 'Index'\n",
            "W0805 09:52:02.885181 140452147025792 ag_logging.py:146] Entity <bound method TfExampleDecoder.decode of <object_detection.data_decoders.tf_example_decoder.TfExampleDecoder object at 0x7fbd1070d8d0>> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: module 'gast' has no attribute 'Index'\n",
            "WARNING:tensorflow:Entity <function eval_input.<locals>.transform_and_pad_input_data_fn at 0x7fbd1b7287a0> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: Bad argument number for Name: 3, expecting 4\n",
            "W0805 09:52:03.103861 140452147025792 ag_logging.py:146] Entity <function eval_input.<locals>.transform_and_pad_input_data_fn at 0x7fbd1b7287a0> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: Bad argument number for Name: 3, expecting 4\n",
            "INFO:tensorflow:Calling model_fn.\n",
            "I0805 09:52:03.723873 140452147025792 estimator.py:1148] Calling model_fn.\n",
            "INFO:tensorflow:depth of additional conv before box predictor: 0\n",
            "I0805 09:52:06.722626 140452147025792 convolutional_box_predictor.py:156] depth of additional conv before box predictor: 0\n",
            "INFO:tensorflow:depth of additional conv before box predictor: 0\n",
            "I0805 09:52:06.764991 140452147025792 convolutional_box_predictor.py:156] depth of additional conv before box predictor: 0\n",
            "INFO:tensorflow:depth of additional conv before box predictor: 0\n",
            "I0805 09:52:06.801952 140452147025792 convolutional_box_predictor.py:156] depth of additional conv before box predictor: 0\n",
            "INFO:tensorflow:depth of additional conv before box predictor: 0\n",
            "I0805 09:52:06.839523 140452147025792 convolutional_box_predictor.py:156] depth of additional conv before box predictor: 0\n",
            "INFO:tensorflow:depth of additional conv before box predictor: 0\n",
            "I0805 09:52:06.880483 140452147025792 convolutional_box_predictor.py:156] depth of additional conv before box predictor: 0\n",
            "INFO:tensorflow:depth of additional conv before box predictor: 0\n",
            "I0805 09:52:06.918765 140452147025792 convolutional_box_predictor.py:156] depth of additional conv before box predictor: 0\n",
            "WARNING:tensorflow:From /content/models/research/object_detection/eval_util.py:830: to_int64 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use `tf.cast` instead.\n",
            "W0805 09:52:07.898757 140452147025792 deprecation.py:323] From /content/models/research/object_detection/eval_util.py:830: to_int64 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use `tf.cast` instead.\n",
            "WARNING:tensorflow:From /content/models/research/object_detection/utils/visualization_utils.py:618: py_func (from tensorflow.python.ops.script_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "tf.py_func is deprecated in TF V2. Instead, there are two\n",
            "    options available in V2.\n",
            "    - tf.py_function takes a python function which manipulates tf eager\n",
            "    tensors instead of numpy arrays. It's easy to convert a tf eager tensor to\n",
            "    an ndarray (just call tensor.numpy()) but having access to eager tensors\n",
            "    means `tf.py_function`s can use accelerators such as GPUs as well as\n",
            "    being differentiable using a gradient tape.\n",
            "    - tf.numpy_function maintains the semantics of the deprecated tf.py_func\n",
            "    (it is not differentiable, and manipulates numpy arrays). It drops the\n",
            "    stateful argument making all functions stateful.\n",
            "    \n",
            "W0805 09:52:08.152179 140452147025792 deprecation.py:323] From /content/models/research/object_detection/utils/visualization_utils.py:618: py_func (from tensorflow.python.ops.script_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "tf.py_func is deprecated in TF V2. Instead, there are two\n",
            "    options available in V2.\n",
            "    - tf.py_function takes a python function which manipulates tf eager\n",
            "    tensors instead of numpy arrays. It's easy to convert a tf eager tensor to\n",
            "    an ndarray (just call tensor.numpy()) but having access to eager tensors\n",
            "    means `tf.py_function`s can use accelerators such as GPUs as well as\n",
            "    being differentiable using a gradient tape.\n",
            "    - tf.numpy_function maintains the semantics of the deprecated tf.py_func\n",
            "    (it is not differentiable, and manipulates numpy arrays). It drops the\n",
            "    stateful argument making all functions stateful.\n",
            "    \n",
            "INFO:tensorflow:Done calling model_fn.\n",
            "I0805 09:52:08.791433 140452147025792 estimator.py:1150] Done calling model_fn.\n",
            "INFO:tensorflow:Starting evaluation at 2021-08-05T09:52:08Z\n",
            "I0805 09:52:08.812003 140452147025792 evaluation.py:255] Starting evaluation at 2021-08-05T09:52:08Z\n",
            "INFO:tensorflow:Graph was finalized.\n",
            "I0805 09:52:09.344022 140452147025792 monitored_session.py:240] Graph was finalized.\n",
            "2021-08-05 09:52:09.345334: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2021-08-05 09:52:09.346034: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1639] Found device 0 with properties: \n",
            "name: Tesla K80 major: 3 minor: 7 memoryClockRate(GHz): 0.8235\n",
            "pciBusID: 0000:00:04.0\n",
            "2021-08-05 09:52:09.346139: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.1\n",
            "2021-08-05 09:52:09.346181: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcublas.so.10\n",
            "2021-08-05 09:52:09.346228: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcufft.so.10\n",
            "2021-08-05 09:52:09.346267: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcurand.so.10\n",
            "2021-08-05 09:52:09.346304: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusolver.so.10\n",
            "2021-08-05 09:52:09.346342: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusparse.so.10\n",
            "2021-08-05 09:52:09.346394: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudnn.so.7\n",
            "2021-08-05 09:52:09.346516: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2021-08-05 09:52:09.347122: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2021-08-05 09:52:09.347677: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1767] Adding visible gpu devices: 0\n",
            "2021-08-05 09:52:09.347758: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1180] Device interconnect StreamExecutor with strength 1 edge matrix:\n",
            "2021-08-05 09:52:09.347777: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1186]      0 \n",
            "2021-08-05 09:52:09.347808: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1199] 0:   N \n",
            "2021-08-05 09:52:09.347927: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2021-08-05 09:52:09.348516: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2021-08-05 09:52:09.349041: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1325] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 10813 MB memory) -> physical GPU (device: 0, name: Tesla K80, pci bus id: 0000:00:04.0, compute capability: 3.7)\n",
            "INFO:tensorflow:Restoring parameters from training/model.ckpt-786\n",
            "I0805 09:52:09.350249 140452147025792 saver.py:1284] Restoring parameters from training/model.ckpt-786\n",
            "INFO:tensorflow:Running local_init_op.\n",
            "I0805 09:52:10.435675 140452147025792 session_manager.py:500] Running local_init_op.\n",
            "INFO:tensorflow:Done running local_init_op.\n",
            "I0805 09:52:10.604053 140452147025792 session_manager.py:502] Done running local_init_op.\n",
            "INFO:tensorflow:Performing evaluation on 72 images.\n",
            "I0805 09:52:16.772559 140450009868032 coco_evaluation.py:237] Performing evaluation on 72 images.\n",
            "creating index...\n",
            "index created!\n",
            "INFO:tensorflow:Loading and preparing annotation results...\n",
            "I0805 09:52:16.773269 140450009868032 coco_tools.py:116] Loading and preparing annotation results...\n",
            "INFO:tensorflow:DONE (t=0.00s)\n",
            "I0805 09:52:16.778248 140450009868032 coco_tools.py:138] DONE (t=0.00s)\n",
            "creating index...\n",
            "index created!\n",
            "Running per image evaluation...\n",
            "Evaluate annotation type *bbox*\n",
            "DONE (t=0.71s).\n",
            "Accumulating evaluation results...\n",
            "DONE (t=0.17s).\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.087\n",
            " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.234\n",
            " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.042\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.007\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.075\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.172\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.098\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.189\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.201\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.062\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.169\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.410\n",
            "INFO:tensorflow:Finished evaluation at 2021-08-05-09:52:17\n",
            "I0805 09:52:17.771716 140452147025792 evaluation.py:275] Finished evaluation at 2021-08-05-09:52:17\n",
            "INFO:tensorflow:Saving dict for global step 786: DetectionBoxes_Precision/mAP = 0.087429404, DetectionBoxes_Precision/mAP (large) = 0.17183857, DetectionBoxes_Precision/mAP (medium) = 0.07477449, DetectionBoxes_Precision/mAP (small) = 0.007292243, DetectionBoxes_Precision/mAP@.50IOU = 0.2336426, DetectionBoxes_Precision/mAP@.75IOU = 0.04222607, DetectionBoxes_Recall/AR@1 = 0.09811842, DetectionBoxes_Recall/AR@10 = 0.18876356, DetectionBoxes_Recall/AR@100 = 0.2006302, DetectionBoxes_Recall/AR@100 (large) = 0.40986842, DetectionBoxes_Recall/AR@100 (medium) = 0.16889368, DetectionBoxes_Recall/AR@100 (small) = 0.0625, Loss/classification_loss = 1.6331179, Loss/localization_loss = 0.9310868, Loss/regularization_loss = 0.24737483, Loss/total_loss = 2.8115795, global_step = 786, learning_rate = 0.004, loss = 2.8115795\n",
            "I0805 09:52:17.772065 140452147025792 estimator.py:2049] Saving dict for global step 786: DetectionBoxes_Precision/mAP = 0.087429404, DetectionBoxes_Precision/mAP (large) = 0.17183857, DetectionBoxes_Precision/mAP (medium) = 0.07477449, DetectionBoxes_Precision/mAP (small) = 0.007292243, DetectionBoxes_Precision/mAP@.50IOU = 0.2336426, DetectionBoxes_Precision/mAP@.75IOU = 0.04222607, DetectionBoxes_Recall/AR@1 = 0.09811842, DetectionBoxes_Recall/AR@10 = 0.18876356, DetectionBoxes_Recall/AR@100 = 0.2006302, DetectionBoxes_Recall/AR@100 (large) = 0.40986842, DetectionBoxes_Recall/AR@100 (medium) = 0.16889368, DetectionBoxes_Recall/AR@100 (small) = 0.0625, Loss/classification_loss = 1.6331179, Loss/localization_loss = 0.9310868, Loss/regularization_loss = 0.24737483, Loss/total_loss = 2.8115795, global_step = 786, learning_rate = 0.004, loss = 2.8115795\n",
            "INFO:tensorflow:Saving 'checkpoint_path' summary for global step 786: training/model.ckpt-786\n",
            "I0805 09:52:18.743072 140452147025792 estimator.py:2109] Saving 'checkpoint_path' summary for global step 786: training/model.ckpt-786\n",
            "INFO:tensorflow:global_step/sec: 1.09498\n",
            "I0805 09:52:29.711411 140452147025792 basic_session_run_hooks.py:692] global_step/sec: 1.09498\n",
            "INFO:tensorflow:loss = 2.0467563, step = 800 (91.326 sec)\n",
            "I0805 09:52:29.712701 140452147025792 basic_session_run_hooks.py:260] loss = 2.0467563, step = 800 (91.326 sec)\n",
            "INFO:tensorflow:global_step/sec: 1.37013\n",
            "I0805 09:53:42.697188 140452147025792 basic_session_run_hooks.py:692] global_step/sec: 1.37013\n",
            "INFO:tensorflow:loss = 1.3815404, step = 900 (72.986 sec)\n",
            "I0805 09:53:42.698480 140452147025792 basic_session_run_hooks.py:260] loss = 1.3815404, step = 900 (72.986 sec)\n",
            "INFO:tensorflow:global_step/sec: 1.4111\n",
            "I0805 09:54:53.564034 140452147025792 basic_session_run_hooks.py:692] global_step/sec: 1.4111\n",
            "INFO:tensorflow:loss = 0.9497414, step = 1000 (70.867 sec)\n",
            "I0805 09:54:53.565230 140452147025792 basic_session_run_hooks.py:260] loss = 0.9497414, step = 1000 (70.867 sec)\n",
            "INFO:tensorflow:global_step/sec: 1.40621\n",
            "I0805 09:56:04.677144 140452147025792 basic_session_run_hooks.py:692] global_step/sec: 1.40621\n",
            "INFO:tensorflow:loss = 1.3225383, step = 1100 (71.113 sec)\n",
            "I0805 09:56:04.678498 140452147025792 basic_session_run_hooks.py:260] loss = 1.3225383, step = 1100 (71.113 sec)\n",
            "INFO:tensorflow:global_step/sec: 1.40395\n",
            "I0805 09:57:15.904886 140452147025792 basic_session_run_hooks.py:692] global_step/sec: 1.40395\n",
            "INFO:tensorflow:loss = 1.6458397, step = 1200 (71.228 sec)\n",
            "I0805 09:57:15.906839 140452147025792 basic_session_run_hooks.py:260] loss = 1.6458397, step = 1200 (71.228 sec)\n",
            "INFO:tensorflow:global_step/sec: 1.40223\n",
            "I0805 09:58:27.219950 140452147025792 basic_session_run_hooks.py:692] global_step/sec: 1.40223\n",
            "INFO:tensorflow:loss = 1.5354189, step = 1300 (71.314 sec)\n",
            "I0805 09:58:27.221320 140452147025792 basic_session_run_hooks.py:260] loss = 1.5354189, step = 1300 (71.314 sec)\n",
            "INFO:tensorflow:global_step/sec: 1.38525\n",
            "I0805 09:59:39.408826 140452147025792 basic_session_run_hooks.py:692] global_step/sec: 1.38525\n",
            "INFO:tensorflow:loss = 1.4293925, step = 1400 (72.189 sec)\n",
            "I0805 09:59:39.410164 140452147025792 basic_session_run_hooks.py:260] loss = 1.4293925, step = 1400 (72.189 sec)\n",
            "INFO:tensorflow:global_step/sec: 1.36969\n",
            "I0805 10:00:52.418094 140452147025792 basic_session_run_hooks.py:692] global_step/sec: 1.36969\n",
            "INFO:tensorflow:loss = 1.4259806, step = 1500 (73.009 sec)\n",
            "I0805 10:00:52.419465 140452147025792 basic_session_run_hooks.py:260] loss = 1.4259806, step = 1500 (73.009 sec)\n",
            "INFO:tensorflow:Saving checkpoints for 1597 into training/model.ckpt.\n",
            "I0805 10:02:01.347874 140452147025792 basic_session_run_hooks.py:606] Saving checkpoints for 1597 into training/model.ckpt.\n",
            "WARNING:tensorflow:Entity <bound method TfExampleDecoder.decode of <object_detection.data_decoders.tf_example_decoder.TfExampleDecoder object at 0x7fbcc13facd0>> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: module 'gast' has no attribute 'Index'\n",
            "W0805 10:02:03.332908 140452147025792 ag_logging.py:146] Entity <bound method TfExampleDecoder.decode of <object_detection.data_decoders.tf_example_decoder.TfExampleDecoder object at 0x7fbcc13facd0>> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: module 'gast' has no attribute 'Index'\n",
            "WARNING:tensorflow:Entity <function eval_input.<locals>.transform_and_pad_input_data_fn at 0x7fbcbaf51170> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: Bad argument number for Name: 3, expecting 4\n",
            "W0805 10:02:03.552145 140452147025792 ag_logging.py:146] Entity <function eval_input.<locals>.transform_and_pad_input_data_fn at 0x7fbcbaf51170> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: Bad argument number for Name: 3, expecting 4\n",
            "INFO:tensorflow:Calling model_fn.\n",
            "I0805 10:02:04.201187 140452147025792 estimator.py:1148] Calling model_fn.\n",
            "INFO:tensorflow:depth of additional conv before box predictor: 0\n",
            "I0805 10:02:06.926266 140452147025792 convolutional_box_predictor.py:156] depth of additional conv before box predictor: 0\n",
            "INFO:tensorflow:depth of additional conv before box predictor: 0\n",
            "I0805 10:02:06.964937 140452147025792 convolutional_box_predictor.py:156] depth of additional conv before box predictor: 0\n",
            "INFO:tensorflow:depth of additional conv before box predictor: 0\n",
            "I0805 10:02:07.003176 140452147025792 convolutional_box_predictor.py:156] depth of additional conv before box predictor: 0\n",
            "INFO:tensorflow:depth of additional conv before box predictor: 0\n",
            "I0805 10:02:07.042522 140452147025792 convolutional_box_predictor.py:156] depth of additional conv before box predictor: 0\n",
            "INFO:tensorflow:depth of additional conv before box predictor: 0\n",
            "I0805 10:02:07.082239 140452147025792 convolutional_box_predictor.py:156] depth of additional conv before box predictor: 0\n",
            "INFO:tensorflow:depth of additional conv before box predictor: 0\n",
            "I0805 10:02:07.120773 140452147025792 convolutional_box_predictor.py:156] depth of additional conv before box predictor: 0\n",
            "INFO:tensorflow:Done calling model_fn.\n",
            "I0805 10:02:09.366779 140452147025792 estimator.py:1150] Done calling model_fn.\n",
            "INFO:tensorflow:Starting evaluation at 2021-08-05T10:02:09Z\n",
            "I0805 10:02:09.388615 140452147025792 evaluation.py:255] Starting evaluation at 2021-08-05T10:02:09Z\n",
            "INFO:tensorflow:Graph was finalized.\n",
            "I0805 10:02:09.922535 140452147025792 monitored_session.py:240] Graph was finalized.\n",
            "2021-08-05 10:02:09.923328: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2021-08-05 10:02:09.923964: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1639] Found device 0 with properties: \n",
            "name: Tesla K80 major: 3 minor: 7 memoryClockRate(GHz): 0.8235\n",
            "pciBusID: 0000:00:04.0\n",
            "2021-08-05 10:02:09.924067: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.1\n",
            "2021-08-05 10:02:09.924109: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcublas.so.10\n",
            "2021-08-05 10:02:09.924163: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcufft.so.10\n",
            "2021-08-05 10:02:09.924205: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcurand.so.10\n",
            "2021-08-05 10:02:09.924251: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusolver.so.10\n",
            "2021-08-05 10:02:09.924295: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusparse.so.10\n",
            "2021-08-05 10:02:09.924350: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudnn.so.7\n",
            "2021-08-05 10:02:09.924474: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2021-08-05 10:02:09.925079: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2021-08-05 10:02:09.925663: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1767] Adding visible gpu devices: 0\n",
            "2021-08-05 10:02:09.925820: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1180] Device interconnect StreamExecutor with strength 1 edge matrix:\n",
            "2021-08-05 10:02:09.925842: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1186]      0 \n",
            "2021-08-05 10:02:09.925857: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1199] 0:   N \n",
            "2021-08-05 10:02:09.926004: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2021-08-05 10:02:09.926633: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2021-08-05 10:02:09.927174: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1325] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 10813 MB memory) -> physical GPU (device: 0, name: Tesla K80, pci bus id: 0000:00:04.0, compute capability: 3.7)\n",
            "INFO:tensorflow:Restoring parameters from training/model.ckpt-1597\n",
            "I0805 10:02:09.928496 140452147025792 saver.py:1284] Restoring parameters from training/model.ckpt-1597\n",
            "INFO:tensorflow:Running local_init_op.\n",
            "I0805 10:02:11.100828 140452147025792 session_manager.py:500] Running local_init_op.\n",
            "INFO:tensorflow:Done running local_init_op.\n",
            "I0805 10:02:11.284939 140452147025792 session_manager.py:502] Done running local_init_op.\n",
            "INFO:tensorflow:Performing evaluation on 72 images.\n",
            "I0805 10:02:17.435781 140450009868032 coco_evaluation.py:237] Performing evaluation on 72 images.\n",
            "creating index...\n",
            "index created!\n",
            "INFO:tensorflow:Loading and preparing annotation results...\n",
            "I0805 10:02:17.436619 140450009868032 coco_tools.py:116] Loading and preparing annotation results...\n",
            "INFO:tensorflow:DONE (t=0.01s)\n",
            "I0805 10:02:17.443682 140450009868032 coco_tools.py:138] DONE (t=0.01s)\n",
            "creating index...\n",
            "index created!\n",
            "Running per image evaluation...\n",
            "Evaluate annotation type *bbox*\n",
            "DONE (t=0.83s).\n",
            "Accumulating evaluation results...\n",
            "DONE (t=0.11s).\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.130\n",
            " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.355\n",
            " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.045\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.015\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.104\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.265\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.149\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.235\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.239\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.087\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.226\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.424\n",
            "INFO:tensorflow:Finished evaluation at 2021-08-05-10:02:18\n",
            "I0805 10:02:18.499291 140452147025792 evaluation.py:275] Finished evaluation at 2021-08-05-10:02:18\n",
            "INFO:tensorflow:Saving dict for global step 1597: DetectionBoxes_Precision/mAP = 0.12977178, DetectionBoxes_Precision/mAP (large) = 0.26454487, DetectionBoxes_Precision/mAP (medium) = 0.10385579, DetectionBoxes_Precision/mAP (small) = 0.014524171, DetectionBoxes_Precision/mAP@.50IOU = 0.3551916, DetectionBoxes_Precision/mAP@.75IOU = 0.044693384, DetectionBoxes_Recall/AR@1 = 0.14869912, DetectionBoxes_Recall/AR@10 = 0.23450534, DetectionBoxes_Recall/AR@100 = 0.23945583, DetectionBoxes_Recall/AR@100 (large) = 0.4236842, DetectionBoxes_Recall/AR@100 (medium) = 0.22615595, DetectionBoxes_Recall/AR@100 (small) = 0.0875, Loss/classification_loss = 1.1531028, Loss/localization_loss = 0.54088473, Loss/regularization_loss = 0.24695094, Loss/total_loss = 1.9409385, global_step = 1597, learning_rate = 0.004, loss = 1.9409385\n",
            "I0805 10:02:18.499631 140452147025792 estimator.py:2049] Saving dict for global step 1597: DetectionBoxes_Precision/mAP = 0.12977178, DetectionBoxes_Precision/mAP (large) = 0.26454487, DetectionBoxes_Precision/mAP (medium) = 0.10385579, DetectionBoxes_Precision/mAP (small) = 0.014524171, DetectionBoxes_Precision/mAP@.50IOU = 0.3551916, DetectionBoxes_Precision/mAP@.75IOU = 0.044693384, DetectionBoxes_Recall/AR@1 = 0.14869912, DetectionBoxes_Recall/AR@10 = 0.23450534, DetectionBoxes_Recall/AR@100 = 0.23945583, DetectionBoxes_Recall/AR@100 (large) = 0.4236842, DetectionBoxes_Recall/AR@100 (medium) = 0.22615595, DetectionBoxes_Recall/AR@100 (small) = 0.0875, Loss/classification_loss = 1.1531028, Loss/localization_loss = 0.54088473, Loss/regularization_loss = 0.24695094, Loss/total_loss = 1.9409385, global_step = 1597, learning_rate = 0.004, loss = 1.9409385\n",
            "INFO:tensorflow:Saving 'checkpoint_path' summary for global step 1597: training/model.ckpt-1597\n",
            "I0805 10:02:18.503021 140452147025792 estimator.py:2109] Saving 'checkpoint_path' summary for global step 1597: training/model.ckpt-1597\n",
            "INFO:tensorflow:global_step/sec: 1.12254\n",
            "I0805 10:02:21.502168 140452147025792 basic_session_run_hooks.py:692] global_step/sec: 1.12254\n",
            "INFO:tensorflow:loss = 1.2596959, step = 1600 (89.084 sec)\n",
            "I0805 10:02:21.503322 140452147025792 basic_session_run_hooks.py:260] loss = 1.2596959, step = 1600 (89.084 sec)\n",
            "INFO:tensorflow:global_step/sec: 1.38336\n",
            "I0805 10:03:33.790099 140452147025792 basic_session_run_hooks.py:692] global_step/sec: 1.38336\n",
            "INFO:tensorflow:loss = 1.4062747, step = 1700 (72.288 sec)\n",
            "I0805 10:03:33.791522 140452147025792 basic_session_run_hooks.py:260] loss = 1.4062747, step = 1700 (72.288 sec)\n",
            "INFO:tensorflow:global_step/sec: 1.3796\n",
            "I0805 10:04:46.275050 140452147025792 basic_session_run_hooks.py:692] global_step/sec: 1.3796\n",
            "INFO:tensorflow:loss = 1.5029975, step = 1800 (72.485 sec)\n",
            "I0805 10:04:46.276171 140452147025792 basic_session_run_hooks.py:260] loss = 1.5029975, step = 1800 (72.485 sec)\n",
            "INFO:tensorflow:global_step/sec: 1.36091\n",
            "I0805 10:05:59.755185 140452147025792 basic_session_run_hooks.py:692] global_step/sec: 1.36091\n",
            "INFO:tensorflow:loss = 1.0285807, step = 1900 (73.480 sec)\n",
            "I0805 10:05:59.756515 140452147025792 basic_session_run_hooks.py:260] loss = 1.0285807, step = 1900 (73.480 sec)\n",
            "INFO:tensorflow:global_step/sec: 1.37777\n",
            "I0805 10:07:12.336564 140452147025792 basic_session_run_hooks.py:692] global_step/sec: 1.37777\n",
            "INFO:tensorflow:loss = 1.389662, step = 2000 (72.581 sec)\n",
            "I0805 10:07:12.337672 140452147025792 basic_session_run_hooks.py:260] loss = 1.389662, step = 2000 (72.581 sec)\n",
            "INFO:tensorflow:global_step/sec: 1.3721\n",
            "I0805 10:08:25.217743 140452147025792 basic_session_run_hooks.py:692] global_step/sec: 1.3721\n",
            "INFO:tensorflow:loss = 1.0228537, step = 2100 (72.881 sec)\n",
            "I0805 10:08:25.219062 140452147025792 basic_session_run_hooks.py:260] loss = 1.0228537, step = 2100 (72.881 sec)\n",
            "INFO:tensorflow:global_step/sec: 1.38772\n",
            "I0805 10:09:37.278610 140452147025792 basic_session_run_hooks.py:692] global_step/sec: 1.38772\n",
            "INFO:tensorflow:loss = 1.683505, step = 2200 (72.061 sec)\n",
            "I0805 10:09:37.280019 140452147025792 basic_session_run_hooks.py:260] loss = 1.683505, step = 2200 (72.061 sec)\n",
            "INFO:tensorflow:global_step/sec: 1.38359\n",
            "I0805 10:10:49.554185 140452147025792 basic_session_run_hooks.py:692] global_step/sec: 1.38359\n",
            "INFO:tensorflow:loss = 1.4238682, step = 2300 (72.275 sec)\n",
            "I0805 10:10:49.555363 140452147025792 basic_session_run_hooks.py:260] loss = 1.4238682, step = 2300 (72.275 sec)\n",
            "INFO:tensorflow:Saving checkpoints for 2401 into training/model.ckpt.\n",
            "I0805 10:12:01.743981 140452147025792 basic_session_run_hooks.py:606] Saving checkpoints for 2401 into training/model.ckpt.\n",
            "WARNING:tensorflow:Entity <bound method TfExampleDecoder.decode of <object_detection.data_decoders.tf_example_decoder.TfExampleDecoder object at 0x7fbcbad6c710>> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: module 'gast' has no attribute 'Index'\n",
            "W0805 10:12:03.763524 140452147025792 ag_logging.py:146] Entity <bound method TfExampleDecoder.decode of <object_detection.data_decoders.tf_example_decoder.TfExampleDecoder object at 0x7fbcbad6c710>> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: module 'gast' has no attribute 'Index'\n",
            "WARNING:tensorflow:Entity <function eval_input.<locals>.transform_and_pad_input_data_fn at 0x7fbcc14c9cb0> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: Bad argument number for Name: 3, expecting 4\n",
            "W0805 10:12:03.986756 140452147025792 ag_logging.py:146] Entity <function eval_input.<locals>.transform_and_pad_input_data_fn at 0x7fbcc14c9cb0> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: Bad argument number for Name: 3, expecting 4\n",
            "INFO:tensorflow:Calling model_fn.\n",
            "I0805 10:12:04.618284 140452147025792 estimator.py:1148] Calling model_fn.\n",
            "INFO:tensorflow:depth of additional conv before box predictor: 0\n",
            "I0805 10:12:07.281633 140452147025792 convolutional_box_predictor.py:156] depth of additional conv before box predictor: 0\n",
            "INFO:tensorflow:depth of additional conv before box predictor: 0\n",
            "I0805 10:12:07.323318 140452147025792 convolutional_box_predictor.py:156] depth of additional conv before box predictor: 0\n",
            "INFO:tensorflow:depth of additional conv before box predictor: 0\n",
            "I0805 10:12:07.375708 140452147025792 convolutional_box_predictor.py:156] depth of additional conv before box predictor: 0\n",
            "INFO:tensorflow:depth of additional conv before box predictor: 0\n",
            "I0805 10:12:07.420664 140452147025792 convolutional_box_predictor.py:156] depth of additional conv before box predictor: 0\n",
            "INFO:tensorflow:depth of additional conv before box predictor: 0\n",
            "I0805 10:12:07.459482 140452147025792 convolutional_box_predictor.py:156] depth of additional conv before box predictor: 0\n",
            "INFO:tensorflow:depth of additional conv before box predictor: 0\n",
            "I0805 10:12:07.502357 140452147025792 convolutional_box_predictor.py:156] depth of additional conv before box predictor: 0\n",
            "INFO:tensorflow:Done calling model_fn.\n",
            "I0805 10:12:09.389236 140452147025792 estimator.py:1150] Done calling model_fn.\n",
            "INFO:tensorflow:Starting evaluation at 2021-08-05T10:12:09Z\n",
            "I0805 10:12:09.413487 140452147025792 evaluation.py:255] Starting evaluation at 2021-08-05T10:12:09Z\n",
            "INFO:tensorflow:Graph was finalized.\n",
            "I0805 10:12:09.930675 140452147025792 monitored_session.py:240] Graph was finalized.\n",
            "2021-08-05 10:12:09.931532: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2021-08-05 10:12:09.932171: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1639] Found device 0 with properties: \n",
            "name: Tesla K80 major: 3 minor: 7 memoryClockRate(GHz): 0.8235\n",
            "pciBusID: 0000:00:04.0\n",
            "2021-08-05 10:12:09.932290: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.1\n",
            "2021-08-05 10:12:09.932338: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcublas.so.10\n",
            "2021-08-05 10:12:09.932404: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcufft.so.10\n",
            "2021-08-05 10:12:09.932466: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcurand.so.10\n",
            "2021-08-05 10:12:09.932529: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusolver.so.10\n",
            "2021-08-05 10:12:09.932573: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusparse.so.10\n",
            "2021-08-05 10:12:09.932621: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudnn.so.7\n",
            "2021-08-05 10:12:09.932741: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2021-08-05 10:12:09.933385: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2021-08-05 10:12:09.933987: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1767] Adding visible gpu devices: 0\n",
            "2021-08-05 10:12:09.934102: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1180] Device interconnect StreamExecutor with strength 1 edge matrix:\n",
            "2021-08-05 10:12:09.934122: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1186]      0 \n",
            "2021-08-05 10:12:09.934137: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1199] 0:   N \n",
            "2021-08-05 10:12:09.934273: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2021-08-05 10:12:09.934877: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2021-08-05 10:12:09.935422: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1325] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 10813 MB memory) -> physical GPU (device: 0, name: Tesla K80, pci bus id: 0000:00:04.0, compute capability: 3.7)\n",
            "INFO:tensorflow:Restoring parameters from training/model.ckpt-2401\n",
            "I0805 10:12:09.936651 140452147025792 saver.py:1284] Restoring parameters from training/model.ckpt-2401\n",
            "INFO:tensorflow:Running local_init_op.\n",
            "I0805 10:12:11.041452 140452147025792 session_manager.py:500] Running local_init_op.\n",
            "INFO:tensorflow:Done running local_init_op.\n",
            "I0805 10:12:11.213995 140452147025792 session_manager.py:502] Done running local_init_op.\n",
            "INFO:tensorflow:Performing evaluation on 72 images.\n",
            "I0805 10:12:17.380279 140448754308864 coco_evaluation.py:237] Performing evaluation on 72 images.\n",
            "creating index...\n",
            "index created!\n",
            "INFO:tensorflow:Loading and preparing annotation results...\n",
            "I0805 10:12:17.381275 140448754308864 coco_tools.py:116] Loading and preparing annotation results...\n",
            "INFO:tensorflow:DONE (t=0.01s)\n",
            "I0805 10:12:17.389208 140448754308864 coco_tools.py:138] DONE (t=0.01s)\n",
            "creating index...\n",
            "index created!\n",
            "Running per image evaluation...\n",
            "Evaluate annotation type *bbox*\n",
            "DONE (t=0.74s).\n",
            "Accumulating evaluation results...\n",
            "DONE (t=0.16s).\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.163\n",
            " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.406\n",
            " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.064\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.034\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.156\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.295\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.165\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.285\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.290\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.104\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.300\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.420\n",
            "INFO:tensorflow:Finished evaluation at 2021-08-05-10:12:18\n",
            "I0805 10:12:18.408321 140452147025792 evaluation.py:275] Finished evaluation at 2021-08-05-10:12:18\n",
            "INFO:tensorflow:Saving dict for global step 2401: DetectionBoxes_Precision/mAP = 0.16280082, DetectionBoxes_Precision/mAP (large) = 0.29514295, DetectionBoxes_Precision/mAP (medium) = 0.15558323, DetectionBoxes_Precision/mAP (small) = 0.034483697, DetectionBoxes_Precision/mAP@.50IOU = 0.40573773, DetectionBoxes_Precision/mAP@.75IOU = 0.06411905, DetectionBoxes_Recall/AR@1 = 0.16461849, DetectionBoxes_Recall/AR@10 = 0.2846028, DetectionBoxes_Recall/AR@100 = 0.29002005, DetectionBoxes_Recall/AR@100 (large) = 0.42039475, DetectionBoxes_Recall/AR@100 (medium) = 0.3004049, DetectionBoxes_Recall/AR@100 (small) = 0.104166664, Loss/classification_loss = 0.8696337, Loss/localization_loss = 0.29738966, Loss/regularization_loss = 0.24647504, Loss/total_loss = 1.4134978, global_step = 2401, learning_rate = 0.004, loss = 1.4134978\n",
            "I0805 10:12:18.408687 140452147025792 estimator.py:2049] Saving dict for global step 2401: DetectionBoxes_Precision/mAP = 0.16280082, DetectionBoxes_Precision/mAP (large) = 0.29514295, DetectionBoxes_Precision/mAP (medium) = 0.15558323, DetectionBoxes_Precision/mAP (small) = 0.034483697, DetectionBoxes_Precision/mAP@.50IOU = 0.40573773, DetectionBoxes_Precision/mAP@.75IOU = 0.06411905, DetectionBoxes_Recall/AR@1 = 0.16461849, DetectionBoxes_Recall/AR@10 = 0.2846028, DetectionBoxes_Recall/AR@100 = 0.29002005, DetectionBoxes_Recall/AR@100 (large) = 0.42039475, DetectionBoxes_Recall/AR@100 (medium) = 0.3004049, DetectionBoxes_Recall/AR@100 (small) = 0.104166664, Loss/classification_loss = 0.8696337, Loss/localization_loss = 0.29738966, Loss/regularization_loss = 0.24647504, Loss/total_loss = 1.4134978, global_step = 2401, learning_rate = 0.004, loss = 1.4134978\n",
            "INFO:tensorflow:Saving 'checkpoint_path' summary for global step 2401: training/model.ckpt-2401\n",
            "I0805 10:12:18.412308 140452147025792 estimator.py:2109] Saving 'checkpoint_path' summary for global step 2401: training/model.ckpt-2401\n",
            "INFO:tensorflow:global_step/sec: 1.12534\n",
            "I0805 10:12:18.416208 140452147025792 basic_session_run_hooks.py:692] global_step/sec: 1.12534\n",
            "INFO:tensorflow:loss = 1.0568042, step = 2400 (88.862 sec)\n",
            "I0805 10:12:18.417299 140452147025792 basic_session_run_hooks.py:260] loss = 1.0568042, step = 2400 (88.862 sec)\n",
            "INFO:tensorflow:global_step/sec: 1.39129\n",
            "I0805 10:13:30.291918 140452147025792 basic_session_run_hooks.py:692] global_step/sec: 1.39129\n",
            "INFO:tensorflow:loss = 1.2726382, step = 2500 (71.876 sec)\n",
            "I0805 10:13:30.293100 140452147025792 basic_session_run_hooks.py:260] loss = 1.2726382, step = 2500 (71.876 sec)\n",
            "INFO:tensorflow:global_step/sec: 1.40654\n",
            "I0805 10:14:41.388215 140452147025792 basic_session_run_hooks.py:692] global_step/sec: 1.40654\n",
            "INFO:tensorflow:loss = 1.17953, step = 2600 (71.096 sec)\n",
            "I0805 10:14:41.389464 140452147025792 basic_session_run_hooks.py:260] loss = 1.17953, step = 2600 (71.096 sec)\n",
            "INFO:tensorflow:global_step/sec: 1.40707\n",
            "I0805 10:15:52.457879 140452147025792 basic_session_run_hooks.py:692] global_step/sec: 1.40707\n",
            "INFO:tensorflow:loss = 1.0171661, step = 2700 (71.070 sec)\n",
            "I0805 10:15:52.459259 140452147025792 basic_session_run_hooks.py:260] loss = 1.0171661, step = 2700 (71.070 sec)\n",
            "INFO:tensorflow:global_step/sec: 1.4074\n",
            "I0805 10:17:03.510815 140452147025792 basic_session_run_hooks.py:692] global_step/sec: 1.4074\n",
            "INFO:tensorflow:loss = 1.3217129, step = 2800 (71.053 sec)\n",
            "I0805 10:17:03.512238 140452147025792 basic_session_run_hooks.py:260] loss = 1.3217129, step = 2800 (71.053 sec)\n",
            "INFO:tensorflow:global_step/sec: 1.41139\n",
            "I0805 10:18:14.363106 140452147025792 basic_session_run_hooks.py:692] global_step/sec: 1.41139\n",
            "INFO:tensorflow:loss = 1.359355, step = 2900 (70.852 sec)\n",
            "I0805 10:18:14.364331 140452147025792 basic_session_run_hooks.py:260] loss = 1.359355, step = 2900 (70.852 sec)\n",
            "INFO:tensorflow:global_step/sec: 1.40349\n",
            "I0805 10:19:25.613911 140452147025792 basic_session_run_hooks.py:692] global_step/sec: 1.40349\n",
            "INFO:tensorflow:loss = 1.2975885, step = 3000 (71.251 sec)\n",
            "I0805 10:19:25.615255 140452147025792 basic_session_run_hooks.py:260] loss = 1.2975885, step = 3000 (71.251 sec)\n",
            "INFO:tensorflow:global_step/sec: 1.4064\n",
            "I0805 10:20:36.717430 140452147025792 basic_session_run_hooks.py:692] global_step/sec: 1.4064\n",
            "INFO:tensorflow:loss = 1.2914442, step = 3100 (71.104 sec)\n",
            "I0805 10:20:36.718946 140452147025792 basic_session_run_hooks.py:260] loss = 1.2914442, step = 3100 (71.104 sec)\n",
            "INFO:tensorflow:global_step/sec: 1.41133\n",
            "I0805 10:21:47.572577 140452147025792 basic_session_run_hooks.py:692] global_step/sec: 1.41133\n",
            "INFO:tensorflow:loss = 1.6536533, step = 3200 (70.855 sec)\n",
            "I0805 10:21:47.574164 140452147025792 basic_session_run_hooks.py:260] loss = 1.6536533, step = 3200 (70.855 sec)\n",
            "INFO:tensorflow:Saving checkpoints for 3222 into training/model.ckpt.\n",
            "I0805 10:22:02.295718 140452147025792 basic_session_run_hooks.py:606] Saving checkpoints for 3222 into training/model.ckpt.\n",
            "WARNING:tensorflow:Entity <bound method TfExampleDecoder.decode of <object_detection.data_decoders.tf_example_decoder.TfExampleDecoder object at 0x7fbcc0080a50>> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: module 'gast' has no attribute 'Index'\n",
            "W0805 10:22:04.293858 140452147025792 ag_logging.py:146] Entity <bound method TfExampleDecoder.decode of <object_detection.data_decoders.tf_example_decoder.TfExampleDecoder object at 0x7fbcc0080a50>> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: module 'gast' has no attribute 'Index'\n",
            "WARNING:tensorflow:Entity <function eval_input.<locals>.transform_and_pad_input_data_fn at 0x7fbcc011c170> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: Bad argument number for Name: 3, expecting 4\n",
            "W0805 10:22:04.507547 140452147025792 ag_logging.py:146] Entity <function eval_input.<locals>.transform_and_pad_input_data_fn at 0x7fbcc011c170> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: Bad argument number for Name: 3, expecting 4\n",
            "INFO:tensorflow:Calling model_fn.\n",
            "I0805 10:22:05.145366 140452147025792 estimator.py:1148] Calling model_fn.\n",
            "INFO:tensorflow:depth of additional conv before box predictor: 0\n",
            "I0805 10:22:08.364631 140452147025792 convolutional_box_predictor.py:156] depth of additional conv before box predictor: 0\n",
            "INFO:tensorflow:depth of additional conv before box predictor: 0\n",
            "I0805 10:22:08.401584 140452147025792 convolutional_box_predictor.py:156] depth of additional conv before box predictor: 0\n",
            "INFO:tensorflow:depth of additional conv before box predictor: 0\n",
            "I0805 10:22:08.438993 140452147025792 convolutional_box_predictor.py:156] depth of additional conv before box predictor: 0\n",
            "INFO:tensorflow:depth of additional conv before box predictor: 0\n",
            "I0805 10:22:08.477506 140452147025792 convolutional_box_predictor.py:156] depth of additional conv before box predictor: 0\n",
            "INFO:tensorflow:depth of additional conv before box predictor: 0\n",
            "I0805 10:22:08.514723 140452147025792 convolutional_box_predictor.py:156] depth of additional conv before box predictor: 0\n",
            "INFO:tensorflow:depth of additional conv before box predictor: 0\n",
            "I0805 10:22:08.552901 140452147025792 convolutional_box_predictor.py:156] depth of additional conv before box predictor: 0\n",
            "INFO:tensorflow:Done calling model_fn.\n",
            "I0805 10:22:10.349190 140452147025792 estimator.py:1150] Done calling model_fn.\n",
            "INFO:tensorflow:Starting evaluation at 2021-08-05T10:22:10Z\n",
            "I0805 10:22:10.370618 140452147025792 evaluation.py:255] Starting evaluation at 2021-08-05T10:22:10Z\n",
            "INFO:tensorflow:Graph was finalized.\n",
            "I0805 10:22:10.905544 140452147025792 monitored_session.py:240] Graph was finalized.\n",
            "2021-08-05 10:22:10.906408: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2021-08-05 10:22:10.907091: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1639] Found device 0 with properties: \n",
            "name: Tesla K80 major: 3 minor: 7 memoryClockRate(GHz): 0.8235\n",
            "pciBusID: 0000:00:04.0\n",
            "2021-08-05 10:22:10.907232: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.1\n",
            "2021-08-05 10:22:10.907323: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcublas.so.10\n",
            "2021-08-05 10:22:10.907399: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcufft.so.10\n",
            "2021-08-05 10:22:10.907441: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcurand.so.10\n",
            "2021-08-05 10:22:10.907488: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusolver.so.10\n",
            "2021-08-05 10:22:10.907534: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusparse.so.10\n",
            "2021-08-05 10:22:10.907599: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudnn.so.7\n",
            "2021-08-05 10:22:10.907720: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2021-08-05 10:22:10.908294: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2021-08-05 10:22:10.908875: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1767] Adding visible gpu devices: 0\n",
            "2021-08-05 10:22:10.908932: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1180] Device interconnect StreamExecutor with strength 1 edge matrix:\n",
            "2021-08-05 10:22:10.908952: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1186]      0 \n",
            "2021-08-05 10:22:10.908966: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1199] 0:   N \n",
            "2021-08-05 10:22:10.909086: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2021-08-05 10:22:10.909662: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2021-08-05 10:22:10.910165: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1325] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 10813 MB memory) -> physical GPU (device: 0, name: Tesla K80, pci bus id: 0000:00:04.0, compute capability: 3.7)\n",
            "INFO:tensorflow:Restoring parameters from training/model.ckpt-3222\n",
            "I0805 10:22:10.911471 140452147025792 saver.py:1284] Restoring parameters from training/model.ckpt-3222\n",
            "INFO:tensorflow:Running local_init_op.\n",
            "I0805 10:22:12.089662 140452147025792 session_manager.py:500] Running local_init_op.\n",
            "INFO:tensorflow:Done running local_init_op.\n",
            "I0805 10:22:12.281207 140452147025792 session_manager.py:502] Done running local_init_op.\n",
            "INFO:tensorflow:Performing evaluation on 72 images.\n",
            "I0805 10:22:18.510703 140448754308864 coco_evaluation.py:237] Performing evaluation on 72 images.\n",
            "creating index...\n",
            "index created!\n",
            "INFO:tensorflow:Loading and preparing annotation results...\n",
            "I0805 10:22:18.512038 140448754308864 coco_tools.py:116] Loading and preparing annotation results...\n",
            "INFO:tensorflow:DONE (t=0.01s)\n",
            "I0805 10:22:18.519947 140448754308864 coco_tools.py:138] DONE (t=0.01s)\n",
            "creating index...\n",
            "index created!\n",
            "Running per image evaluation...\n",
            "Evaluate annotation type *bbox*\n",
            "DONE (t=0.80s).\n",
            "Accumulating evaluation results...\n",
            "DONE (t=0.12s).\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.205\n",
            " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.524\n",
            " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.087\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.044\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.206\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.368\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.220\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.290\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.295\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.100\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.304\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.524\n",
            "INFO:tensorflow:Finished evaluation at 2021-08-05-10:22:19\n",
            "I0805 10:22:19.559060 140452147025792 evaluation.py:275] Finished evaluation at 2021-08-05-10:22:19\n",
            "INFO:tensorflow:Saving dict for global step 3222: DetectionBoxes_Precision/mAP = 0.20489183, DetectionBoxes_Precision/mAP (large) = 0.3682003, DetectionBoxes_Precision/mAP (medium) = 0.20613873, DetectionBoxes_Precision/mAP (small) = 0.044105023, DetectionBoxes_Precision/mAP@.50IOU = 0.5239739, DetectionBoxes_Precision/mAP@.75IOU = 0.0868927, DetectionBoxes_Recall/AR@1 = 0.22000943, DetectionBoxes_Recall/AR@10 = 0.29004675, DetectionBoxes_Recall/AR@100 = 0.29499725, DetectionBoxes_Recall/AR@100 (large) = 0.5243421, DetectionBoxes_Recall/AR@100 (medium) = 0.3040687, DetectionBoxes_Recall/AR@100 (small) = 0.1, Loss/classification_loss = 0.77441686, Loss/localization_loss = 0.25517514, Loss/regularization_loss = 0.24597278, Loss/total_loss = 1.2755647, global_step = 3222, learning_rate = 0.004, loss = 1.2755647\n",
            "I0805 10:22:19.559364 140452147025792 estimator.py:2049] Saving dict for global step 3222: DetectionBoxes_Precision/mAP = 0.20489183, DetectionBoxes_Precision/mAP (large) = 0.3682003, DetectionBoxes_Precision/mAP (medium) = 0.20613873, DetectionBoxes_Precision/mAP (small) = 0.044105023, DetectionBoxes_Precision/mAP@.50IOU = 0.5239739, DetectionBoxes_Precision/mAP@.75IOU = 0.0868927, DetectionBoxes_Recall/AR@1 = 0.22000943, DetectionBoxes_Recall/AR@10 = 0.29004675, DetectionBoxes_Recall/AR@100 = 0.29499725, DetectionBoxes_Recall/AR@100 (large) = 0.5243421, DetectionBoxes_Recall/AR@100 (medium) = 0.3040687, DetectionBoxes_Recall/AR@100 (small) = 0.1, Loss/classification_loss = 0.77441686, Loss/localization_loss = 0.25517514, Loss/regularization_loss = 0.24597278, Loss/total_loss = 1.2755647, global_step = 3222, learning_rate = 0.004, loss = 1.2755647\n",
            "INFO:tensorflow:Saving 'checkpoint_path' summary for global step 3222: training/model.ckpt-3222\n",
            "I0805 10:22:19.563045 140452147025792 estimator.py:2109] Saving 'checkpoint_path' summary for global step 3222: training/model.ckpt-3222\n",
            "INFO:tensorflow:global_step/sec: 1.1113\n",
            "I0805 10:23:17.556982 140452147025792 basic_session_run_hooks.py:692] global_step/sec: 1.1113\n",
            "INFO:tensorflow:loss = 1.0735297, step = 3300 (89.984 sec)\n",
            "I0805 10:23:17.558408 140452147025792 basic_session_run_hooks.py:260] loss = 1.0735297, step = 3300 (89.984 sec)\n",
            "INFO:tensorflow:global_step/sec: 1.36606\n",
            "I0805 10:24:30.759929 140452147025792 basic_session_run_hooks.py:692] global_step/sec: 1.36606\n",
            "INFO:tensorflow:loss = 1.0403639, step = 3400 (73.203 sec)\n",
            "I0805 10:24:30.761180 140452147025792 basic_session_run_hooks.py:260] loss = 1.0403639, step = 3400 (73.203 sec)\n",
            "INFO:tensorflow:global_step/sec: 1.36066\n",
            "I0805 10:25:44.253678 140452147025792 basic_session_run_hooks.py:692] global_step/sec: 1.36066\n",
            "INFO:tensorflow:loss = 1.2916203, step = 3500 (73.494 sec)\n",
            "I0805 10:25:44.255268 140452147025792 basic_session_run_hooks.py:260] loss = 1.2916203, step = 3500 (73.494 sec)\n",
            "INFO:tensorflow:global_step/sec: 1.36045\n",
            "I0805 10:26:57.759030 140452147025792 basic_session_run_hooks.py:692] global_step/sec: 1.36045\n",
            "INFO:tensorflow:loss = 1.0507363, step = 3600 (73.505 sec)\n",
            "I0805 10:26:57.760276 140452147025792 basic_session_run_hooks.py:260] loss = 1.0507363, step = 3600 (73.505 sec)\n",
            "INFO:tensorflow:global_step/sec: 1.37154\n",
            "I0805 10:28:10.669651 140452147025792 basic_session_run_hooks.py:692] global_step/sec: 1.37154\n",
            "INFO:tensorflow:loss = 1.0362313, step = 3700 (72.911 sec)\n",
            "I0805 10:28:10.670881 140452147025792 basic_session_run_hooks.py:260] loss = 1.0362313, step = 3700 (72.911 sec)\n",
            "INFO:tensorflow:global_step/sec: 1.37113\n",
            "I0805 10:29:23.602217 140452147025792 basic_session_run_hooks.py:692] global_step/sec: 1.37113\n",
            "INFO:tensorflow:loss = 1.2181787, step = 3800 (72.932 sec)\n",
            "I0805 10:29:23.603304 140452147025792 basic_session_run_hooks.py:260] loss = 1.2181787, step = 3800 (72.932 sec)\n",
            "INFO:tensorflow:global_step/sec: 1.37226\n",
            "I0805 10:30:36.474852 140452147025792 basic_session_run_hooks.py:692] global_step/sec: 1.37226\n",
            "INFO:tensorflow:loss = 1.0808179, step = 3900 (72.873 sec)\n",
            "I0805 10:30:36.476177 140452147025792 basic_session_run_hooks.py:260] loss = 1.0808179, step = 3900 (72.873 sec)\n",
            "INFO:tensorflow:global_step/sec: 1.37375\n",
            "I0805 10:31:49.268422 140452147025792 basic_session_run_hooks.py:692] global_step/sec: 1.37375\n",
            "INFO:tensorflow:loss = 1.0569388, step = 4000 (72.793 sec)\n",
            "I0805 10:31:49.269616 140452147025792 basic_session_run_hooks.py:260] loss = 1.0569388, step = 4000 (72.793 sec)\n",
            "INFO:tensorflow:Saving checkpoints for 4019 into training/model.ckpt.\n",
            "I0805 10:32:02.343804 140452147025792 basic_session_run_hooks.py:606] Saving checkpoints for 4019 into training/model.ckpt.\n",
            "WARNING:tensorflow:From /tensorflow-1.15.2/python3.7/tensorflow_core/python/training/saver.py:963: remove_checkpoint (from tensorflow.python.training.checkpoint_management) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use standard file APIs to delete files with this prefix.\n",
            "W0805 10:32:02.456279 140452147025792 deprecation.py:323] From /tensorflow-1.15.2/python3.7/tensorflow_core/python/training/saver.py:963: remove_checkpoint (from tensorflow.python.training.checkpoint_management) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use standard file APIs to delete files with this prefix.\n",
            "WARNING:tensorflow:Entity <bound method TfExampleDecoder.decode of <object_detection.data_decoders.tf_example_decoder.TfExampleDecoder object at 0x7fbcc1202a50>> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: module 'gast' has no attribute 'Index'\n",
            "W0805 10:32:04.331125 140452147025792 ag_logging.py:146] Entity <bound method TfExampleDecoder.decode of <object_detection.data_decoders.tf_example_decoder.TfExampleDecoder object at 0x7fbcc1202a50>> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: module 'gast' has no attribute 'Index'\n",
            "WARNING:tensorflow:Entity <function eval_input.<locals>.transform_and_pad_input_data_fn at 0x7fbd10508440> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: Bad argument number for Name: 3, expecting 4\n",
            "W0805 10:32:04.542170 140452147025792 ag_logging.py:146] Entity <function eval_input.<locals>.transform_and_pad_input_data_fn at 0x7fbd10508440> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: Bad argument number for Name: 3, expecting 4\n",
            "INFO:tensorflow:Calling model_fn.\n",
            "I0805 10:32:05.170855 140452147025792 estimator.py:1148] Calling model_fn.\n",
            "INFO:tensorflow:depth of additional conv before box predictor: 0\n",
            "I0805 10:32:07.832988 140452147025792 convolutional_box_predictor.py:156] depth of additional conv before box predictor: 0\n",
            "INFO:tensorflow:depth of additional conv before box predictor: 0\n",
            "I0805 10:32:07.869951 140452147025792 convolutional_box_predictor.py:156] depth of additional conv before box predictor: 0\n",
            "INFO:tensorflow:depth of additional conv before box predictor: 0\n",
            "I0805 10:32:07.919571 140452147025792 convolutional_box_predictor.py:156] depth of additional conv before box predictor: 0\n",
            "INFO:tensorflow:depth of additional conv before box predictor: 0\n",
            "I0805 10:32:07.972656 140452147025792 convolutional_box_predictor.py:156] depth of additional conv before box predictor: 0\n",
            "INFO:tensorflow:depth of additional conv before box predictor: 0\n",
            "I0805 10:32:08.009918 140452147025792 convolutional_box_predictor.py:156] depth of additional conv before box predictor: 0\n",
            "INFO:tensorflow:depth of additional conv before box predictor: 0\n",
            "I0805 10:32:08.048134 140452147025792 convolutional_box_predictor.py:156] depth of additional conv before box predictor: 0\n",
            "INFO:tensorflow:Done calling model_fn.\n",
            "I0805 10:32:09.889129 140452147025792 estimator.py:1150] Done calling model_fn.\n",
            "INFO:tensorflow:Starting evaluation at 2021-08-05T10:32:09Z\n",
            "I0805 10:32:09.911101 140452147025792 evaluation.py:255] Starting evaluation at 2021-08-05T10:32:09Z\n",
            "INFO:tensorflow:Graph was finalized.\n",
            "I0805 10:32:10.430726 140452147025792 monitored_session.py:240] Graph was finalized.\n",
            "2021-08-05 10:32:10.431665: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2021-08-05 10:32:10.432381: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1639] Found device 0 with properties: \n",
            "name: Tesla K80 major: 3 minor: 7 memoryClockRate(GHz): 0.8235\n",
            "pciBusID: 0000:00:04.0\n",
            "2021-08-05 10:32:10.432529: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.1\n",
            "2021-08-05 10:32:10.432587: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcublas.so.10\n",
            "2021-08-05 10:32:10.432642: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcufft.so.10\n",
            "2021-08-05 10:32:10.432687: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcurand.so.10\n",
            "2021-08-05 10:32:10.432725: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusolver.so.10\n",
            "2021-08-05 10:32:10.432761: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusparse.so.10\n",
            "2021-08-05 10:32:10.432797: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudnn.so.7\n",
            "2021-08-05 10:32:10.432886: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2021-08-05 10:32:10.433429: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2021-08-05 10:32:10.434262: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1767] Adding visible gpu devices: 0\n",
            "2021-08-05 10:32:10.434418: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1180] Device interconnect StreamExecutor with strength 1 edge matrix:\n",
            "2021-08-05 10:32:10.434439: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1186]      0 \n",
            "2021-08-05 10:32:10.434478: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1199] 0:   N \n",
            "2021-08-05 10:32:10.434620: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2021-08-05 10:32:10.435179: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2021-08-05 10:32:10.435716: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1325] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 10813 MB memory) -> physical GPU (device: 0, name: Tesla K80, pci bus id: 0000:00:04.0, compute capability: 3.7)\n",
            "INFO:tensorflow:Restoring parameters from training/model.ckpt-4019\n",
            "I0805 10:32:10.437182 140452147025792 saver.py:1284] Restoring parameters from training/model.ckpt-4019\n",
            "INFO:tensorflow:Running local_init_op.\n",
            "I0805 10:32:11.557194 140452147025792 session_manager.py:500] Running local_init_op.\n",
            "INFO:tensorflow:Done running local_init_op.\n",
            "I0805 10:32:11.729110 140452147025792 session_manager.py:502] Done running local_init_op.\n",
            "INFO:tensorflow:Performing evaluation on 72 images.\n",
            "I0805 10:32:17.691833 140450009868032 coco_evaluation.py:237] Performing evaluation on 72 images.\n",
            "creating index...\n",
            "index created!\n",
            "INFO:tensorflow:Loading and preparing annotation results...\n",
            "I0805 10:32:17.692541 140450009868032 coco_tools.py:116] Loading and preparing annotation results...\n",
            "INFO:tensorflow:DONE (t=0.01s)\n",
            "I0805 10:32:17.701216 140450009868032 coco_tools.py:138] DONE (t=0.01s)\n",
            "creating index...\n",
            "index created!\n",
            "Running per image evaluation...\n",
            "Evaluate annotation type *bbox*\n",
            "DONE (t=1.16s).\n",
            "Accumulating evaluation results...\n",
            "DONE (t=0.10s).\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.222\n",
            " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.533\n",
            " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.126\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.055\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.238\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.387\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.243\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.316\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.322\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.127\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.358\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.524\n",
            "INFO:tensorflow:Finished evaluation at 2021-08-05-10:32:19\n",
            "I0805 10:32:19.084223 140452147025792 evaluation.py:275] Finished evaluation at 2021-08-05-10:32:19\n",
            "INFO:tensorflow:Saving dict for global step 4019: DetectionBoxes_Precision/mAP = 0.22218463, DetectionBoxes_Precision/mAP (large) = 0.38697127, DetectionBoxes_Precision/mAP (medium) = 0.23756455, DetectionBoxes_Precision/mAP (small) = 0.055361267, DetectionBoxes_Precision/mAP@.50IOU = 0.5328298, DetectionBoxes_Precision/mAP@.75IOU = 0.12578373, DetectionBoxes_Recall/AR@1 = 0.24299014, DetectionBoxes_Recall/AR@10 = 0.3163777, DetectionBoxes_Recall/AR@100 = 0.3215757, DetectionBoxes_Recall/AR@100 (large) = 0.5236842, DetectionBoxes_Recall/AR@100 (medium) = 0.3577978, DetectionBoxes_Recall/AR@100 (small) = 0.12708333, Loss/classification_loss = 0.68194604, Loss/localization_loss = 0.19699512, Loss/regularization_loss = 0.24547702, Loss/total_loss = 1.1244181, global_step = 4019, learning_rate = 0.004, loss = 1.1244181\n",
            "I0805 10:32:19.084619 140452147025792 estimator.py:2049] Saving dict for global step 4019: DetectionBoxes_Precision/mAP = 0.22218463, DetectionBoxes_Precision/mAP (large) = 0.38697127, DetectionBoxes_Precision/mAP (medium) = 0.23756455, DetectionBoxes_Precision/mAP (small) = 0.055361267, DetectionBoxes_Precision/mAP@.50IOU = 0.5328298, DetectionBoxes_Precision/mAP@.75IOU = 0.12578373, DetectionBoxes_Recall/AR@1 = 0.24299014, DetectionBoxes_Recall/AR@10 = 0.3163777, DetectionBoxes_Recall/AR@100 = 0.3215757, DetectionBoxes_Recall/AR@100 (large) = 0.5236842, DetectionBoxes_Recall/AR@100 (medium) = 0.3577978, DetectionBoxes_Recall/AR@100 (small) = 0.12708333, Loss/classification_loss = 0.68194604, Loss/localization_loss = 0.19699512, Loss/regularization_loss = 0.24547702, Loss/total_loss = 1.1244181, global_step = 4019, learning_rate = 0.004, loss = 1.1244181\n",
            "INFO:tensorflow:Saving 'checkpoint_path' summary for global step 4019: training/model.ckpt-4019\n",
            "I0805 10:32:19.088091 140452147025792 estimator.py:2109] Saving 'checkpoint_path' summary for global step 4019: training/model.ckpt-4019\n",
            "INFO:tensorflow:global_step/sec: 1.11683\n",
            "I0805 10:33:18.807788 140452147025792 basic_session_run_hooks.py:692] global_step/sec: 1.11683\n",
            "INFO:tensorflow:loss = 1.1613518, step = 4100 (89.539 sec)\n",
            "I0805 10:33:18.809045 140452147025792 basic_session_run_hooks.py:260] loss = 1.1613518, step = 4100 (89.539 sec)\n",
            "INFO:tensorflow:global_step/sec: 1.36766\n",
            "I0805 10:34:31.925138 140452147025792 basic_session_run_hooks.py:692] global_step/sec: 1.36766\n",
            "INFO:tensorflow:loss = 1.2380232, step = 4200 (73.117 sec)\n",
            "I0805 10:34:31.926437 140452147025792 basic_session_run_hooks.py:260] loss = 1.2380232, step = 4200 (73.117 sec)\n",
            "INFO:tensorflow:global_step/sec: 1.37359\n",
            "I0805 10:35:44.727230 140452147025792 basic_session_run_hooks.py:692] global_step/sec: 1.37359\n",
            "INFO:tensorflow:loss = 1.201452, step = 4300 (72.802 sec)\n",
            "I0805 10:35:44.728610 140452147025792 basic_session_run_hooks.py:260] loss = 1.201452, step = 4300 (72.802 sec)\n",
            "INFO:tensorflow:global_step/sec: 1.37637\n",
            "I0805 10:36:57.381835 140452147025792 basic_session_run_hooks.py:692] global_step/sec: 1.37637\n",
            "INFO:tensorflow:loss = 1.1995947, step = 4400 (72.655 sec)\n",
            "I0805 10:36:57.383130 140452147025792 basic_session_run_hooks.py:260] loss = 1.1995947, step = 4400 (72.655 sec)\n",
            "INFO:tensorflow:global_step/sec: 1.36915\n",
            "I0805 10:38:10.419791 140452147025792 basic_session_run_hooks.py:692] global_step/sec: 1.36915\n",
            "INFO:tensorflow:loss = 0.9944857, step = 4500 (73.038 sec)\n",
            "I0805 10:38:10.421176 140452147025792 basic_session_run_hooks.py:260] loss = 0.9944857, step = 4500 (73.038 sec)\n",
            "INFO:tensorflow:global_step/sec: 1.37238\n",
            "I0805 10:39:23.285947 140452147025792 basic_session_run_hooks.py:692] global_step/sec: 1.37238\n",
            "INFO:tensorflow:loss = 1.2774493, step = 4600 (72.866 sec)\n",
            "I0805 10:39:23.287299 140452147025792 basic_session_run_hooks.py:260] loss = 1.2774493, step = 4600 (72.866 sec)\n",
            "INFO:tensorflow:global_step/sec: 1.37079\n",
            "I0805 10:40:36.236573 140452147025792 basic_session_run_hooks.py:692] global_step/sec: 1.37079\n",
            "INFO:tensorflow:loss = 0.9749211, step = 4700 (72.951 sec)\n",
            "I0805 10:40:36.237880 140452147025792 basic_session_run_hooks.py:260] loss = 0.9749211, step = 4700 (72.951 sec)\n",
            "INFO:tensorflow:global_step/sec: 1.38762\n",
            "I0805 10:41:48.302339 140452147025792 basic_session_run_hooks.py:692] global_step/sec: 1.38762\n",
            "INFO:tensorflow:loss = 1.1626647, step = 4800 (72.066 sec)\n",
            "I0805 10:41:48.303578 140452147025792 basic_session_run_hooks.py:260] loss = 1.1626647, step = 4800 (72.066 sec)\n",
            "INFO:tensorflow:Saving checkpoints for 4820 into training/model.ckpt.\n",
            "I0805 10:42:02.356597 140452147025792 basic_session_run_hooks.py:606] Saving checkpoints for 4820 into training/model.ckpt.\n",
            "INFO:tensorflow:Skip the current checkpoint eval due to throttle secs (600 secs).\n",
            "I0805 10:42:04.249150 140452147025792 training.py:527] Skip the current checkpoint eval due to throttle secs (600 secs).\n",
            "INFO:tensorflow:global_step/sec: 1.33237\n",
            "I0805 10:43:03.356406 140452147025792 basic_session_run_hooks.py:692] global_step/sec: 1.33237\n",
            "INFO:tensorflow:loss = 1.1093285, step = 4900 (75.054 sec)\n",
            "I0805 10:43:03.357678 140452147025792 basic_session_run_hooks.py:260] loss = 1.1093285, step = 4900 (75.054 sec)\n",
            "INFO:tensorflow:Saving checkpoints for 5000 into training/model.ckpt.\n",
            "I0805 10:44:15.122685 140452147025792 basic_session_run_hooks.py:606] Saving checkpoints for 5000 into training/model.ckpt.\n",
            "WARNING:tensorflow:Entity <bound method TfExampleDecoder.decode of <object_detection.data_decoders.tf_example_decoder.TfExampleDecoder object at 0x7fbcbf40d8d0>> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: module 'gast' has no attribute 'Index'\n",
            "W0805 10:44:17.187644 140452147025792 ag_logging.py:146] Entity <bound method TfExampleDecoder.decode of <object_detection.data_decoders.tf_example_decoder.TfExampleDecoder object at 0x7fbcbf40d8d0>> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: module 'gast' has no attribute 'Index'\n",
            "WARNING:tensorflow:Entity <function eval_input.<locals>.transform_and_pad_input_data_fn at 0x7fbcc1c88050> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: Bad argument number for Name: 3, expecting 4\n",
            "W0805 10:44:17.407078 140452147025792 ag_logging.py:146] Entity <function eval_input.<locals>.transform_and_pad_input_data_fn at 0x7fbcc1c88050> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: Bad argument number for Name: 3, expecting 4\n",
            "INFO:tensorflow:Calling model_fn.\n",
            "I0805 10:44:18.027425 140452147025792 estimator.py:1148] Calling model_fn.\n",
            "INFO:tensorflow:depth of additional conv before box predictor: 0\n",
            "I0805 10:44:20.737895 140452147025792 convolutional_box_predictor.py:156] depth of additional conv before box predictor: 0\n",
            "INFO:tensorflow:depth of additional conv before box predictor: 0\n",
            "I0805 10:44:20.776420 140452147025792 convolutional_box_predictor.py:156] depth of additional conv before box predictor: 0\n",
            "INFO:tensorflow:depth of additional conv before box predictor: 0\n",
            "I0805 10:44:20.813611 140452147025792 convolutional_box_predictor.py:156] depth of additional conv before box predictor: 0\n",
            "INFO:tensorflow:depth of additional conv before box predictor: 0\n",
            "I0805 10:44:20.850898 140452147025792 convolutional_box_predictor.py:156] depth of additional conv before box predictor: 0\n",
            "INFO:tensorflow:depth of additional conv before box predictor: 0\n",
            "I0805 10:44:20.889604 140452147025792 convolutional_box_predictor.py:156] depth of additional conv before box predictor: 0\n",
            "INFO:tensorflow:depth of additional conv before box predictor: 0\n",
            "I0805 10:44:20.926789 140452147025792 convolutional_box_predictor.py:156] depth of additional conv before box predictor: 0\n",
            "INFO:tensorflow:Done calling model_fn.\n",
            "I0805 10:44:22.736358 140452147025792 estimator.py:1150] Done calling model_fn.\n",
            "INFO:tensorflow:Starting evaluation at 2021-08-05T10:44:22Z\n",
            "I0805 10:44:22.756416 140452147025792 evaluation.py:255] Starting evaluation at 2021-08-05T10:44:22Z\n",
            "INFO:tensorflow:Graph was finalized.\n",
            "I0805 10:44:23.267479 140452147025792 monitored_session.py:240] Graph was finalized.\n",
            "2021-08-05 10:44:23.268354: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2021-08-05 10:44:23.269016: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1639] Found device 0 with properties: \n",
            "name: Tesla K80 major: 3 minor: 7 memoryClockRate(GHz): 0.8235\n",
            "pciBusID: 0000:00:04.0\n",
            "2021-08-05 10:44:23.269134: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.1\n",
            "2021-08-05 10:44:23.269183: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcublas.so.10\n",
            "2021-08-05 10:44:23.269224: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcufft.so.10\n",
            "2021-08-05 10:44:23.269276: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcurand.so.10\n",
            "2021-08-05 10:44:23.269316: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusolver.so.10\n",
            "2021-08-05 10:44:23.269360: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusparse.so.10\n",
            "2021-08-05 10:44:23.269431: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudnn.so.7\n",
            "2021-08-05 10:44:23.269529: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2021-08-05 10:44:23.270094: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2021-08-05 10:44:23.270662: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1767] Adding visible gpu devices: 0\n",
            "2021-08-05 10:44:23.270733: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1180] Device interconnect StreamExecutor with strength 1 edge matrix:\n",
            "2021-08-05 10:44:23.270753: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1186]      0 \n",
            "2021-08-05 10:44:23.270767: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1199] 0:   N \n",
            "2021-08-05 10:44:23.270906: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2021-08-05 10:44:23.271494: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2021-08-05 10:44:23.272019: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1325] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 10813 MB memory) -> physical GPU (device: 0, name: Tesla K80, pci bus id: 0000:00:04.0, compute capability: 3.7)\n",
            "INFO:tensorflow:Restoring parameters from training/model.ckpt-5000\n",
            "I0805 10:44:23.273265 140452147025792 saver.py:1284] Restoring parameters from training/model.ckpt-5000\n",
            "INFO:tensorflow:Running local_init_op.\n",
            "I0805 10:44:24.385587 140452147025792 session_manager.py:500] Running local_init_op.\n",
            "INFO:tensorflow:Done running local_init_op.\n",
            "I0805 10:44:24.557539 140452147025792 session_manager.py:502] Done running local_init_op.\n",
            "INFO:tensorflow:Performing evaluation on 72 images.\n",
            "I0805 10:44:30.571255 140448754308864 coco_evaluation.py:237] Performing evaluation on 72 images.\n",
            "creating index...\n",
            "index created!\n",
            "INFO:tensorflow:Loading and preparing annotation results...\n",
            "I0805 10:44:30.571886 140448754308864 coco_tools.py:116] Loading and preparing annotation results...\n",
            "INFO:tensorflow:DONE (t=0.01s)\n",
            "I0805 10:44:30.580523 140448754308864 coco_tools.py:138] DONE (t=0.01s)\n",
            "creating index...\n",
            "index created!\n",
            "Running per image evaluation...\n",
            "Evaluate annotation type *bbox*\n",
            "DONE (t=0.79s).\n",
            "Accumulating evaluation results...\n",
            "DONE (t=0.14s).\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.238\n",
            " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.586\n",
            " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.157\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.065\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.242\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.365\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.256\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.320\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.326\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.115\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.351\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.445\n",
            "INFO:tensorflow:Finished evaluation at 2021-08-05-10:44:31\n",
            "I0805 10:44:31.622119 140452147025792 evaluation.py:275] Finished evaluation at 2021-08-05-10:44:31\n",
            "INFO:tensorflow:Saving dict for global step 5000: DetectionBoxes_Precision/mAP = 0.2379695, DetectionBoxes_Precision/mAP (large) = 0.36476228, DetectionBoxes_Precision/mAP (medium) = 0.2421235, DetectionBoxes_Precision/mAP (small) = 0.065438405, DetectionBoxes_Precision/mAP@.50IOU = 0.5863219, DetectionBoxes_Precision/mAP@.75IOU = 0.15716295, DetectionBoxes_Recall/AR@1 = 0.25568974, DetectionBoxes_Recall/AR@10 = 0.31953305, DetectionBoxes_Recall/AR@100 = 0.32611996, DetectionBoxes_Recall/AR@100 (large) = 0.44539472, DetectionBoxes_Recall/AR@100 (medium) = 0.35148904, DetectionBoxes_Recall/AR@100 (small) = 0.114583336, Loss/classification_loss = 0.6545734, Loss/localization_loss = 0.20183595, Loss/regularization_loss = 0.24486038, Loss/total_loss = 1.1012695, global_step = 5000, learning_rate = 0.004, loss = 1.1012695\n",
            "I0805 10:44:31.622475 140452147025792 estimator.py:2049] Saving dict for global step 5000: DetectionBoxes_Precision/mAP = 0.2379695, DetectionBoxes_Precision/mAP (large) = 0.36476228, DetectionBoxes_Precision/mAP (medium) = 0.2421235, DetectionBoxes_Precision/mAP (small) = 0.065438405, DetectionBoxes_Precision/mAP@.50IOU = 0.5863219, DetectionBoxes_Precision/mAP@.75IOU = 0.15716295, DetectionBoxes_Recall/AR@1 = 0.25568974, DetectionBoxes_Recall/AR@10 = 0.31953305, DetectionBoxes_Recall/AR@100 = 0.32611996, DetectionBoxes_Recall/AR@100 (large) = 0.44539472, DetectionBoxes_Recall/AR@100 (medium) = 0.35148904, DetectionBoxes_Recall/AR@100 (small) = 0.114583336, Loss/classification_loss = 0.6545734, Loss/localization_loss = 0.20183595, Loss/regularization_loss = 0.24486038, Loss/total_loss = 1.1012695, global_step = 5000, learning_rate = 0.004, loss = 1.1012695\n",
            "INFO:tensorflow:Saving 'checkpoint_path' summary for global step 5000: training/model.ckpt-5000\n",
            "I0805 10:44:31.626134 140452147025792 estimator.py:2109] Saving 'checkpoint_path' summary for global step 5000: training/model.ckpt-5000\n",
            "INFO:tensorflow:Performing the final export in the end of training.\n",
            "I0805 10:44:31.627049 140452147025792 exporter.py:410] Performing the final export in the end of training.\n",
            "INFO:tensorflow:Calling model_fn.\n",
            "I0805 10:44:31.943253 140452147025792 estimator.py:1148] Calling model_fn.\n",
            "INFO:tensorflow:depth of additional conv before box predictor: 0\n",
            "I0805 10:44:34.547749 140452147025792 convolutional_box_predictor.py:156] depth of additional conv before box predictor: 0\n",
            "INFO:tensorflow:depth of additional conv before box predictor: 0\n",
            "I0805 10:44:34.585690 140452147025792 convolutional_box_predictor.py:156] depth of additional conv before box predictor: 0\n",
            "INFO:tensorflow:depth of additional conv before box predictor: 0\n",
            "I0805 10:44:34.624657 140452147025792 convolutional_box_predictor.py:156] depth of additional conv before box predictor: 0\n",
            "INFO:tensorflow:depth of additional conv before box predictor: 0\n",
            "I0805 10:44:34.661908 140452147025792 convolutional_box_predictor.py:156] depth of additional conv before box predictor: 0\n",
            "INFO:tensorflow:depth of additional conv before box predictor: 0\n",
            "I0805 10:44:34.700192 140452147025792 convolutional_box_predictor.py:156] depth of additional conv before box predictor: 0\n",
            "INFO:tensorflow:depth of additional conv before box predictor: 0\n",
            "I0805 10:44:34.737047 140452147025792 convolutional_box_predictor.py:156] depth of additional conv before box predictor: 0\n",
            "INFO:tensorflow:Done calling model_fn.\n",
            "I0805 10:44:35.682933 140452147025792 estimator.py:1150] Done calling model_fn.\n",
            "WARNING:tensorflow:From /tensorflow-1.15.2/python3.7/tensorflow_core/python/saved_model/signature_def_utils_impl.py:201: build_tensor_info (from tensorflow.python.saved_model.utils_impl) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "This function will only be available through the v1 compatibility library as tf.compat.v1.saved_model.utils.build_tensor_info or tf.compat.v1.saved_model.build_tensor_info.\n",
            "W0805 10:44:35.683281 140452147025792 deprecation.py:323] From /tensorflow-1.15.2/python3.7/tensorflow_core/python/saved_model/signature_def_utils_impl.py:201: build_tensor_info (from tensorflow.python.saved_model.utils_impl) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "This function will only be available through the v1 compatibility library as tf.compat.v1.saved_model.utils.build_tensor_info or tf.compat.v1.saved_model.build_tensor_info.\n",
            "INFO:tensorflow:Signatures INCLUDED in export for Classify: None\n",
            "I0805 10:44:35.684085 140452147025792 export_utils.py:170] Signatures INCLUDED in export for Classify: None\n",
            "INFO:tensorflow:Signatures INCLUDED in export for Regress: None\n",
            "I0805 10:44:35.684225 140452147025792 export_utils.py:170] Signatures INCLUDED in export for Regress: None\n",
            "INFO:tensorflow:Signatures INCLUDED in export for Predict: ['tensorflow/serving/predict', 'serving_default']\n",
            "I0805 10:44:35.684352 140452147025792 export_utils.py:170] Signatures INCLUDED in export for Predict: ['tensorflow/serving/predict', 'serving_default']\n",
            "INFO:tensorflow:Signatures INCLUDED in export for Train: None\n",
            "I0805 10:44:35.684499 140452147025792 export_utils.py:170] Signatures INCLUDED in export for Train: None\n",
            "INFO:tensorflow:Signatures INCLUDED in export for Eval: None\n",
            "I0805 10:44:35.684652 140452147025792 export_utils.py:170] Signatures INCLUDED in export for Eval: None\n",
            "2021-08-05 10:44:35.685309: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2021-08-05 10:44:35.685991: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1639] Found device 0 with properties: \n",
            "name: Tesla K80 major: 3 minor: 7 memoryClockRate(GHz): 0.8235\n",
            "pciBusID: 0000:00:04.0\n",
            "2021-08-05 10:44:35.686077: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.1\n",
            "2021-08-05 10:44:35.686133: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcublas.so.10\n",
            "2021-08-05 10:44:35.686207: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcufft.so.10\n",
            "2021-08-05 10:44:35.686245: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcurand.so.10\n",
            "2021-08-05 10:44:35.686296: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusolver.so.10\n",
            "2021-08-05 10:44:35.686332: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusparse.so.10\n",
            "2021-08-05 10:44:35.686368: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudnn.so.7\n",
            "2021-08-05 10:44:35.686476: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2021-08-05 10:44:35.687036: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2021-08-05 10:44:35.687608: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1767] Adding visible gpu devices: 0\n",
            "2021-08-05 10:44:35.687677: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1180] Device interconnect StreamExecutor with strength 1 edge matrix:\n",
            "2021-08-05 10:44:35.687697: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1186]      0 \n",
            "2021-08-05 10:44:35.687711: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1199] 0:   N \n",
            "2021-08-05 10:44:35.687863: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2021-08-05 10:44:35.688429: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2021-08-05 10:44:35.688941: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1325] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 10813 MB memory) -> physical GPU (device: 0, name: Tesla K80, pci bus id: 0000:00:04.0, compute capability: 3.7)\n",
            "INFO:tensorflow:Restoring parameters from training/model.ckpt-5000\n",
            "I0805 10:44:35.691939 140452147025792 saver.py:1284] Restoring parameters from training/model.ckpt-5000\n",
            "INFO:tensorflow:Assets added to graph.\n",
            "I0805 10:44:36.246060 140452147025792 builder_impl.py:665] Assets added to graph.\n",
            "INFO:tensorflow:No assets to write.\n",
            "I0805 10:44:36.246356 140452147025792 builder_impl.py:460] No assets to write.\n",
            "INFO:tensorflow:SavedModel written to: training/export/Servo/temp-b'1628160271'/saved_model.pb\n",
            "I0805 10:44:37.145357 140452147025792 builder_impl.py:425] SavedModel written to: training/export/Servo/temp-b'1628160271'/saved_model.pb\n",
            "INFO:tensorflow:Loss for final step: 0.97562885.\n",
            "I0805 10:44:37.628201 140452147025792 estimator.py:371] Loss for final step: 0.97562885.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KP-tUdtnRybs",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c86bbbe8-7f06-46c6-8073-ddeca3574d95"
      },
      "source": [
        "#model dir check for the trained model\n",
        "!ls {model_dir}"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "checkpoint\n",
            "eval_0\n",
            "events.out.tfevents.1628156487.46e2b19903aa\n",
            "export\n",
            "graph.pbtxt\n",
            "model.ckpt-2401.data-00000-of-00001\n",
            "model.ckpt-2401.index\n",
            "model.ckpt-2401.meta\n",
            "model.ckpt-3222.data-00000-of-00001\n",
            "model.ckpt-3222.index\n",
            "model.ckpt-3222.meta\n",
            "model.ckpt-4019.data-00000-of-00001\n",
            "model.ckpt-4019.index\n",
            "model.ckpt-4019.meta\n",
            "model.ckpt-4820.data-00000-of-00001\n",
            "model.ckpt-4820.index\n",
            "model.ckpt-4820.meta\n",
            "model.ckpt-5000.data-00000-of-00001\n",
            "model.ckpt-5000.index\n",
            "model.ckpt-5000.meta\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OmSESMetj1sa"
      },
      "source": [
        "## Export a Trained Inference Graph\n",
        "Once your training job is complete, you need to extract the newly trained inference graph, which will be later used to perform the object detection. This can be done as follows:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zZJ_AF5MD3hZ"
      },
      "source": [
        "#clean output_directory if necessary to start fresh:\n",
        "\n",
        "!rm -rf /content/object_detection_demo/fine_tuned_model/ \n",
        "os.makedirs('/content/object_detection_demo_flow/fine_tuned_model/', exist_ok=True)"
      ],
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DHoP90pUyKSq"
      },
      "source": [
        "%%capture\n",
        "import re\n",
        "import numpy as np\n",
        "\n",
        "output_directory = './fine_tuned_model'\n",
        "# output_directory = '/content/gdrive/My\\ Drive/data/'\n",
        "\n",
        "lst = os.listdir(model_dir)\n",
        "lst = [l for l in lst if 'model.ckpt-' in l and '.meta' in l]\n",
        "steps=np.array([int(re.findall('\\d+', l)[0]) for l in lst])\n",
        "last_model = lst[steps.argmax()].replace('.meta', '')\n",
        "\n",
        "last_model_path = os.path.join(model_dir, last_model)\n",
        "print(last_model_path)\n",
        "!python /content/models/research/object_detection/export_inference_graph.py \\\n",
        "    --input_type=image_tensor \\\n",
        "    --pipeline_config_path={pipeline_fname} \\\n",
        "    --output_directory={output_directory} \\\n",
        "    --trained_checkpoint_prefix={last_model_path}"
      ],
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "usgBZvkz0nqD",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d67fa979-ec04-4e3e-c4a7-58c8c01d013a"
      },
      "source": [
        "#export directory check\n",
        "!ls {output_directory}"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "checkpoint\t\t\tmodel.ckpt.index  saved_model\n",
            "frozen_inference_graph.pb\tmodel.ckpt.meta\n",
            "model.ckpt.data-00000-of-00001\tpipeline.config\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CnDo1lonKgFr"
      },
      "source": [
        "import os\n",
        "pb_fname = os.path.join(os.path.abspath(output_directory), \"saved_model/saved_model.pb\")\n",
        "assert os.path.isfile(pb_fname), '`{}` not exist'.format(pb_fname)\n",
        "# !ls -alh {pb_fname}"
      ],
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-ZHHqjjfMurV",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "outputId": "ec657442-8dd1-4f70-9c4e-3b9505ff0eac"
      },
      "source": [
        "#download frozen graph for posterity, you can keep this so you don't have to start over on training\n",
        "from google.colab import files\n",
        "files.download(pb_fname)"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ],
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "application/javascript": [
              "download(\"download_31c02468-0f60-4d45-9d99-7c78a715256f\", \"saved_model.pb\", 19510050)"
            ],
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mz1gX19GlVW7"
      },
      "source": [
        "## Running Inference: Checking what the trained model can detect\n",
        "Test with images in repository `tensorflow-object-detection-faster-rcnn/data/images/final test` directory."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iydNnHsvz5II"
      },
      "source": [
        "#You will need to import test images into the test folder specified below - In Roboflow you can export raw images in YOLO Darknet format\n",
        "\n",
        "test_folder = '/content/tensorflow-object-detection-faster-rcnn'\n",
        "sample_img = 'https://storage.googleapis.com/roboflow-platform-transforms/D7CAGZafFYZMvKbKibZGc42BUAx2/56694b0cb356d57b9da4914993042958/transformed.jpg'"
      ],
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Pzj9A4e5mj5l",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5f17f12f-de54-4bbf-a0dc-b998eadb4761"
      },
      "source": [
        "import os\n",
        "import glob\n",
        "\n",
        "# Path to frozen detection graph. This is the actual model that is used for the object detection.\n",
        "PATH_TO_CKPT = pb_fname\n",
        "\n",
        "# List of the strings that is used to add correct label for each box.\n",
        "PATH_TO_LABELS = label_map_pbtxt_fname\n",
        "\n",
        "# If you want to test the code with your images, just add images files to the PATH_TO_TEST_IMAGES_DIR.\n",
        "PATH_TO_TEST_IMAGES_DIR = test_folder + \"/data/test/\"\n",
        "\n",
        "import urllib.request\n",
        "urllib.request.urlretrieve(sample_img, \n",
        "                           PATH_TO_TEST_IMAGES_DIR + \"language.jpg\")\n",
        "\n",
        "assert os.path.isfile(pb_fname)\n",
        "assert os.path.isfile(PATH_TO_LABELS)\n",
        "TEST_IMAGE_PATHS = glob.glob(os.path.join(PATH_TO_TEST_IMAGES_DIR, \"*.jpg*\"))\n",
        "assert len(TEST_IMAGE_PATHS) > 0, 'No image found in `{}`.'.format(PATH_TO_TEST_IMAGES_DIR)\n",
        "print(TEST_IMAGE_PATHS)"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['/content/tensorflow-object-detection-faster-rcnn/data/test/language.jpg']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CG5YUMdg1Po7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f7dfc0ad-e908-47be-aba5-97d395cede31"
      },
      "source": [
        "%cd /content/models/research/object_detection\n",
        "\n",
        "import numpy as np\n",
        "import os\n",
        "import six.moves.urllib as urllib\n",
        "import sys\n",
        "import tarfile\n",
        "import tensorflow as tf\n",
        "import zipfile\n",
        "\n",
        "from collections import defaultdict\n",
        "from io import StringIO\n",
        "# This is needed to display the images.\n",
        "%matplotlib inline\n",
        "import matplotlib.pyplot as plt\n",
        "from PIL import Image\n",
        "\n",
        "# This is needed since the notebook is stored in the object_detection folder.\n",
        "sys.path.append(\"..\")\n",
        "from object_detection.utils import ops as utils_ops\n",
        "\n",
        "from object_detection.utils import label_map_util\n",
        "\n",
        "from object_detection.utils import visualization_utils as vis_util\n",
        "\n",
        "\n",
        "detection_graph = tf.Graph()\n",
        "with detection_graph.as_default():\n",
        "    od_graph_def = tf.GraphDef()\n",
        "    PATH_TO_CKPT = '/content/models/research/fine_tuned_model/frozen_inference_graph.pb'\n",
        "    with tf.gfile.GFile(PATH_TO_CKPT, 'rb') as fid:\n",
        "        serialized_graph = fid.read()\n",
        "        od_graph_def.ParseFromString(serialized_graph)\n",
        "        tf.import_graph_def(od_graph_def, name='')\n",
        "\n",
        "\n",
        "label_map = label_map_util.load_labelmap(PATH_TO_LABELS)\n",
        "categories = label_map_util.convert_label_map_to_categories(\n",
        "    label_map, max_num_classes=num_classes, use_display_name=True)\n",
        "category_index = label_map_util.create_category_index(categories)\n",
        "\n",
        "\n",
        "def load_image_into_numpy_array(image):\n",
        "    (im_width, im_height) = image.size\n",
        "    return np.array(image.getdata()).reshape(\n",
        "        (im_height, im_width, 3)).astype(np.uint8)\n",
        "\n",
        "# Size, in inches, of the output images.\n",
        "IMAGE_SIZE = (12, 8)\n",
        "\n",
        "\n",
        "def run_inference_for_single_image(image, graph):\n",
        "    with graph.as_default():\n",
        "        with tf.Session() as sess:\n",
        "            # Get handles to input and output tensors\n",
        "            ops = tf.get_default_graph().get_operations()\n",
        "            all_tensor_names = {\n",
        "                output.name for op in ops for output in op.outputs}\n",
        "            tensor_dict = {}\n",
        "            for key in [\n",
        "                'num_detections', 'detection_boxes', 'detection_scores',\n",
        "                'detection_classes', 'detection_masks'\n",
        "            ]:\n",
        "                tensor_name = key + ':0'\n",
        "                if tensor_name in all_tensor_names:\n",
        "                    tensor_dict[key] = tf.get_default_graph().get_tensor_by_name(\n",
        "                        tensor_name)\n",
        "            if 'detection_masks' in tensor_dict:\n",
        "                # The following processing is only for single image\n",
        "                detection_boxes = tf.squeeze(\n",
        "                    tensor_dict['detection_boxes'], [0])\n",
        "                detection_masks = tf.squeeze(\n",
        "                    tensor_dict['detection_masks'], [0])\n",
        "                # Reframe is required to translate mask from box coordinates to image coordinates and fit the image size.\n",
        "                real_num_detection = tf.cast(\n",
        "                    tensor_dict['num_detections'][0], tf.int32)\n",
        "                detection_boxes = tf.slice(detection_boxes, [0, 0], [\n",
        "                                           real_num_detection, -1])\n",
        "                detection_masks = tf.slice(detection_masks, [0, 0, 0], [\n",
        "                                           real_num_detection, -1, -1])\n",
        "                detection_masks_reframed = utils_ops.reframe_box_masks_to_image_masks(\n",
        "                    detection_masks, detection_boxes, image.shape[0], image.shape[1])\n",
        "                detection_masks_reframed = tf.cast(\n",
        "                    tf.greater(detection_masks_reframed, 0.5), tf.uint8)\n",
        "                # Follow the convention by adding back the batch dimension\n",
        "                tensor_dict['detection_masks'] = tf.expand_dims(\n",
        "                    detection_masks_reframed, 0)\n",
        "            image_tensor = tf.get_default_graph().get_tensor_by_name('image_tensor:0')\n",
        "\n",
        "            # Run inference\n",
        "            output_dict = sess.run(tensor_dict,\n",
        "                                   feed_dict={image_tensor: np.expand_dims(image, 0)})\n",
        "\n",
        "            # all outputs are float32 numpy arrays, so convert types as appropriate\n",
        "            output_dict['num_detections'] = int(\n",
        "                output_dict['num_detections'][0])\n",
        "            output_dict['detection_classes'] = output_dict[\n",
        "                'detection_classes'][0].astype(np.uint8)\n",
        "            output_dict['detection_boxes'] = output_dict['detection_boxes'][0]\n",
        "            output_dict['detection_scores'] = output_dict['detection_scores'][0]\n",
        "            if 'detection_masks' in output_dict:\n",
        "                output_dict['detection_masks'] = output_dict['detection_masks'][0]\n",
        "    return output_dict\n",
        "\n",
        "\n",
        "for image_path in TEST_IMAGE_PATHS:\n",
        "    image = Image.open(image_path)\n",
        "    print(image_path)\n",
        "    # the array based representation of the image will be used later in order to prepare the\n",
        "    # result image with boxes and labels on it.\n",
        "    image_np = load_image_into_numpy_array(image)\n",
        "    # Expand dimensions since the model expects images to have shape: [1, None, None, 3]\n",
        "    image_np_expanded = np.expand_dims(image_np, axis=0)\n",
        "    # Actual detection.\n",
        "    output_dict = run_inference_for_single_image(image_np, detection_graph)\n",
        "    # Visualization of the results of a detection.\n",
        "    vis_util.visualize_boxes_and_labels_on_image_array(\n",
        "        image_np,\n",
        "        output_dict['detection_boxes'],\n",
        "        output_dict['detection_classes'],\n",
        "        output_dict['detection_scores'],\n",
        "        category_index,\n",
        "        instance_masks=output_dict.get('detection_masks'),\n",
        "        use_normalized_coordinates=True,\n",
        "        line_thickness=8)\n",
        "    plt.figure(figsize=IMAGE_SIZE)\n",
        "    plt.imshow(image_np)\n",
        "    plt.show()"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/models/research/object_detection\n",
            "/content/tensorflow-object-detection-faster-rcnn/data/test/language.jpg\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_PlfZAR1OCK2"
      },
      "source": [
        "# Convert TF model to OpenVINO 20.01 Intermediate Representation (IR)\n",
        " This can be used to run inference on OpenVINO.\n",
        "# In order to run the model on DepthAI modules, we then compile the IR obtained above to a .blob (via a server we set up just for that) "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3qucQJwsWhL3"
      },
      "source": [
        "## First, we install Open Vino 20.01\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0BxCxkQ6NkcF",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "980e838e-6e4f-4d38-96c1-ceda62ff5d53"
      },
      "source": [
        "%cd ../.."
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5py5tfxS6VaA",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "64a6aa33-39e5-43fb-c345-b801735c8b4d"
      },
      "source": [
        "%%time\n",
        "# %%capture\n",
        "## install tools. Open Vino takes some time to download: 10-15 min sometimes.\n",
        "!sudo apt-get install -y pciutils cpio\n",
        "!sudo apt autoremove\n",
        "## downnload installation files\n",
        "!wget http://registrationcenter-download.intel.com/akdlm/irc_nas/16345/l_openvino_toolkit_p_2020.1.023.tgz\n",
        "path = \"l_openvino_toolkit_p_2020.1.023.tgz\"\n",
        "# path = \"/content/software/Intel OpenVINO 2019 R3.1/l_openvino_toolkit_p_2019.3.376.tgz\"\n",
        "## install openvino\n",
        "!tar xf \"{path}\"\n",
        "# !tar xf \"{path}\" && \\\n",
        "#     cd l_openvino_toolkit_p* && \\\n",
        "#     ./install_openvino_dependencies.sh && \\\n",
        "#     sed -i 's/decline/accept/g' silent.cfg && \\\n",
        "#     ./install.sh\n",
        "# ## install dependencies\n",
        "# !/opt/intel/openvino/install_dependencies/install_openvino_dependencies.sh\n",
        "# ## install prerequisites\n",
        "# !/opt/intel/openvino/deployment_tools/model_optimizer/install_prerequisites/install_prerequisites.sh"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Reading package lists... Done\n",
            "Building dependency tree       \n",
            "Reading state information... Done\n",
            "The following additional packages will be installed:\n",
            "  libpci3\n",
            "Suggested packages:\n",
            "  libarchive1\n",
            "The following NEW packages will be installed:\n",
            "  cpio libpci3 pciutils\n",
            "0 upgraded, 3 newly installed, 0 to remove and 94 not upgraded.\n",
            "Need to get 368 kB of archives.\n",
            "After this operation, 1,786 kB of additional disk space will be used.\n",
            "Get:1 http://archive.ubuntu.com/ubuntu bionic-updates/main amd64 cpio amd64 2.12+dfsg-6ubuntu0.18.04.1 [86.2 kB]\n",
            "Get:2 http://archive.ubuntu.com/ubuntu bionic-updates/main amd64 libpci3 amd64 1:3.5.2-1ubuntu1.1 [24.1 kB]\n",
            "Get:3 http://archive.ubuntu.com/ubuntu bionic-updates/main amd64 pciutils amd64 1:3.5.2-1ubuntu1.1 [257 kB]\n",
            "Fetched 368 kB in 2s (198 kB/s)\n",
            "debconf: unable to initialize frontend: Dialog\n",
            "debconf: (No usable dialog-like program is installed, so the dialog based frontend cannot be used. at /usr/share/perl5/Debconf/FrontEnd/Dialog.pm line 76, <> line 3.)\n",
            "debconf: falling back to frontend: Readline\n",
            "debconf: unable to initialize frontend: Readline\n",
            "debconf: (This frontend requires a controlling tty.)\n",
            "debconf: falling back to frontend: Teletype\n",
            "dpkg-preconfigure: unable to re-open stdin: \n",
            "Selecting previously unselected package cpio.\n",
            "(Reading database ... 161222 files and directories currently installed.)\n",
            "Preparing to unpack .../cpio_2.12+dfsg-6ubuntu0.18.04.1_amd64.deb ...\n",
            "Unpacking cpio (2.12+dfsg-6ubuntu0.18.04.1) ...\n",
            "Selecting previously unselected package libpci3:amd64.\n",
            "Preparing to unpack .../libpci3_1%3a3.5.2-1ubuntu1.1_amd64.deb ...\n",
            "Unpacking libpci3:amd64 (1:3.5.2-1ubuntu1.1) ...\n",
            "Selecting previously unselected package pciutils.\n",
            "Preparing to unpack .../pciutils_1%3a3.5.2-1ubuntu1.1_amd64.deb ...\n",
            "Unpacking pciutils (1:3.5.2-1ubuntu1.1) ...\n",
            "Setting up cpio (2.12+dfsg-6ubuntu0.18.04.1) ...\n",
            "update-alternatives: using /bin/mt-gnu to provide /bin/mt (mt) in auto mode\n",
            "Setting up libpci3:amd64 (1:3.5.2-1ubuntu1.1) ...\n",
            "Setting up pciutils (1:3.5.2-1ubuntu1.1) ...\n",
            "Processing triggers for libc-bin (2.27-3ubuntu1.2) ...\n",
            "/sbin/ldconfig.real: /usr/local/lib/python3.7/dist-packages/ideep4py/lib/libmkldnn.so.0 is not a symbolic link\n",
            "\n",
            "Processing triggers for man-db (2.8.3-2ubuntu0.1) ...\n",
            "Reading package lists... Done\n",
            "Building dependency tree       \n",
            "Reading state information... Done\n",
            "0 upgraded, 0 newly installed, 0 to remove and 94 not upgraded.\n",
            "--2021-08-05 10:46:08--  http://registrationcenter-download.intel.com/akdlm/irc_nas/16345/l_openvino_toolkit_p_2020.1.023.tgz\n",
            "Resolving registrationcenter-download.intel.com (registrationcenter-download.intel.com)... 23.203.135.147, 23.203.135.145\n",
            "Connecting to registrationcenter-download.intel.com (registrationcenter-download.intel.com)|23.203.135.147|:80... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 508213676 (485M) [application/octet-stream]\n",
            "Saving to: ‘l_openvino_toolkit_p_2020.1.023.tgz’\n",
            "\n",
            "l_openvino_toolkit_ 100%[===================>] 484.67M  11.9MB/s    in 36s     \n",
            "\n",
            "2021-08-05 10:46:45 (13.3 MB/s) - ‘l_openvino_toolkit_p_2020.1.023.tgz’ saved [508213676/508213676]\n",
            "\n",
            "CPU times: user 691 ms, sys: 253 ms, total: 943 ms\n",
            "Wall time: 53.9 s\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PNFUanul7s1g"
      },
      "source": [
        "%%capture\n",
        "%cd l_openvino_toolkit_p_2020.1.023/\n",
        "!./install_openvino_dependencies.sh && \\\n",
        "    sed -i 's/decline/accept/g' silent.cfg && \\\n",
        "    ./install.sh --silent silent.cfg"
      ],
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "r2enKxK_qakX",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c9b513f9-fc8e-45f3-f231-29d0519bdef6"
      },
      "source": [
        "!ls"
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "EULA.txt\tinstall_openvino_dependencies.sh  pset\t\t  rpm\n",
            "install_GUI.sh\tinstall.sh\t\t\t  PUBLIC_KEY.PUB  silent.cfg\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "h-jbjiw-7nAv"
      },
      "source": [
        "[Optional] Open Vino install check, generally not needed"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0NJp28Oj7Ts9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5f8efaff-800e-4a62-b4f7-0cb6282bb725"
      },
      "source": [
        "!source /opt/intel/openvino/bin/setupvars.sh && \\\n",
        "    /opt/intel/openvino/deployment_tools/demo/demo_squeezenet_download_convert_run.sh"
      ],
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[setupvars.sh] OpenVINO environment initialized\n",
            "target_precision = FP16\n",
            "[setupvars.sh] OpenVINO environment initialized\n",
            "\n",
            "\n",
            "###################################################\n",
            "\n",
            "\n",
            "\n",
            "Downloading the Caffe model and the prototxt\n",
            "Installing dependencies\n",
            "Hit:1 https://cloud.r-project.org/bin/linux/ubuntu bionic-cran40/ InRelease\n",
            "Ign:2 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu1804/x86_64  InRelease\n",
            "Get:3 http://security.ubuntu.com/ubuntu bionic-security InRelease [88.7 kB]\n",
            "Ign:4 https://developer.download.nvidia.com/compute/machine-learning/repos/ubuntu1804/x86_64  InRelease\n",
            "Hit:5 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu1804/x86_64  Release\n",
            "Hit:6 https://developer.download.nvidia.com/compute/machine-learning/repos/ubuntu1804/x86_64  Release\n",
            "Hit:7 http://ppa.launchpad.net/c2d4u.team/c2d4u4.0+/ubuntu bionic InRelease\n",
            "Hit:8 http://archive.ubuntu.com/ubuntu bionic InRelease\n",
            "Get:11 http://archive.ubuntu.com/ubuntu bionic-updates InRelease [88.7 kB]\n",
            "Hit:12 http://ppa.launchpad.net/cran/libgit2/ubuntu bionic InRelease\n",
            "Hit:13 http://ppa.launchpad.net/deadsnakes/ppa/ubuntu bionic InRelease\n",
            "Get:14 http://archive.ubuntu.com/ubuntu bionic-backports InRelease [74.6 kB]\n",
            "Hit:15 http://ppa.launchpad.net/graphics-drivers/ppa/ubuntu bionic InRelease\n",
            "Fetched 252 kB in 2s (129 kB/s)\n",
            "Reading package lists... Done\n",
            "Building dependency tree       \n",
            "Reading state information... Done\n",
            "92 packages can be upgraded. Run 'apt list --upgradable' to see them.\n",
            "Run sudo -E apt -y install build-essential python3-pip virtualenv cmake libcairo2-dev libpango1.0-dev libglib2.0-dev libgtk2.0-dev libswscale-dev libavcodec-dev libavformat-dev libgstreamer1.0-0 gstreamer1.0-plugins-base\n",
            "\n",
            "Reading package lists... Done\n",
            "Building dependency tree       \n",
            "Reading state information... Done\n",
            "build-essential is already the newest version (12.4ubuntu1).\n",
            "cmake is already the newest version (3.10.2-1ubuntu2.18.04.2).\n",
            "gstreamer1.0-plugins-base is already the newest version (1.14.5-0ubuntu1~18.04.3).\n",
            "libglib2.0-dev is already the newest version (2.56.4-0ubuntu0.18.04.8).\n",
            "libglib2.0-dev set to manually installed.\n",
            "libgstreamer1.0-0 is already the newest version (1.14.5-0ubuntu1~18.04.2).\n",
            "libavcodec-dev is already the newest version (7:3.4.8-0ubuntu0.2).\n",
            "libavcodec-dev set to manually installed.\n",
            "libavformat-dev is already the newest version (7:3.4.8-0ubuntu0.2).\n",
            "libavformat-dev set to manually installed.\n",
            "libswscale-dev is already the newest version (7:3.4.8-0ubuntu0.2).\n",
            "libswscale-dev set to manually installed.\n",
            "The following additional packages will be installed:\n",
            "  autoconf automake autopoint autotools-dev debhelper dh-autoreconf\n",
            "  dh-strip-nondeterminism file gettext gettext-base gir1.2-atk-1.0\n",
            "  gir1.2-freedesktop gir1.2-gdkpixbuf-2.0 gir1.2-gtk-2.0 gir1.2-pango-1.0\n",
            "  intltool-debian libarchive-cpio-perl libarchive-zip-perl libatk1.0-dev\n",
            "  libcairo-script-interpreter2 libfile-stripnondeterminism-perl libgail-common\n",
            "  libgail18 libgdk-pixbuf2.0-dev libgtk2.0-0 libgtk2.0-bin libgtk2.0-common\n",
            "  libmagic-mgc libmagic1 libmail-sendmail-perl libpangoxft-1.0-0\n",
            "  libpixman-1-dev libsigsegv2 libsys-hostname-long-perl libtimedate-perl\n",
            "  libtool libxcb-shm0-dev libxcomposite-dev libxcursor-dev libxinerama-dev\n",
            "  libxml2-utils libxrandr-dev m4 po-debconf python-pip-whl python3-asn1crypto\n",
            "  python3-cffi-backend python3-crypto python3-cryptography python3-idna\n",
            "  python3-keyring python3-keyrings.alt python3-pkg-resources\n",
            "  python3-secretstorage python3-setuptools python3-six python3-virtualenv\n",
            "  python3-wheel python3-xdg x11proto-composite-dev x11proto-randr-dev\n",
            "  x11proto-xinerama-dev\n",
            "Suggested packages:\n",
            "  autoconf-archive gnu-standards autoconf-doc dh-make dwz gettext-doc\n",
            "  libasprintf-dev libgettextpo-dev libcairo2-doc gvfs libgtk2.0-doc\n",
            "  imagemagick libpango1.0-doc libtool-doc gcj-jdk m4-doc libmail-box-perl\n",
            "  python-crypto-doc python-cryptography-doc python3-cryptography-vectors\n",
            "  gnome-keyring libkf5wallet-bin gir1.2-gnomekeyring-1.0\n",
            "  python-secretstorage-doc python-setuptools-doc\n",
            "The following NEW packages will be installed:\n",
            "  autoconf automake autopoint autotools-dev debhelper dh-autoreconf\n",
            "  dh-strip-nondeterminism file gettext gettext-base gir1.2-atk-1.0\n",
            "  gir1.2-freedesktop gir1.2-gdkpixbuf-2.0 gir1.2-gtk-2.0 gir1.2-pango-1.0\n",
            "  intltool-debian libarchive-cpio-perl libarchive-zip-perl libatk1.0-dev\n",
            "  libcairo-script-interpreter2 libcairo2-dev libfile-stripnondeterminism-perl\n",
            "  libgail-common libgail18 libgdk-pixbuf2.0-dev libgtk2.0-0 libgtk2.0-bin\n",
            "  libgtk2.0-common libgtk2.0-dev libmagic-mgc libmagic1 libmail-sendmail-perl\n",
            "  libpango1.0-dev libpangoxft-1.0-0 libpixman-1-dev libsigsegv2\n",
            "  libsys-hostname-long-perl libtimedate-perl libtool libxcb-shm0-dev\n",
            "  libxcomposite-dev libxcursor-dev libxinerama-dev libxml2-utils libxrandr-dev\n",
            "  m4 po-debconf python-pip-whl python3-asn1crypto python3-cffi-backend\n",
            "  python3-crypto python3-cryptography python3-idna python3-keyring\n",
            "  python3-keyrings.alt python3-pip python3-pkg-resources python3-secretstorage\n",
            "  python3-setuptools python3-six python3-virtualenv python3-wheel python3-xdg\n",
            "  virtualenv x11proto-composite-dev x11proto-randr-dev x11proto-xinerama-dev\n",
            "0 upgraded, 67 newly installed, 0 to remove and 92 not upgraded.\n",
            "Need to get 14.1 MB of archives.\n",
            "After this operation, 66.0 MB of additional disk space will be used.\n",
            "Get:1 http://archive.ubuntu.com/ubuntu bionic-updates/main amd64 libmagic-mgc amd64 1:5.32-2ubuntu0.4 [184 kB]\n",
            "Get:2 http://archive.ubuntu.com/ubuntu bionic-updates/main amd64 libmagic1 amd64 1:5.32-2ubuntu0.4 [68.6 kB]\n",
            "Get:3 http://archive.ubuntu.com/ubuntu bionic-updates/main amd64 file amd64 1:5.32-2ubuntu0.4 [22.1 kB]\n",
            "Get:4 http://archive.ubuntu.com/ubuntu bionic-updates/main amd64 gettext-base amd64 0.19.8.1-6ubuntu0.3 [113 kB]\n",
            "Get:5 http://archive.ubuntu.com/ubuntu bionic/main amd64 libsigsegv2 amd64 2.12-1 [14.7 kB]\n",
            "Get:6 http://archive.ubuntu.com/ubuntu bionic/main amd64 m4 amd64 1.4.18-1 [197 kB]\n",
            "Get:7 http://archive.ubuntu.com/ubuntu bionic/main amd64 autoconf all 2.69-11 [322 kB]\n",
            "Get:8 http://archive.ubuntu.com/ubuntu bionic/main amd64 autotools-dev all 20180224.1 [39.6 kB]\n",
            "Get:9 http://archive.ubuntu.com/ubuntu bionic/main amd64 automake all 1:1.15.1-3ubuntu2 [509 kB]\n",
            "Get:10 http://archive.ubuntu.com/ubuntu bionic-updates/main amd64 autopoint all 0.19.8.1-6ubuntu0.3 [426 kB]\n",
            "Get:11 http://archive.ubuntu.com/ubuntu bionic/main amd64 libtool all 2.4.6-2 [194 kB]\n",
            "Get:12 http://archive.ubuntu.com/ubuntu bionic/main amd64 dh-autoreconf all 17 [15.8 kB]\n",
            "Get:13 http://archive.ubuntu.com/ubuntu bionic-updates/main amd64 libarchive-zip-perl all 1.60-1ubuntu0.1 [84.6 kB]\n",
            "Get:14 http://archive.ubuntu.com/ubuntu bionic/main amd64 libfile-stripnondeterminism-perl all 0.040-1.1~build1 [13.8 kB]\n",
            "Get:15 http://archive.ubuntu.com/ubuntu bionic/main amd64 libtimedate-perl all 2.3000-2 [37.5 kB]\n",
            "Get:16 http://archive.ubuntu.com/ubuntu bionic/main amd64 dh-strip-nondeterminism all 0.040-1.1~build1 [5,208 B]\n",
            "Get:17 http://archive.ubuntu.com/ubuntu bionic-updates/main amd64 gettext amd64 0.19.8.1-6ubuntu0.3 [1,293 kB]\n",
            "Get:18 http://archive.ubuntu.com/ubuntu bionic/main amd64 intltool-debian all 0.35.0+20060710.4 [24.9 kB]\n",
            "Get:19 http://archive.ubuntu.com/ubuntu bionic/main amd64 po-debconf all 1.0.20 [232 kB]\n",
            "Get:20 http://archive.ubuntu.com/ubuntu bionic-updates/main amd64 debhelper all 11.1.6ubuntu2 [902 kB]\n",
            "Get:21 http://archive.ubuntu.com/ubuntu bionic/main amd64 gir1.2-atk-1.0 amd64 2.28.1-1 [17.8 kB]\n",
            "Get:22 http://archive.ubuntu.com/ubuntu bionic/main amd64 gir1.2-freedesktop amd64 1.56.1-1 [9,080 B]\n",
            "Get:23 http://archive.ubuntu.com/ubuntu bionic/main amd64 gir1.2-gdkpixbuf-2.0 amd64 2.36.11-2 [7,748 B]\n",
            "Get:24 http://archive.ubuntu.com/ubuntu bionic/main amd64 libgtk2.0-common all 2.24.32-1ubuntu1 [125 kB]\n",
            "Get:25 http://archive.ubuntu.com/ubuntu bionic-updates/main amd64 libpangoxft-1.0-0 amd64 1.40.14-1ubuntu0.1 [15.0 kB]\n",
            "Get:26 http://archive.ubuntu.com/ubuntu bionic-updates/main amd64 gir1.2-pango-1.0 amd64 1.40.14-1ubuntu0.1 [21.6 kB]\n",
            "Get:27 http://archive.ubuntu.com/ubuntu bionic/main amd64 libgtk2.0-0 amd64 2.24.32-1ubuntu1 [1,769 kB]\n",
            "Get:28 http://archive.ubuntu.com/ubuntu bionic/main amd64 gir1.2-gtk-2.0 amd64 2.24.32-1ubuntu1 [172 kB]\n",
            "Get:29 http://archive.ubuntu.com/ubuntu bionic/main amd64 libarchive-cpio-perl all 0.10-1 [9,644 B]\n",
            "Get:30 http://archive.ubuntu.com/ubuntu bionic/main amd64 libatk1.0-dev amd64 2.28.1-1 [79.9 kB]\n",
            "Get:31 http://archive.ubuntu.com/ubuntu bionic-updates/main amd64 libcairo-script-interpreter2 amd64 1.15.10-2ubuntu0.1 [53.5 kB]\n",
            "Get:32 http://archive.ubuntu.com/ubuntu bionic/main amd64 libpixman-1-dev amd64 0.34.0-2 [244 kB]\n",
            "Get:33 http://archive.ubuntu.com/ubuntu bionic-updates/main amd64 libxcb-shm0-dev amd64 1.13-2~ubuntu18.04 [6,684 B]\n",
            "Get:34 http://archive.ubuntu.com/ubuntu bionic-updates/main amd64 libcairo2-dev amd64 1.15.10-2ubuntu0.1 [626 kB]\n",
            "Get:35 http://archive.ubuntu.com/ubuntu bionic/main amd64 libgail18 amd64 2.24.32-1ubuntu1 [14.2 kB]\n",
            "Get:36 http://archive.ubuntu.com/ubuntu bionic/main amd64 libgail-common amd64 2.24.32-1ubuntu1 [112 kB]\n",
            "Get:37 http://archive.ubuntu.com/ubuntu bionic/main amd64 libgdk-pixbuf2.0-dev amd64 2.36.11-2 [46.8 kB]\n",
            "Get:38 http://archive.ubuntu.com/ubuntu bionic/main amd64 libgtk2.0-bin amd64 2.24.32-1ubuntu1 [7,536 B]\n",
            "Get:39 http://archive.ubuntu.com/ubuntu bionic-updates/main amd64 libpango1.0-dev amd64 1.40.14-1ubuntu0.1 [288 kB]\n",
            "Get:40 http://archive.ubuntu.com/ubuntu bionic/main amd64 x11proto-xinerama-dev all 2018.4-4 [2,628 B]\n",
            "Get:41 http://archive.ubuntu.com/ubuntu bionic/main amd64 libxinerama-dev amd64 2:1.1.3-1 [8,404 B]\n",
            "Get:42 http://archive.ubuntu.com/ubuntu bionic/main amd64 x11proto-randr-dev all 2018.4-4 [2,620 B]\n",
            "Get:43 http://archive.ubuntu.com/ubuntu bionic/main amd64 libxrandr-dev amd64 2:1.5.1-1 [24.0 kB]\n",
            "Get:44 http://archive.ubuntu.com/ubuntu bionic/main amd64 libxcursor-dev amd64 1:1.1.15-1 [26.5 kB]\n",
            "Get:45 http://archive.ubuntu.com/ubuntu bionic/main amd64 x11proto-composite-dev all 1:2018.4-4 [2,620 B]\n",
            "Get:46 http://archive.ubuntu.com/ubuntu bionic/main amd64 libxcomposite-dev amd64 1:0.4.4-2 [9,136 B]\n",
            "Get:47 http://archive.ubuntu.com/ubuntu bionic-updates/main amd64 libxml2-utils amd64 2.9.4+dfsg1-6.1ubuntu1.4 [35.8 kB]\n",
            "Get:48 http://archive.ubuntu.com/ubuntu bionic/main amd64 libgtk2.0-dev amd64 2.24.32-1ubuntu1 [2,652 kB]\n",
            "Get:49 http://archive.ubuntu.com/ubuntu bionic/main amd64 libsys-hostname-long-perl all 1.5-1 [11.7 kB]\n",
            "Get:50 http://archive.ubuntu.com/ubuntu bionic/main amd64 libmail-sendmail-perl all 0.80-1 [22.6 kB]\n",
            "Get:51 http://archive.ubuntu.com/ubuntu bionic-updates/universe amd64 python-pip-whl all 9.0.1-2.3~ubuntu1.18.04.5 [1,653 kB]\n",
            "Get:52 http://archive.ubuntu.com/ubuntu bionic/main amd64 python3-asn1crypto all 0.24.0-1 [72.8 kB]\n",
            "Get:53 http://archive.ubuntu.com/ubuntu bionic/main amd64 python3-cffi-backend amd64 1.11.5-1 [64.6 kB]\n",
            "Get:54 http://archive.ubuntu.com/ubuntu bionic/main amd64 python3-crypto amd64 2.6.1-8ubuntu2 [244 kB]\n",
            "Get:55 http://archive.ubuntu.com/ubuntu bionic/main amd64 python3-idna all 2.6-1 [32.5 kB]\n",
            "Get:56 http://archive.ubuntu.com/ubuntu bionic/main amd64 python3-six all 1.11.0-2 [11.4 kB]\n",
            "Get:57 http://archive.ubuntu.com/ubuntu bionic-updates/main amd64 python3-cryptography amd64 2.1.4-1ubuntu1.4 [220 kB]\n",
            "Get:58 http://archive.ubuntu.com/ubuntu bionic/main amd64 python3-secretstorage all 2.3.1-2 [12.1 kB]\n",
            "Get:59 http://archive.ubuntu.com/ubuntu bionic/main amd64 python3-keyring all 10.6.0-1 [26.7 kB]\n",
            "Get:60 http://archive.ubuntu.com/ubuntu bionic/main amd64 python3-keyrings.alt all 3.0-1 [16.6 kB]\n",
            "Get:61 http://archive.ubuntu.com/ubuntu bionic-updates/universe amd64 python3-pip all 9.0.1-2.3~ubuntu1.18.04.5 [114 kB]\n",
            "Get:62 http://archive.ubuntu.com/ubuntu bionic/main amd64 python3-pkg-resources all 39.0.1-2 [98.8 kB]\n",
            "Get:63 http://archive.ubuntu.com/ubuntu bionic/main amd64 python3-setuptools all 39.0.1-2 [248 kB]\n",
            "Get:64 http://archive.ubuntu.com/ubuntu bionic/universe amd64 python3-virtualenv all 15.1.0+ds-1.1 [43.4 kB]\n",
            "Get:65 http://archive.ubuntu.com/ubuntu bionic/universe amd64 python3-wheel all 0.30.0-0.2 [36.5 kB]\n",
            "Get:66 http://archive.ubuntu.com/ubuntu bionic-updates/main amd64 python3-xdg all 0.25-4ubuntu1.1 [31.3 kB]\n",
            "Get:67 http://archive.ubuntu.com/ubuntu bionic/universe amd64 virtualenv all 15.1.0+ds-1.1 [4,476 B]\n",
            "Fetched 14.1 MB in 5s (2,846 kB/s)\n",
            "Extracting templates from packages: 100%\n",
            "Selecting previously unselected package libmagic-mgc.\n",
            "(Reading database ... 162235 files and directories currently installed.)\n",
            "Preparing to unpack .../00-libmagic-mgc_1%3a5.32-2ubuntu0.4_amd64.deb ...\n",
            "Unpacking libmagic-mgc (1:5.32-2ubuntu0.4) ...\n",
            "Selecting previously unselected package libmagic1:amd64.\n",
            "Preparing to unpack .../01-libmagic1_1%3a5.32-2ubuntu0.4_amd64.deb ...\n",
            "Unpacking libmagic1:amd64 (1:5.32-2ubuntu0.4) ...\n",
            "Selecting previously unselected package file.\n",
            "Preparing to unpack .../02-file_1%3a5.32-2ubuntu0.4_amd64.deb ...\n",
            "Unpacking file (1:5.32-2ubuntu0.4) ...\n",
            "Selecting previously unselected package gettext-base.\n",
            "Preparing to unpack .../03-gettext-base_0.19.8.1-6ubuntu0.3_amd64.deb ...\n",
            "Unpacking gettext-base (0.19.8.1-6ubuntu0.3) ...\n",
            "Selecting previously unselected package libsigsegv2:amd64.\n",
            "Preparing to unpack .../04-libsigsegv2_2.12-1_amd64.deb ...\n",
            "Unpacking libsigsegv2:amd64 (2.12-1) ...\n",
            "Selecting previously unselected package m4.\n",
            "Preparing to unpack .../05-m4_1.4.18-1_amd64.deb ...\n",
            "Unpacking m4 (1.4.18-1) ...\n",
            "Selecting previously unselected package autoconf.\n",
            "Preparing to unpack .../06-autoconf_2.69-11_all.deb ...\n",
            "Unpacking autoconf (2.69-11) ...\n",
            "Selecting previously unselected package autotools-dev.\n",
            "Preparing to unpack .../07-autotools-dev_20180224.1_all.deb ...\n",
            "Unpacking autotools-dev (20180224.1) ...\n",
            "Selecting previously unselected package automake.\n",
            "Preparing to unpack .../08-automake_1%3a1.15.1-3ubuntu2_all.deb ...\n",
            "Unpacking automake (1:1.15.1-3ubuntu2) ...\n",
            "Selecting previously unselected package autopoint.\n",
            "Preparing to unpack .../09-autopoint_0.19.8.1-6ubuntu0.3_all.deb ...\n",
            "Unpacking autopoint (0.19.8.1-6ubuntu0.3) ...\n",
            "Selecting previously unselected package libtool.\n",
            "Preparing to unpack .../10-libtool_2.4.6-2_all.deb ...\n",
            "Unpacking libtool (2.4.6-2) ...\n",
            "Selecting previously unselected package dh-autoreconf.\n",
            "Preparing to unpack .../11-dh-autoreconf_17_all.deb ...\n",
            "Unpacking dh-autoreconf (17) ...\n",
            "Selecting previously unselected package libarchive-zip-perl.\n",
            "Preparing to unpack .../12-libarchive-zip-perl_1.60-1ubuntu0.1_all.deb ...\n",
            "Unpacking libarchive-zip-perl (1.60-1ubuntu0.1) ...\n",
            "Selecting previously unselected package libfile-stripnondeterminism-perl.\n",
            "Preparing to unpack .../13-libfile-stripnondeterminism-perl_0.040-1.1~build1_all.deb ...\n",
            "Unpacking libfile-stripnondeterminism-perl (0.040-1.1~build1) ...\n",
            "Selecting previously unselected package libtimedate-perl.\n",
            "Preparing to unpack .../14-libtimedate-perl_2.3000-2_all.deb ...\n",
            "Unpacking libtimedate-perl (2.3000-2) ...\n",
            "Selecting previously unselected package dh-strip-nondeterminism.\n",
            "Preparing to unpack .../15-dh-strip-nondeterminism_0.040-1.1~build1_all.deb ...\n",
            "Unpacking dh-strip-nondeterminism (0.040-1.1~build1) ...\n",
            "Selecting previously unselected package gettext.\n",
            "Preparing to unpack .../16-gettext_0.19.8.1-6ubuntu0.3_amd64.deb ...\n",
            "Unpacking gettext (0.19.8.1-6ubuntu0.3) ...\n",
            "Selecting previously unselected package intltool-debian.\n",
            "Preparing to unpack .../17-intltool-debian_0.35.0+20060710.4_all.deb ...\n",
            "Unpacking intltool-debian (0.35.0+20060710.4) ...\n",
            "Selecting previously unselected package po-debconf.\n",
            "Preparing to unpack .../18-po-debconf_1.0.20_all.deb ...\n",
            "Unpacking po-debconf (1.0.20) ...\n",
            "Selecting previously unselected package debhelper.\n",
            "Preparing to unpack .../19-debhelper_11.1.6ubuntu2_all.deb ...\n",
            "Unpacking debhelper (11.1.6ubuntu2) ...\n",
            "Selecting previously unselected package gir1.2-atk-1.0:amd64.\n",
            "Preparing to unpack .../20-gir1.2-atk-1.0_2.28.1-1_amd64.deb ...\n",
            "Unpacking gir1.2-atk-1.0:amd64 (2.28.1-1) ...\n",
            "Selecting previously unselected package gir1.2-freedesktop:amd64.\n",
            "Preparing to unpack .../21-gir1.2-freedesktop_1.56.1-1_amd64.deb ...\n",
            "Unpacking gir1.2-freedesktop:amd64 (1.56.1-1) ...\n",
            "Selecting previously unselected package gir1.2-gdkpixbuf-2.0:amd64.\n",
            "Preparing to unpack .../22-gir1.2-gdkpixbuf-2.0_2.36.11-2_amd64.deb ...\n",
            "Unpacking gir1.2-gdkpixbuf-2.0:amd64 (2.36.11-2) ...\n",
            "Selecting previously unselected package libgtk2.0-common.\n",
            "Preparing to unpack .../23-libgtk2.0-common_2.24.32-1ubuntu1_all.deb ...\n",
            "Unpacking libgtk2.0-common (2.24.32-1ubuntu1) ...\n",
            "Selecting previously unselected package libpangoxft-1.0-0:amd64.\n",
            "Preparing to unpack .../24-libpangoxft-1.0-0_1.40.14-1ubuntu0.1_amd64.deb ...\n",
            "Unpacking libpangoxft-1.0-0:amd64 (1.40.14-1ubuntu0.1) ...\n",
            "Selecting previously unselected package gir1.2-pango-1.0:amd64.\n",
            "Preparing to unpack .../25-gir1.2-pango-1.0_1.40.14-1ubuntu0.1_amd64.deb ...\n",
            "Unpacking gir1.2-pango-1.0:amd64 (1.40.14-1ubuntu0.1) ...\n",
            "Selecting previously unselected package libgtk2.0-0:amd64.\n",
            "Preparing to unpack .../26-libgtk2.0-0_2.24.32-1ubuntu1_amd64.deb ...\n",
            "Unpacking libgtk2.0-0:amd64 (2.24.32-1ubuntu1) ...\n",
            "Selecting previously unselected package gir1.2-gtk-2.0.\n",
            "Preparing to unpack .../27-gir1.2-gtk-2.0_2.24.32-1ubuntu1_amd64.deb ...\n",
            "Unpacking gir1.2-gtk-2.0 (2.24.32-1ubuntu1) ...\n",
            "Selecting previously unselected package libarchive-cpio-perl.\n",
            "Preparing to unpack .../28-libarchive-cpio-perl_0.10-1_all.deb ...\n",
            "Unpacking libarchive-cpio-perl (0.10-1) ...\n",
            "Selecting previously unselected package libatk1.0-dev:amd64.\n",
            "Preparing to unpack .../29-libatk1.0-dev_2.28.1-1_amd64.deb ...\n",
            "Unpacking libatk1.0-dev:amd64 (2.28.1-1) ...\n",
            "Selecting previously unselected package libcairo-script-interpreter2:amd64.\n",
            "Preparing to unpack .../30-libcairo-script-interpreter2_1.15.10-2ubuntu0.1_amd64.deb ...\n",
            "Unpacking libcairo-script-interpreter2:amd64 (1.15.10-2ubuntu0.1) ...\n",
            "Selecting previously unselected package libpixman-1-dev:amd64.\n",
            "Preparing to unpack .../31-libpixman-1-dev_0.34.0-2_amd64.deb ...\n",
            "Unpacking libpixman-1-dev:amd64 (0.34.0-2) ...\n",
            "Selecting previously unselected package libxcb-shm0-dev:amd64.\n",
            "Preparing to unpack .../32-libxcb-shm0-dev_1.13-2~ubuntu18.04_amd64.deb ...\n",
            "Unpacking libxcb-shm0-dev:amd64 (1.13-2~ubuntu18.04) ...\n",
            "Selecting previously unselected package libcairo2-dev:amd64.\n",
            "Preparing to unpack .../33-libcairo2-dev_1.15.10-2ubuntu0.1_amd64.deb ...\n",
            "Unpacking libcairo2-dev:amd64 (1.15.10-2ubuntu0.1) ...\n",
            "Selecting previously unselected package libgail18:amd64.\n",
            "Preparing to unpack .../34-libgail18_2.24.32-1ubuntu1_amd64.deb ...\n",
            "Unpacking libgail18:amd64 (2.24.32-1ubuntu1) ...\n",
            "Selecting previously unselected package libgail-common:amd64.\n",
            "Preparing to unpack .../35-libgail-common_2.24.32-1ubuntu1_amd64.deb ...\n",
            "Unpacking libgail-common:amd64 (2.24.32-1ubuntu1) ...\n",
            "Selecting previously unselected package libgdk-pixbuf2.0-dev.\n",
            "Preparing to unpack .../36-libgdk-pixbuf2.0-dev_2.36.11-2_amd64.deb ...\n",
            "Unpacking libgdk-pixbuf2.0-dev (2.36.11-2) ...\n",
            "Selecting previously unselected package libgtk2.0-bin.\n",
            "Preparing to unpack .../37-libgtk2.0-bin_2.24.32-1ubuntu1_amd64.deb ...\n",
            "Unpacking libgtk2.0-bin (2.24.32-1ubuntu1) ...\n",
            "Selecting previously unselected package libpango1.0-dev.\n",
            "Preparing to unpack .../38-libpango1.0-dev_1.40.14-1ubuntu0.1_amd64.deb ...\n",
            "Unpacking libpango1.0-dev (1.40.14-1ubuntu0.1) ...\n",
            "Selecting previously unselected package x11proto-xinerama-dev.\n",
            "Preparing to unpack .../39-x11proto-xinerama-dev_2018.4-4_all.deb ...\n",
            "Unpacking x11proto-xinerama-dev (2018.4-4) ...\n",
            "Selecting previously unselected package libxinerama-dev:amd64.\n",
            "Preparing to unpack .../40-libxinerama-dev_2%3a1.1.3-1_amd64.deb ...\n",
            "Unpacking libxinerama-dev:amd64 (2:1.1.3-1) ...\n",
            "Selecting previously unselected package x11proto-randr-dev.\n",
            "Preparing to unpack .../41-x11proto-randr-dev_2018.4-4_all.deb ...\n",
            "Unpacking x11proto-randr-dev (2018.4-4) ...\n",
            "Selecting previously unselected package libxrandr-dev:amd64.\n",
            "Preparing to unpack .../42-libxrandr-dev_2%3a1.5.1-1_amd64.deb ...\n",
            "Unpacking libxrandr-dev:amd64 (2:1.5.1-1) ...\n",
            "Selecting previously unselected package libxcursor-dev:amd64.\n",
            "Preparing to unpack .../43-libxcursor-dev_1%3a1.1.15-1_amd64.deb ...\n",
            "Unpacking libxcursor-dev:amd64 (1:1.1.15-1) ...\n",
            "Selecting previously unselected package x11proto-composite-dev.\n",
            "Preparing to unpack .../44-x11proto-composite-dev_1%3a2018.4-4_all.deb ...\n",
            "Unpacking x11proto-composite-dev (1:2018.4-4) ...\n",
            "Selecting previously unselected package libxcomposite-dev:amd64.\n",
            "Preparing to unpack .../45-libxcomposite-dev_1%3a0.4.4-2_amd64.deb ...\n",
            "Unpacking libxcomposite-dev:amd64 (1:0.4.4-2) ...\n",
            "Selecting previously unselected package libxml2-utils.\n",
            "Preparing to unpack .../46-libxml2-utils_2.9.4+dfsg1-6.1ubuntu1.4_amd64.deb ...\n",
            "Unpacking libxml2-utils (2.9.4+dfsg1-6.1ubuntu1.4) ...\n",
            "Selecting previously unselected package libgtk2.0-dev.\n",
            "Preparing to unpack .../47-libgtk2.0-dev_2.24.32-1ubuntu1_amd64.deb ...\n",
            "Unpacking libgtk2.0-dev (2.24.32-1ubuntu1) ...\n",
            "Selecting previously unselected package libsys-hostname-long-perl.\n",
            "Preparing to unpack .../48-libsys-hostname-long-perl_1.5-1_all.deb ...\n",
            "Unpacking libsys-hostname-long-perl (1.5-1) ...\n",
            "Selecting previously unselected package libmail-sendmail-perl.\n",
            "Preparing to unpack .../49-libmail-sendmail-perl_0.80-1_all.deb ...\n",
            "Unpacking libmail-sendmail-perl (0.80-1) ...\n",
            "Selecting previously unselected package python-pip-whl.\n",
            "Preparing to unpack .../50-python-pip-whl_9.0.1-2.3~ubuntu1.18.04.5_all.deb ...\n",
            "Unpacking python-pip-whl (9.0.1-2.3~ubuntu1.18.04.5) ...\n",
            "Selecting previously unselected package python3-asn1crypto.\n",
            "Preparing to unpack .../51-python3-asn1crypto_0.24.0-1_all.deb ...\n",
            "Unpacking python3-asn1crypto (0.24.0-1) ...\n",
            "Selecting previously unselected package python3-cffi-backend.\n",
            "Preparing to unpack .../52-python3-cffi-backend_1.11.5-1_amd64.deb ...\n",
            "Unpacking python3-cffi-backend (1.11.5-1) ...\n",
            "Selecting previously unselected package python3-crypto.\n",
            "Preparing to unpack .../53-python3-crypto_2.6.1-8ubuntu2_amd64.deb ...\n",
            "Unpacking python3-crypto (2.6.1-8ubuntu2) ...\n",
            "Selecting previously unselected package python3-idna.\n",
            "Preparing to unpack .../54-python3-idna_2.6-1_all.deb ...\n",
            "Unpacking python3-idna (2.6-1) ...\n",
            "Selecting previously unselected package python3-six.\n",
            "Preparing to unpack .../55-python3-six_1.11.0-2_all.deb ...\n",
            "Unpacking python3-six (1.11.0-2) ...\n",
            "Selecting previously unselected package python3-cryptography.\n",
            "Preparing to unpack .../56-python3-cryptography_2.1.4-1ubuntu1.4_amd64.deb ...\n",
            "Unpacking python3-cryptography (2.1.4-1ubuntu1.4) ...\n",
            "Selecting previously unselected package python3-secretstorage.\n",
            "Preparing to unpack .../57-python3-secretstorage_2.3.1-2_all.deb ...\n",
            "Unpacking python3-secretstorage (2.3.1-2) ...\n",
            "Selecting previously unselected package python3-keyring.\n",
            "Preparing to unpack .../58-python3-keyring_10.6.0-1_all.deb ...\n",
            "Unpacking python3-keyring (10.6.0-1) ...\n",
            "Selecting previously unselected package python3-keyrings.alt.\n",
            "Preparing to unpack .../59-python3-keyrings.alt_3.0-1_all.deb ...\n",
            "Unpacking python3-keyrings.alt (3.0-1) ...\n",
            "Selecting previously unselected package python3-pip.\n",
            "Preparing to unpack .../60-python3-pip_9.0.1-2.3~ubuntu1.18.04.5_all.deb ...\n",
            "Unpacking python3-pip (9.0.1-2.3~ubuntu1.18.04.5) ...\n",
            "Selecting previously unselected package python3-pkg-resources.\n",
            "Preparing to unpack .../61-python3-pkg-resources_39.0.1-2_all.deb ...\n",
            "Unpacking python3-pkg-resources (39.0.1-2) ...\n",
            "Selecting previously unselected package python3-setuptools.\n",
            "Preparing to unpack .../62-python3-setuptools_39.0.1-2_all.deb ...\n",
            "Unpacking python3-setuptools (39.0.1-2) ...\n",
            "Selecting previously unselected package python3-virtualenv.\n",
            "Preparing to unpack .../63-python3-virtualenv_15.1.0+ds-1.1_all.deb ...\n",
            "Unpacking python3-virtualenv (15.1.0+ds-1.1) ...\n",
            "Selecting previously unselected package python3-wheel.\n",
            "Preparing to unpack .../64-python3-wheel_0.30.0-0.2_all.deb ...\n",
            "Unpacking python3-wheel (0.30.0-0.2) ...\n",
            "Selecting previously unselected package python3-xdg.\n",
            "Preparing to unpack .../65-python3-xdg_0.25-4ubuntu1.1_all.deb ...\n",
            "Unpacking python3-xdg (0.25-4ubuntu1.1) ...\n",
            "Selecting previously unselected package virtualenv.\n",
            "Preparing to unpack .../66-virtualenv_15.1.0+ds-1.1_all.deb ...\n",
            "Unpacking virtualenv (15.1.0+ds-1.1) ...\n",
            "Setting up python-pip-whl (9.0.1-2.3~ubuntu1.18.04.5) ...\n",
            "Setting up libxcursor-dev:amd64 (1:1.1.15-1) ...\n",
            "Setting up gir1.2-atk-1.0:amd64 (2.28.1-1) ...\n",
            "Setting up libgtk2.0-common (2.24.32-1ubuntu1) ...\n",
            "Setting up libarchive-zip-perl (1.60-1ubuntu0.1) ...\n",
            "Setting up python3-cffi-backend (1.11.5-1) ...\n",
            "Setting up libtimedate-perl (2.3000-2) ...\n",
            "Setting up libcairo-script-interpreter2:amd64 (1.15.10-2ubuntu0.1) ...\n",
            "Setting up libsigsegv2:amd64 (2.12-1) ...\n",
            "Setting up python3-crypto (2.6.1-8ubuntu2) ...\n",
            "Setting up gir1.2-freedesktop:amd64 (1.56.1-1) ...\n",
            "Setting up python3-idna (2.6-1) ...\n",
            "Setting up python3-xdg (0.25-4ubuntu1.1) ...\n",
            "Setting up libxcb-shm0-dev:amd64 (1.13-2~ubuntu18.04) ...\n",
            "Setting up python3-six (1.11.0-2) ...\n",
            "Setting up libpangoxft-1.0-0:amd64 (1.40.14-1ubuntu0.1) ...\n",
            "Setting up libxml2-utils (2.9.4+dfsg1-6.1ubuntu1.4) ...\n",
            "Setting up libarchive-cpio-perl (0.10-1) ...\n",
            "Setting up gir1.2-gdkpixbuf-2.0:amd64 (2.36.11-2) ...\n",
            "Setting up libatk1.0-dev:amd64 (2.28.1-1) ...\n",
            "Setting up gettext-base (0.19.8.1-6ubuntu0.3) ...\n",
            "Setting up python3-wheel (0.30.0-0.2) ...\n",
            "Setting up m4 (1.4.18-1) ...\n",
            "Setting up python3-pkg-resources (39.0.1-2) ...\n",
            "Setting up libmagic-mgc (1:5.32-2ubuntu0.4) ...\n",
            "Setting up gir1.2-pango-1.0:amd64 (1.40.14-1ubuntu0.1) ...\n",
            "Setting up libmagic1:amd64 (1:5.32-2ubuntu0.4) ...\n",
            "Setting up python3-asn1crypto (0.24.0-1) ...\n",
            "Setting up libsys-hostname-long-perl (1.5-1) ...\n",
            "Setting up libgdk-pixbuf2.0-dev (2.36.11-2) ...\n",
            "Setting up libmail-sendmail-perl (0.80-1) ...\n",
            "Setting up x11proto-xinerama-dev (2018.4-4) ...\n",
            "Setting up autotools-dev (20180224.1) ...\n",
            "Setting up libpixman-1-dev:amd64 (0.34.0-2) ...\n",
            "Setting up x11proto-randr-dev (2018.4-4) ...\n",
            "Setting up libxinerama-dev:amd64 (2:1.1.3-1) ...\n",
            "Setting up python3-virtualenv (15.1.0+ds-1.1) ...\n",
            "Setting up python3-pip (9.0.1-2.3~ubuntu1.18.04.5) ...\n",
            "Setting up python3-setuptools (39.0.1-2) ...\n",
            "Setting up virtualenv (15.1.0+ds-1.1) ...\n",
            "Setting up x11proto-composite-dev (1:2018.4-4) ...\n",
            "Setting up autopoint (0.19.8.1-6ubuntu0.3) ...\n",
            "Setting up libfile-stripnondeterminism-perl (0.040-1.1~build1) ...\n",
            "Setting up python3-cryptography (2.1.4-1ubuntu1.4) ...\n",
            "Setting up libgtk2.0-0:amd64 (2.24.32-1ubuntu1) ...\n",
            "Setting up libgail18:amd64 (2.24.32-1ubuntu1) ...\n",
            "Setting up libxrandr-dev:amd64 (2:1.5.1-1) ...\n",
            "Setting up libcairo2-dev:amd64 (1.15.10-2ubuntu0.1) ...\n",
            "Setting up gettext (0.19.8.1-6ubuntu0.3) ...\n",
            "Setting up libxcomposite-dev:amd64 (1:0.4.4-2) ...\n",
            "Setting up python3-keyrings.alt (3.0-1) ...\n",
            "Setting up libgail-common:amd64 (2.24.32-1ubuntu1) ...\n",
            "Setting up autoconf (2.69-11) ...\n",
            "Setting up file (1:5.32-2ubuntu0.4) ...\n",
            "Setting up intltool-debian (0.35.0+20060710.4) ...\n",
            "Setting up automake (1:1.15.1-3ubuntu2) ...\n",
            "update-alternatives: using /usr/bin/automake-1.15 to provide /usr/bin/automake (automake) in auto mode\n",
            "Setting up libpango1.0-dev (1.40.14-1ubuntu0.1) ...\n",
            "Setting up python3-secretstorage (2.3.1-2) ...\n",
            "Setting up gir1.2-gtk-2.0 (2.24.32-1ubuntu1) ...\n",
            "Setting up libgtk2.0-bin (2.24.32-1ubuntu1) ...\n",
            "Setting up libtool (2.4.6-2) ...\n",
            "Setting up po-debconf (1.0.20) ...\n",
            "Setting up python3-keyring (10.6.0-1) ...\n",
            "Setting up libgtk2.0-dev (2.24.32-1ubuntu1) ...\n",
            "Setting up dh-autoreconf (17) ...\n",
            "Setting up debhelper (11.1.6ubuntu2) ...\n",
            "Setting up dh-strip-nondeterminism (0.040-1.1~build1) ...\n",
            "Processing triggers for libc-bin (2.27-3ubuntu1.2) ...\n",
            "/sbin/ldconfig.real: /usr/local/lib/python3.7/dist-packages/ideep4py/lib/libmkldnn.so.0 is not a symbolic link\n",
            "\n",
            "Processing triggers for man-db (2.8.3-2ubuntu0.1) ...\n",
            "Reading package lists... Done\n",
            "Building dependency tree       \n",
            "Reading state information... Done\n",
            "libpng-dev is already the newest version (1.6.34-1ubuntu0.18.04.2).\n",
            "0 upgraded, 0 newly installed, 0 to remove and 92 not upgraded.\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.7/dist-packages (from -r /opt/intel/openvino/deployment_tools/demo/../open_model_zoo/tools/downloader/requirements.in (line 1)) (3.13)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from -r /opt/intel/openvino/deployment_tools/demo/../open_model_zoo/tools/downloader/requirements.in (line 2)) (2.23.0)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->-r /opt/intel/openvino/deployment_tools/demo/../open_model_zoo/tools/downloader/requirements.in (line 2)) (2.10)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->-r /opt/intel/openvino/deployment_tools/demo/../open_model_zoo/tools/downloader/requirements.in (line 2)) (2021.5.30)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->-r /opt/intel/openvino/deployment_tools/demo/../open_model_zoo/tools/downloader/requirements.in (line 2)) (1.24.3)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->-r /opt/intel/openvino/deployment_tools/demo/../open_model_zoo/tools/downloader/requirements.in (line 2)) (3.0.4)\n",
            "Run python3 /opt/intel/openvino_2020.1.023/deployment_tools/open_model_zoo/tools/downloader/downloader.py --name squeezenet1.1 --output_dir /root/openvino_models/models --cache_dir /root/openvino_models/cache\n",
            "\n",
            "################|| Downloading models ||################\n",
            "\n",
            "========== Downloading /root/openvino_models/models/public/squeezenet1.1/squeezenet1.1.prototxt\n",
            "... 100%, 9 KB, 33068 KB/s, 0 seconds passed\n",
            "\n",
            "========== Downloading /root/openvino_models/models/public/squeezenet1.1/squeezenet1.1.caffemodel\n",
            "... 100%, 4834 KB, 50917 KB/s, 0 seconds passed\n",
            "\n",
            "################|| Post-processing ||################\n",
            "\n",
            "========== Replacing text in /root/openvino_models/models/public/squeezenet1.1/squeezenet1.1.prototxt\n",
            "\n",
            "\n",
            "###################################################\n",
            "\n",
            "Install Model Optimizer dependencies\n",
            "\n",
            "Hit:1 https://cloud.r-project.org/bin/linux/ubuntu bionic-cran40/ InRelease\n",
            "Ign:2 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu1804/x86_64  InRelease\n",
            "Ign:3 https://developer.download.nvidia.com/compute/machine-learning/repos/ubuntu1804/x86_64  InRelease\n",
            "Hit:4 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu1804/x86_64  Release\n",
            "Hit:5 https://developer.download.nvidia.com/compute/machine-learning/repos/ubuntu1804/x86_64  Release\n",
            "Hit:6 http://ppa.launchpad.net/c2d4u.team/c2d4u4.0+/ubuntu bionic InRelease\n",
            "Get:9 http://security.ubuntu.com/ubuntu bionic-security InRelease [88.7 kB]\n",
            "Hit:10 http://archive.ubuntu.com/ubuntu bionic InRelease\n",
            "Get:11 http://archive.ubuntu.com/ubuntu bionic-updates InRelease [88.7 kB]\n",
            "Hit:12 http://ppa.launchpad.net/cran/libgit2/ubuntu bionic InRelease\n",
            "Hit:13 http://ppa.launchpad.net/deadsnakes/ppa/ubuntu bionic InRelease\n",
            "Get:14 http://archive.ubuntu.com/ubuntu bionic-backports InRelease [74.6 kB]\n",
            "Hit:15 http://ppa.launchpad.net/graphics-drivers/ppa/ubuntu bionic InRelease\n",
            "Fetched 252 kB in 2s (120 kB/s)\n",
            "Reading package lists... Done\n",
            "Building dependency tree       \n",
            "Reading state information... Done\n",
            "92 packages can be upgraded. Run 'apt list --upgradable' to see them.\n",
            "Reading package lists... Done\n",
            "Building dependency tree       \n",
            "Reading state information... Done\n",
            "python3-pip is already the newest version (9.0.1-2.3~ubuntu1.18.04.5).\n",
            "The following additional packages will be installed:\n",
            "  gcc-6-base python3.6-venv\n",
            "The following NEW packages will be installed:\n",
            "  gcc-6-base libgfortran3 python3-venv python3.6-venv\n",
            "0 upgraded, 4 newly installed, 0 to remove and 92 not upgraded.\n",
            "Need to get 294 kB of archives.\n",
            "After this operation, 1,438 kB of additional disk space will be used.\n",
            "Get:1 http://archive.ubuntu.com/ubuntu bionic-updates/universe amd64 gcc-6-base amd64 6.5.0-2ubuntu1~18.04 [16.7 kB]\n",
            "Get:2 http://archive.ubuntu.com/ubuntu bionic-updates/universe amd64 libgfortran3 amd64 6.5.0-2ubuntu1~18.04 [270 kB]\n",
            "Get:3 http://archive.ubuntu.com/ubuntu bionic-updates/universe amd64 python3.6-venv amd64 3.6.9-1~18.04ubuntu1.4 [6,188 B]\n",
            "Get:4 http://archive.ubuntu.com/ubuntu bionic-updates/universe amd64 python3-venv amd64 3.6.7-1~18.04 [1,208 B]\n",
            "Fetched 294 kB in 2s (169 kB/s)\n",
            "Selecting previously unselected package gcc-6-base:amd64.\n",
            "(Reading database ... 164976 files and directories currently installed.)\n",
            "Preparing to unpack .../gcc-6-base_6.5.0-2ubuntu1~18.04_amd64.deb ...\n",
            "Unpacking gcc-6-base:amd64 (6.5.0-2ubuntu1~18.04) ...\n",
            "Selecting previously unselected package libgfortran3:amd64.\n",
            "Preparing to unpack .../libgfortran3_6.5.0-2ubuntu1~18.04_amd64.deb ...\n",
            "Unpacking libgfortran3:amd64 (6.5.0-2ubuntu1~18.04) ...\n",
            "Selecting previously unselected package python3.6-venv.\n",
            "Preparing to unpack .../python3.6-venv_3.6.9-1~18.04ubuntu1.4_amd64.deb ...\n",
            "Unpacking python3.6-venv (3.6.9-1~18.04ubuntu1.4) ...\n",
            "Selecting previously unselected package python3-venv.\n",
            "Preparing to unpack .../python3-venv_3.6.7-1~18.04_amd64.deb ...\n",
            "Unpacking python3-venv (3.6.7-1~18.04) ...\n",
            "Setting up gcc-6-base:amd64 (6.5.0-2ubuntu1~18.04) ...\n",
            "Setting up python3.6-venv (3.6.9-1~18.04ubuntu1.4) ...\n",
            "Setting up python3-venv (3.6.7-1~18.04) ...\n",
            "Setting up libgfortran3:amd64 (6.5.0-2ubuntu1~18.04) ...\n",
            "Processing triggers for man-db (2.8.3-2ubuntu0.1) ...\n",
            "Processing triggers for libc-bin (2.27-3ubuntu1.2) ...\n",
            "/sbin/ldconfig.real: /usr/local/lib/python3.7/dist-packages/ideep4py/lib/libmkldnn.so.0 is not a symbolic link\n",
            "\n",
            "Requirement already satisfied: networkx>=1.11 in /usr/local/lib/python3.7/dist-packages (from -r /opt/intel/openvino_2020.1.023/deployment_tools/model_optimizer/install_prerequisites/../requirements_caffe.txt (line 1)) (2.5.1)\n",
            "Requirement already satisfied: numpy>=1.12.0 in /usr/local/lib/python3.7/dist-packages (from -r /opt/intel/openvino_2020.1.023/deployment_tools/model_optimizer/install_prerequisites/../requirements_caffe.txt (line 2)) (1.17.5)\n",
            "Collecting protobuf==3.6.1\n",
            "  Downloading protobuf-3.6.1-cp37-cp37m-manylinux1_x86_64.whl (1.1 MB)\n",
            "\u001b[K     |████████████████████████████████| 1.1 MB 3.8 MB/s \n",
            "\u001b[?25hRequirement already satisfied: defusedxml>=0.5.0 in /usr/local/lib/python3.7/dist-packages (from -r /opt/intel/openvino_2020.1.023/deployment_tools/model_optimizer/install_prerequisites/../requirements_caffe.txt (line 4)) (0.7.1)\n",
            "Requirement already satisfied: six>=1.9 in /usr/local/lib/python3.7/dist-packages (from protobuf==3.6.1->-r /opt/intel/openvino_2020.1.023/deployment_tools/model_optimizer/install_prerequisites/../requirements_caffe.txt (line 3)) (1.15.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.7/dist-packages (from protobuf==3.6.1->-r /opt/intel/openvino_2020.1.023/deployment_tools/model_optimizer/install_prerequisites/../requirements_caffe.txt (line 3)) (57.2.0)\n",
            "Requirement already satisfied: decorator<5,>=4.3 in /usr/local/lib/python3.7/dist-packages (from networkx>=1.11->-r /opt/intel/openvino_2020.1.023/deployment_tools/model_optimizer/install_prerequisites/../requirements_caffe.txt (line 1)) (4.4.2)\n",
            "Installing collected packages: protobuf\n",
            "  Attempting uninstall: protobuf\n",
            "    Found existing installation: protobuf 3.17.3\n",
            "    Uninstalling protobuf-3.17.3:\n",
            "      Successfully uninstalled protobuf-3.17.3\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "tensorflow 2.5.0 requires numpy~=1.19.2, but you have numpy 1.17.5 which is incompatible.\n",
            "tensorflow 2.5.0 requires protobuf>=3.9.2, but you have protobuf 3.6.1 which is incompatible.\n",
            "tensorflow-metadata 1.1.0 requires protobuf<4,>=3.13, but you have protobuf 3.6.1 which is incompatible.\n",
            "tensorflow-hub 0.12.0 requires protobuf>=3.8.0, but you have protobuf 3.6.1 which is incompatible.\n",
            "kapre 0.3.5 requires numpy>=1.18.5, but you have numpy 1.17.5 which is incompatible.\n",
            "googleapis-common-protos 1.53.0 requires protobuf>=3.12.0, but you have protobuf 3.6.1 which is incompatible.\n",
            "google-api-core 1.26.3 requires protobuf>=3.12.0, but you have protobuf 3.6.1 which is incompatible.\u001b[0m\n",
            "Successfully installed protobuf-3.6.1\n",
            "[WARNING] All Model Optimizer dependencies are installed globally.\n",
            "[WARNING] If you want to keep Model Optimizer in separate sandbox\n",
            "[WARNING] run install_prerequisites.sh venv {caffe|tf|mxnet|kaldi|onnx}\n",
            "\n",
            "\n",
            "###################################################\n",
            "\n",
            "Convert a model with Model Optimizer\n",
            "\n",
            "Run python3 /opt/intel/openvino_2020.1.023/deployment_tools/open_model_zoo/tools/downloader/converter.py --mo /opt/intel/openvino_2020.1.023/deployment_tools/model_optimizer/mo.py --name squeezenet1.1 -d /root/openvino_models/models -o /root/openvino_models/ir --precisions FP16\n",
            "\n",
            "========= Converting squeezenet1.1 to IR (FP16)\n",
            "Conversion command: /usr/bin/python3 -- /opt/intel/openvino_2020.1.023/deployment_tools/model_optimizer/mo.py --framework=caffe --data_type=FP16 --output_dir=/root/openvino_models/ir/public/squeezenet1.1/FP16 --model_name=squeezenet1.1 '--input_shape=[1,3,227,227]' --input=data '--mean_values=data[104.0,117.0,123.0]' --output=prob --input_model=/root/openvino_models/models/public/squeezenet1.1/squeezenet1.1.caffemodel --input_proto=/root/openvino_models/models/public/squeezenet1.1/squeezenet1.1.prototxt\n",
            "\n",
            "Model Optimizer arguments:\n",
            "Common parameters:\n",
            "\t- Path to the Input Model: \t/root/openvino_models/models/public/squeezenet1.1/squeezenet1.1.caffemodel\n",
            "\t- Path for generated IR: \t/root/openvino_models/ir/public/squeezenet1.1/FP16\n",
            "\t- IR output name: \tsqueezenet1.1\n",
            "\t- Log level: \tERROR\n",
            "\t- Batch: \tNot specified, inherited from the model\n",
            "\t- Input layers: \tdata\n",
            "\t- Output layers: \tprob\n",
            "\t- Input shapes: \t[1,3,227,227]\n",
            "\t- Mean values: \tdata[104.0,117.0,123.0]\n",
            "\t- Scale values: \tNot specified\n",
            "\t- Scale factor: \tNot specified\n",
            "\t- Precision of IR: \tFP16\n",
            "\t- Enable fusing: \tTrue\n",
            "\t- Enable grouped convolutions fusing: \tTrue\n",
            "\t- Move mean values to preprocess section: \tFalse\n",
            "\t- Reverse input channels: \tFalse\n",
            "Caffe specific parameters:\n",
            "\t- Path to Python Caffe* parser generated from caffe.proto: \t/opt/intel/openvino_2020.1.023/deployment_tools/model_optimizer/mo/front/caffe/proto\n",
            "\t- Enable resnet optimization: \tTrue\n",
            "\t- Path to the Input prototxt: \t/root/openvino_models/models/public/squeezenet1.1/squeezenet1.1.prototxt\n",
            "\t- Path to CustomLayersMapping.xml: \tDefault\n",
            "\t- Path to a mean file: \tNot specified\n",
            "\t- Offsets for a mean file: \tNot specified\n",
            "Model Optimizer version: \t2020.1.0-61-gd349c3ba4a\n",
            "\n",
            "[ SUCCESS ] Generated IR version 10 model.\n",
            "[ SUCCESS ] XML file: /root/openvino_models/ir/public/squeezenet1.1/FP16/squeezenet1.1.xml\n",
            "[ SUCCESS ] BIN file: /root/openvino_models/ir/public/squeezenet1.1/FP16/squeezenet1.1.bin\n",
            "[ SUCCESS ] Total execution time: 5.56 seconds. \n",
            "[ SUCCESS ] Memory consumed: 113 MB. \n",
            "\n",
            "\n",
            "\n",
            "###################################################\n",
            "\n",
            "Build Inference Engine samples\n",
            "\n",
            "-- The C compiler identification is GNU 7.5.0\n",
            "-- The CXX compiler identification is GNU 7.5.0\n",
            "-- Check for working C compiler: /usr/bin/cc\n",
            "-- Check for working C compiler: /usr/bin/cc -- works\n",
            "-- Detecting C compiler ABI info\n",
            "-- Detecting C compiler ABI info - done\n",
            "-- Detecting C compile features\n",
            "-- Detecting C compile features - done\n",
            "-- Check for working CXX compiler: /usr/bin/c++\n",
            "-- Check for working CXX compiler: /usr/bin/c++ -- works\n",
            "-- Detecting CXX compiler ABI info\n",
            "-- Detecting CXX compiler ABI info - done\n",
            "-- Detecting CXX compile features\n",
            "-- Detecting CXX compile features - done\n",
            "-- Looking for C++ include unistd.h\n",
            "-- Looking for C++ include unistd.h - found\n",
            "-- Looking for C++ include stdint.h\n",
            "-- Looking for C++ include stdint.h - found\n",
            "-- Looking for C++ include sys/types.h\n",
            "-- Looking for C++ include sys/types.h - found\n",
            "-- Looking for C++ include fnmatch.h\n",
            "-- Looking for C++ include fnmatch.h - found\n",
            "-- Looking for strtoll\n",
            "-- Looking for strtoll - found\n",
            "-- Found InferenceEngine: /opt/intel/openvino_2020.1.023/deployment_tools/inference_engine/lib/intel64/libinference_engine.so (Required is at least version \"2.1\") \n",
            "-- Configuring done\n",
            "-- Generating done\n",
            "-- Build files have been written to: /root/inference_engine_samples_build\n",
            "\u001b[35m\u001b[1mScanning dependencies of target format_reader\u001b[0m\n",
            "\u001b[35m\u001b[1mScanning dependencies of target gflags_nothreads_static\u001b[0m\n",
            "[  9%] \u001b[32mBuilding CXX object thirdparty/gflags/CMakeFiles/gflags_nothreads_static.dir/src/gflags.cc.o\u001b[0m\n",
            "[ 18%] \u001b[32mBuilding CXX object thirdparty/gflags/CMakeFiles/gflags_nothreads_static.dir/src/gflags_completions.cc.o\u001b[0m\n",
            "[ 27%] \u001b[32mBuilding CXX object thirdparty/gflags/CMakeFiles/gflags_nothreads_static.dir/src/gflags_reporting.cc.o\u001b[0m\n",
            "[ 36%] \u001b[32mBuilding CXX object common/format_reader/CMakeFiles/format_reader.dir/MnistUbyte.cpp.o\u001b[0m\n",
            "[ 54%] \u001b[32mBuilding CXX object common/format_reader/CMakeFiles/format_reader.dir/bmp.cpp.o\u001b[0m\n",
            "[ 54%] \u001b[32mBuilding CXX object common/format_reader/CMakeFiles/format_reader.dir/opencv_wraper.cpp.o\u001b[0m\n",
            "[ 63%] \u001b[32mBuilding CXX object common/format_reader/CMakeFiles/format_reader.dir/format_reader.cpp.o\u001b[0m\n",
            "[ 72%] \u001b[32m\u001b[1mLinking CXX shared library ../../intel64/Release/lib/libformat_reader.so\u001b[0m\n",
            "[ 72%] Built target format_reader\n",
            "[ 81%] \u001b[32m\u001b[1mLinking CXX static library ../../intel64/Release/lib/libgflags_nothreads.a\u001b[0m\n",
            "[ 81%] Built target gflags_nothreads_static\n",
            "\u001b[35m\u001b[1mScanning dependencies of target classification_sample_async\u001b[0m\n",
            "[ 90%] \u001b[32mBuilding CXX object classification_sample_async/CMakeFiles/classification_sample_async.dir/main.cpp.o\u001b[0m\n",
            "[100%] \u001b[32m\u001b[1mLinking CXX executable ../intel64/Release/classification_sample_async\u001b[0m\n",
            "[100%] Built target classification_sample_async\n",
            "\n",
            "\n",
            "###################################################\n",
            "\n",
            "Run Inference Engine classification sample\n",
            "\n",
            "Run ./classification_sample_async -d CPU -i /opt/intel/openvino/deployment_tools/demo/car.png -m /root/openvino_models/ir/public/squeezenet1.1/FP16/squeezenet1.1.xml\n",
            "\n",
            "[ INFO ] InferenceEngine: \n",
            "\tAPI version ............ 2.1\n",
            "\tBuild .................. 37988\n",
            "\tDescription ....... API\n",
            "[ INFO ] Parsing input parameters\n",
            "[ INFO ] Parsing input parameters\n",
            "[ INFO ] Files were added: 1\n",
            "[ INFO ]     /opt/intel/openvino/deployment_tools/demo/car.png\n",
            "[ INFO ] Creating Inference Engine\n",
            "\tCPU\n",
            "\tMKLDNNPlugin version ......... 2.1\n",
            "\tBuild ........... 37988\n",
            "\n",
            "[ INFO ] Loading network files\n",
            "[ INFO ] Preparing input blobs\n",
            "[ WARNING ] Image is resized from (787, 259) to (227, 227)\n",
            "[ INFO ] Batch size is 1\n",
            "[ INFO ] Loading model to the device\n",
            "[ INFO ] Create infer request\n",
            "[ INFO ] Start inference (10 asynchronous executions)\n",
            "[ INFO ] Completed 1 async request execution\n",
            "[ INFO ] Completed 2 async request execution\n",
            "[ INFO ] Completed 3 async request execution\n",
            "[ INFO ] Completed 4 async request execution\n",
            "[ INFO ] Completed 5 async request execution\n",
            "[ INFO ] Completed 6 async request execution\n",
            "[ INFO ] Completed 7 async request execution\n",
            "[ INFO ] Completed 8 async request execution\n",
            "[ INFO ] Completed 9 async request execution\n",
            "[ INFO ] Completed 10 async request execution\n",
            "[ INFO ] Processing output blobs\n",
            "\n",
            "Top 10 results:\n",
            "\n",
            "Image /opt/intel/openvino/deployment_tools/demo/car.png\n",
            "\n",
            "classid probability label\n",
            "------- ----------- -----\n",
            "817     0.6853030   sports car, sport car\n",
            "479     0.1835197   car wheel\n",
            "511     0.0917197   convertible\n",
            "436     0.0200694   beach wagon, station wagon, wagon, estate car, beach waggon, station waggon, waggon\n",
            "751     0.0069604   racer, race car, racing car\n",
            "656     0.0044177   minivan\n",
            "717     0.0024739   pickup, pickup truck\n",
            "581     0.0017788   grille, radiator grille\n",
            "468     0.0013083   cab, hack, taxi, taxicab\n",
            "661     0.0007443   Model T\n",
            "\n",
            "[ INFO ] Execution successful\n",
            "\n",
            "[ INFO ] This sample is an API example, for any performance measurements please use the dedicated benchmark_app tool\n",
            "\n",
            "\n",
            "###################################################\n",
            "\n",
            "Demo completed successfully.\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TygLw4WIO8BD"
      },
      "source": [
        "### Here we run some modifications in the ssd2 OpenVINO extension for TF so that our Mobilenet SSDv2 model can convert successfully to the IR"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "P-bGZHGcMNbZ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "16a0a540-c3d0-4890-88c1-ae2ca5d270a2"
      },
      "source": [
        "%cd /opt/intel/openvino/deployment_tools/model_optimizer/extensions/front/tf/\n",
        "#openvino fixes: edit \n",
        "# Read in the file, make sure the .json corresponds to the model!!!\n",
        "with open('ssd_v2_support.json', 'r') as file :\n",
        "  filedata = file.read()\n",
        "\n",
        "# Replace the target string\n",
        "filedata = filedata.replace('\"Postprocessor/ToFloat\"', '\"Postprocessor/Cast_1\"')\n",
        "\n",
        "# Write the file out again\n",
        "with open('ssd_v2_support.json', 'w') as file:\n",
        "  file.write(filedata)\n"
      ],
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/opt/intel/openvino_2020.1.023/deployment_tools/model_optimizer/extensions/front/tf\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ROig0wlCkxoX"
      },
      "source": [
        "%cp \"/content/models/research/fine_tuned_model/saved_model/saved_model.pb\" \"/content/models/research/fine_tuned_model/\""
      ],
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "R7sqTX79W6hh"
      },
      "source": [
        "## Convert TF model to Open Vino Intermediate Representation\n",
        "If using own model, please change to your desired name for output directory --output_dir \"choose name\""
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LsWggE5AIWS6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a757965a-d1fe-4833-de85-2cbbdee8e80f"
      },
      "source": [
        "#CONVERT TF MODEL to OPEN VINO IRv10. saved in IR_V10_fruits_mnssdv2_6k directory or\n",
        "#choose own name for --output_dir \"choose name\"\n",
        "%cd \"/content/models/research/fine_tuned_model/\"\n",
        "!source /opt/intel/openvino/bin/setupvars.sh && \\\n",
        "    python /opt/intel/openvino/deployment_tools/model_optimizer/mo.py \\\n",
        "    --input_model frozen_inference_graph.pb \\\n",
        "    --tensorflow_use_custom_operations_config /opt/intel/openvino/deployment_tools/model_optimizer/extensions/front/tf/ssd_v2_support.json \\\n",
        "    --tensorflow_object_detection_api_pipeline_config pipeline.config \\\n",
        "    --reverse_input_channels \\\n",
        "    --output_dir signs \\\n",
        "    --data_type FP16"
      ],
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/models/research/fine_tuned_model\n",
            "[setupvars.sh] OpenVINO environment initialized\n",
            "[ WARNING ]  Use of deprecated cli option --tensorflow_use_custom_operations_config detected. Option use in the following releases will be fatal. Please use --transformations_config cli option instead\n",
            "Model Optimizer arguments:\n",
            "Common parameters:\n",
            "\t- Path to the Input Model: \t/content/models/research/fine_tuned_model/frozen_inference_graph.pb\n",
            "\t- Path for generated IR: \t/content/models/research/fine_tuned_model/signs\n",
            "\t- IR output name: \tfrozen_inference_graph\n",
            "\t- Log level: \tERROR\n",
            "\t- Batch: \tNot specified, inherited from the model\n",
            "\t- Input layers: \tNot specified, inherited from the model\n",
            "\t- Output layers: \tNot specified, inherited from the model\n",
            "\t- Input shapes: \tNot specified, inherited from the model\n",
            "\t- Mean values: \tNot specified\n",
            "\t- Scale values: \tNot specified\n",
            "\t- Scale factor: \tNot specified\n",
            "\t- Precision of IR: \tFP16\n",
            "\t- Enable fusing: \tTrue\n",
            "\t- Enable grouped convolutions fusing: \tTrue\n",
            "\t- Move mean values to preprocess section: \tFalse\n",
            "\t- Reverse input channels: \tTrue\n",
            "TensorFlow specific parameters:\n",
            "\t- Input model in text protobuf format: \tFalse\n",
            "\t- Path to model dump for TensorBoard: \tNone\n",
            "\t- List of shared libraries with TensorFlow custom layers implementation: \tNone\n",
            "\t- Update the configuration file with input/output node names: \tNone\n",
            "\t- Use configuration file used to generate the model with Object Detection API: \t/content/models/research/fine_tuned_model/pipeline.config\n",
            "\t- Operations to offload: \tNone\n",
            "\t- Patterns to offload: \tNone\n",
            "\t- Use the config file: \t/opt/intel/openvino/deployment_tools/model_optimizer/extensions/front/tf/ssd_v2_support.json\n",
            "Model Optimizer version: \t2020.1.0-61-gd349c3ba4a\n",
            "The Preprocessor block has been removed. Only nodes performing mean value subtraction and scaling (if applicable) are kept.\n",
            "\n",
            "[ SUCCESS ] Generated IR version 10 model.\n",
            "[ SUCCESS ] XML file: /content/models/research/fine_tuned_model/signs/frozen_inference_graph.xml\n",
            "[ SUCCESS ] BIN file: /content/models/research/fine_tuned_model/signs/frozen_inference_graph.bin\n",
            "[ SUCCESS ] Total execution time: 37.25 seconds. \n",
            "[ SUCCESS ] Memory consumed: 973 MB. \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "o9R7LTkNvZos",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a5020a86-5d89-4c41-b230-1219f8c42618"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "P15Hl-Fbmkib",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "18acde30-843f-45bf-a33a-fe8f107cf00a"
      },
      "source": [
        "#check directory containing the exported TF trained model and the IRv10 folder\n",
        "%ls "
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "checkpoint                      model.ckpt.index  \u001b[0m\u001b[01;34msaved_model\u001b[0m/\n",
            "frozen_inference_graph.pb       model.ckpt.meta   saved_model.pb\n",
            "model.ckpt.data-00000-of-00001  pipeline.config   \u001b[01;34msigns\u001b[0m/\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WD2BMtXoPjYN"
      },
      "source": [
        "## Now we compile the IR model to a .blob for use on DepthAI modules/platform\n",
        "\n",
        "---\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZqZqajTIP3Sv"
      },
      "source": [
        "### We save the blob in the IR directory from above, corresponding to --output_dir parameter above. \n",
        "The blob filename will be *frozen_inference_graph.blob*"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OBDt-QKvlcdO",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f2e239b2-ca82-4557-aa70-2375a49581a3"
      },
      "source": [
        "%ls /content/models/research/fine_tuned_model/signs"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "frozen_inference_graph.bin      frozen_inference_graph.xml\n",
            "frozen_inference_graph.mapping\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IqiPpnCwPioH",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "baab7701-29ee-433c-d25c-7c34b8a6da83"
      },
      "source": [
        "#No changes needed here unless using custom data.\n",
        "#CHOOSE the directory where you would like to save the blob.\n",
        "# I use the same --output_dir as above for the IR conversion\n",
        "blob_dir = \"/content/models/research/fine_tuned_model/signs/\"\n",
        "\n",
        "#Copy the path of your .xml and .bin files. For that, you can look at the IR\n",
        "#conversion output cell, select and copy from:\n",
        "#[SUCCESS] XML file and bin file paths.\n",
        "#Or you can choose to compile other .xml .bin files from a different location\n",
        "#\n",
        "xmlfile = \"/content/models/research/fine_tuned_model/signs/frozen_inference_graph.xml\"\n",
        "binfile = \"/content/models/research/fine_tuned_model/signs/frozen_inference_graph.bin\"\n",
        "\n",
        "import requests\n",
        "\n",
        "#For openvino 20.01 use this link to compile the blob\n",
        "url = \"http://69.164.214.171:8080\"\n",
        "\n",
        "\n",
        "#open vino 20.02 link:\n",
        "# url = \"69.164.214.171:8081\"\n",
        "\n",
        "payload = {'compiler_params': '-ip U8 -VPU_MYRIAD_PLATFORM VPU_MYRIAD_2480 -VPU_NUMBER_OF_SHAVES 4 -VPU_NUMBER_OF_CMX_SLICES 4'}\n",
        "files = [\n",
        "  ('definition', open(xmlfile,'rb')),\n",
        "  ('weights', open(binfile,'rb'))\n",
        "]\n",
        "# headers = {\n",
        "#   'Content-Type': 'application/json'\n",
        "# }\n",
        "response = requests.request(\"POST\", url, data = payload, files = files)\n",
        "blobnameraw = response.headers.get('Content-Disposition')\n",
        "print(blobnameraw)\n",
        "blobname = blobnameraw[blobnameraw.find('='):][1:]\n",
        "with open(blob_dir + blobname, 'wb') as f:\n",
        "  f.write(response.content)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "attachment; filename=frozen_inference_graph.blob\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2qJ0knjImLIn",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "outputId": "3f9fed03-13bc-4bd2-8b4d-4812ffbfb62d"
      },
      "source": [
        "from google.colab import files\n",
        "files.download('/content/models/research/fine_tuned_model/signs/frozen_inference_graph.blob')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ],
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "application/javascript": [
              "download(\"download_ced5d77c-af24-4783-b8ba-a85cddf6fcb8\", \"frozen_inference_graph.blob\", 14279104)"
            ],
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "24-2kaAFvyEd"
      },
      "source": [
        "## To run the .blob in DepthAI, we proceed step 5 here:\n",
        " https://docs.luxonis.com/tutorials/object_det_mnssv2_training/"
      ]
    }
  ]
}